{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13044b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (50000, 1)\n",
      "Learning rate:  0.001\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 32, 32, 16)   448         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 32, 32, 16)  64          ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 32, 32, 16)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 32, 32, 16)   2320        ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 32, 32, 16)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 32, 32, 16)   0           ['activation[0][0]',             \n",
      "                                                                  'batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 32, 32, 16)   0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 32, 32, 16)   0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 32, 32, 16)   0           ['activation_2[0][0]',           \n",
      "                                                                  'batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 32, 32, 16)   0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 32, 32, 16)   0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 32, 32, 16)   2320        ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 32, 32, 16)   0           ['activation_4[0][0]',           \n",
      "                                                                  'batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 32, 32, 16)   0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 16, 16, 32)   4640        ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 16, 16, 32)  128         ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 16, 16, 32)   0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 16, 16, 32)   9248        ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 16, 16, 32)   544         ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 16, 16, 32)  128         ['conv2d_8[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 16, 16, 32)   0           ['conv2d_9[0][0]',               \n",
      "                                                                  'batch_normalization_8[0][0]']  \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 16, 16, 32)   0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv2d_10 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 16, 16, 32)  128         ['conv2d_10[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 16, 16, 32)   0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 16, 16, 32)  128         ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 16, 16, 32)   0           ['activation_8[0][0]',           \n",
      "                                                                  'batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 16, 16, 32)   0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 16, 16, 32)  128         ['conv2d_12[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 16, 16, 32)   0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 16, 16, 32)   9248        ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 16, 16, 32)  128         ['conv2d_13[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 16, 16, 32)   0           ['activation_10[0][0]',          \n",
      "                                                                  'batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 16, 16, 32)   0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 8, 8, 64)     18496       ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 8, 8, 64)    256         ['conv2d_14[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 8, 8, 64)     2112        ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 8, 8, 64)    256         ['conv2d_15[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 8, 8, 64)     0           ['conv2d_16[0][0]',              \n",
      "                                                                  'batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 8, 8, 64)     0           ['add_6[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_14[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 8, 8, 64)    256         ['conv2d_17[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 8, 8, 64)    256         ['conv2d_18[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 8, 8, 64)     0           ['activation_14[0][0]',          \n",
      "                                                                  'batch_normalization_16[0][0]'] \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 8, 8, 64)     0           ['add_7[0][0]']                  \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 8, 8, 64)    256         ['conv2d_19[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 8, 8, 64)     0           ['batch_normalization_17[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)             (None, 8, 8, 64)     36928       ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_18 (BatchN  (None, 8, 8, 64)    256         ['conv2d_20[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 8, 8, 64)     0           ['activation_16[0][0]',          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                  'batch_normalization_18[0][0]'] \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 8, 8, 64)     0           ['add_8[0][0]']                  \n",
      "                                                                                                  \n",
      " average_pooling2d (AveragePool  (None, 1, 1, 64)    0           ['activation_18[0][0]']          \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 64)           0           ['average_pooling2d[0][0]']      \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 10)           650         ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 274,442\n",
      "Trainable params: 273,066\n",
      "Non-trainable params: 1,376\n",
      "__________________________________________________________________________________________________\n",
      "ResNet20v1\n",
      "Using real-time data augmentation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yue\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "C:\\Users\\Yue\\AppData\\Local\\Temp\\ipykernel_5076\\1709507490.py:412: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Epoch 1/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 1.5688 - accuracy: 0.4850WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 73s 35ms/step - loss: 1.5687 - accuracy: 0.4850 - val_loss: 1.4964 - val_accuracy: 0.5420 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 2/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 1.1874 - accuracy: 0.6340WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 1.1873 - accuracy: 0.6340 - val_loss: 1.2315 - val_accuracy: 0.6275 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 3/200\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 1.0215 - accuracy: 0.6985WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 1.0213 - accuracy: 0.6985 - val_loss: 1.1751 - val_accuracy: 0.6509 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 4/200\n",
      "1557/1563 [============================>.] - ETA: 0s - loss: 0.9243 - accuracy: 0.7359WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.9241 - accuracy: 0.7361 - val_loss: 1.1445 - val_accuracy: 0.6750 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 5/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.8635 - accuracy: 0.7593WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 0.8635 - accuracy: 0.7593 - val_loss: 0.9673 - val_accuracy: 0.7306 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 6/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.8189 - accuracy: 0.7750WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.8188 - accuracy: 0.7750 - val_loss: 1.1737 - val_accuracy: 0.6838 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 7/200\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.7867 - accuracy: 0.7885WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 0.7868 - accuracy: 0.7885 - val_loss: 1.0853 - val_accuracy: 0.7074 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 8/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.7553 - accuracy: 0.8004WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.7551 - accuracy: 0.8004 - val_loss: 1.0949 - val_accuracy: 0.6998 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 9/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.7280 - accuracy: 0.8109WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 34ms/step - loss: 0.7280 - accuracy: 0.8109 - val_loss: 1.1114 - val_accuracy: 0.7116 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 10/200\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 0.7114 - accuracy: 0.8171WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.7116 - accuracy: 0.8171 - val_loss: 0.8003 - val_accuracy: 0.7950 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 11/200\n",
      "1557/1563 [============================>.] - ETA: 0s - loss: 0.7009 - accuracy: 0.8224WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 33ms/step - loss: 0.7007 - accuracy: 0.8225 - val_loss: 0.8875 - val_accuracy: 0.7623 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 12/200\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 0.6823 - accuracy: 0.8305WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.6825 - accuracy: 0.8305 - val_loss: 0.9189 - val_accuracy: 0.7707 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 13/200\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.6672 - accuracy: 0.8359WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.6671 - accuracy: 0.8359 - val_loss: 0.8990 - val_accuracy: 0.7577 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 14/200\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.6533 - accuracy: 0.8396WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.6531 - accuracy: 0.8397 - val_loss: 0.8170 - val_accuracy: 0.7917 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 15/200\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.6515 - accuracy: 0.8411WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.6515 - accuracy: 0.8411 - val_loss: 0.8964 - val_accuracy: 0.7758 - lr: 3.1623e-04\n",
      "Learning rate:  0.001\n",
      "Epoch 16/200\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.6349 - accuracy: 0.8492WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 33ms/step - loss: 0.6348 - accuracy: 0.8492 - val_loss: 0.8135 - val_accuracy: 0.7944 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 17/200\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 0.6282 - accuracy: 0.8514WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.6283 - accuracy: 0.8514 - val_loss: 0.8658 - val_accuracy: 0.7911 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 18/200\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.6188 - accuracy: 0.8553WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.6187 - accuracy: 0.8553 - val_loss: 0.7660 - val_accuracy: 0.8119 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 19/200\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.6105 - accuracy: 0.8555WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.6104 - accuracy: 0.8554 - val_loss: 0.8539 - val_accuracy: 0.7887 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 20/200\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.6075 - accuracy: 0.8583WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.6074 - accuracy: 0.8584 - val_loss: 0.9866 - val_accuracy: 0.7565 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 21/200\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.5999 - accuracy: 0.8606WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.5999 - accuracy: 0.8606 - val_loss: 0.9065 - val_accuracy: 0.7822 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 22/200\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 0.5992 - accuracy: 0.8617WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.5992 - accuracy: 0.8617 - val_loss: 0.7384 - val_accuracy: 0.8246 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 23/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5962 - accuracy: 0.8629WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.5962 - accuracy: 0.8629 - val_loss: 0.7318 - val_accuracy: 0.8300 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 24/200\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.5875 - accuracy: 0.8647WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.5876 - accuracy: 0.8647 - val_loss: 0.8311 - val_accuracy: 0.8074 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Epoch 25/200\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.5817 - accuracy: 0.8683WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 34ms/step - loss: 0.5819 - accuracy: 0.8681 - val_loss: 0.7209 - val_accuracy: 0.8244 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 26/200\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.5795 - accuracy: 0.8699WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.5793 - accuracy: 0.8700 - val_loss: 0.7593 - val_accuracy: 0.8209 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 27/200\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.5750 - accuracy: 0.8718WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.5753 - accuracy: 0.8717 - val_loss: 0.7391 - val_accuracy: 0.8231 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 28/200\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.5715 - accuracy: 0.8712WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 0.5716 - accuracy: 0.8712 - val_loss: 0.9663 - val_accuracy: 0.7685 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 29/200\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.5687 - accuracy: 0.8733WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 0.5688 - accuracy: 0.8732 - val_loss: 0.8974 - val_accuracy: 0.7828 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 30/200\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 0.5611 - accuracy: 0.8751WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 54s 33ms/step - loss: 0.5614 - accuracy: 0.8751 - val_loss: 0.7005 - val_accuracy: 0.8433 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 31/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5612 - accuracy: 0.8763WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 0.5613 - accuracy: 0.8762 - val_loss: 0.9569 - val_accuracy: 0.7854 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 32/200\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.5633 - accuracy: 0.8770WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.5632 - accuracy: 0.8770 - val_loss: 0.7468 - val_accuracy: 0.8261 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 33/200\n",
      "1557/1563 [============================>.] - ETA: 0s - loss: 0.5538 - accuracy: 0.8787WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.5538 - accuracy: 0.8786 - val_loss: 0.7347 - val_accuracy: 0.8248 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 34/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5573 - accuracy: 0.8791WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.5573 - accuracy: 0.8791 - val_loss: 0.7949 - val_accuracy: 0.8180 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 35/200\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.5544 - accuracy: 0.8791WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.5542 - accuracy: 0.8792 - val_loss: 0.6412 - val_accuracy: 0.8529 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 36/200\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.5495 - accuracy: 0.8813WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.5492 - accuracy: 0.8814 - val_loss: 0.6618 - val_accuracy: 0.8489 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 37/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5453 - accuracy: 0.8824WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.5453 - accuracy: 0.8824 - val_loss: 0.8410 - val_accuracy: 0.8041 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 38/200\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.5461 - accuracy: 0.8816WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.5464 - accuracy: 0.8815 - val_loss: 0.6859 - val_accuracy: 0.8398 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 39/200\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.5456 - accuracy: 0.8816WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.5455 - accuracy: 0.8816 - val_loss: 0.6794 - val_accuracy: 0.8460 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 40/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5418 - accuracy: 0.8845WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.5418 - accuracy: 0.8845 - val_loss: 0.6327 - val_accuracy: 0.8594 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 41/200\n",
      "1557/1563 [============================>.] - ETA: 0s - loss: 0.5372 - accuracy: 0.8848WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.5373 - accuracy: 0.8848 - val_loss: 0.8102 - val_accuracy: 0.8035 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 42/200\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.5368 - accuracy: 0.8857WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.5369 - accuracy: 0.8856 - val_loss: 0.6539 - val_accuracy: 0.8540 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 43/200\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.5302 - accuracy: 0.8869WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.5302 - accuracy: 0.8869 - val_loss: 0.8639 - val_accuracy: 0.7915 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 44/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5358 - accuracy: 0.8877WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.5358 - accuracy: 0.8877 - val_loss: 0.7993 - val_accuracy: 0.8160 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 45/200\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.5364 - accuracy: 0.8868WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.5364 - accuracy: 0.8868 - val_loss: 0.8244 - val_accuracy: 0.8160 - lr: 3.1623e-04\n",
      "Learning rate:  0.001\n",
      "Epoch 46/200\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.5355 - accuracy: 0.8861WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.5354 - accuracy: 0.8861 - val_loss: 0.7134 - val_accuracy: 0.8402 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 47/200\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.5281 - accuracy: 0.8888WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.5278 - accuracy: 0.8888 - val_loss: 0.7165 - val_accuracy: 0.8346 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 48/200\n",
      "1557/1563 [============================>.] - ETA: 0s - loss: 0.5266 - accuracy: 0.8895WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.5264 - accuracy: 0.8896 - val_loss: 0.7145 - val_accuracy: 0.8388 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Epoch 49/200\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.5266 - accuracy: 0.8905WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.5265 - accuracy: 0.8905 - val_loss: 0.7856 - val_accuracy: 0.8152 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 50/200\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 0.5253 - accuracy: 0.8901WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.5251 - accuracy: 0.8902 - val_loss: 0.6673 - val_accuracy: 0.8490 - lr: 3.1623e-04\n",
      "Learning rate:  0.001\n",
      "Epoch 51/200\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 0.5255 - accuracy: 0.8893WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.5255 - accuracy: 0.8893 - val_loss: 0.7823 - val_accuracy: 0.8152 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 52/200\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 0.5248 - accuracy: 0.8903WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.5244 - accuracy: 0.8904 - val_loss: 0.7669 - val_accuracy: 0.8230 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 53/200\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.5200 - accuracy: 0.8909WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.5200 - accuracy: 0.8908 - val_loss: 0.6726 - val_accuracy: 0.8452 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 54/200\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 0.5182 - accuracy: 0.8915WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.5184 - accuracy: 0.8915 - val_loss: 0.6861 - val_accuracy: 0.8436 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 55/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5168 - accuracy: 0.8935WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 34ms/step - loss: 0.5168 - accuracy: 0.8934 - val_loss: 0.7580 - val_accuracy: 0.8304 - lr: 3.1623e-04\n",
      "Learning rate:  0.001\n",
      "Epoch 56/200\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.5182 - accuracy: 0.8926WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 34ms/step - loss: 0.5182 - accuracy: 0.8926 - val_loss: 0.6017 - val_accuracy: 0.8708 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 57/200\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.5129 - accuracy: 0.8946WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.5129 - accuracy: 0.8947 - val_loss: 0.6568 - val_accuracy: 0.8586 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 58/200\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.5201 - accuracy: 0.8926WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.5201 - accuracy: 0.8927 - val_loss: 0.6011 - val_accuracy: 0.8691 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 59/200\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 0.5130 - accuracy: 0.8951WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.5129 - accuracy: 0.8951 - val_loss: 0.6825 - val_accuracy: 0.8470 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 60/200\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.5134 - accuracy: 0.8931WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.5134 - accuracy: 0.8931 - val_loss: 0.7717 - val_accuracy: 0.8215 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 61/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5122 - accuracy: 0.8948WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.5123 - accuracy: 0.8947 - val_loss: 0.6500 - val_accuracy: 0.8564 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 62/200\n",
      "1557/1563 [============================>.] - ETA: 0s - loss: 0.5114 - accuracy: 0.8946WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.5115 - accuracy: 0.8946 - val_loss: 0.7455 - val_accuracy: 0.8277 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 63/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5088 - accuracy: 0.8959WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.5088 - accuracy: 0.8959 - val_loss: 0.7191 - val_accuracy: 0.8331 - lr: 3.1623e-04\n",
      "Learning rate:  0.001\n",
      "Epoch 64/200\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.5095 - accuracy: 0.8949WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.5094 - accuracy: 0.8950 - val_loss: 0.6961 - val_accuracy: 0.8523 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 65/200\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.5042 - accuracy: 0.8980WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.5041 - accuracy: 0.8981 - val_loss: 0.6894 - val_accuracy: 0.8396 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 66/200\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 0.5081 - accuracy: 0.8955WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.5079 - accuracy: 0.8955 - val_loss: 0.6053 - val_accuracy: 0.8662 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 67/200\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 0.5046 - accuracy: 0.8967WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.5048 - accuracy: 0.8966 - val_loss: 0.6939 - val_accuracy: 0.8466 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 68/200\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.5054 - accuracy: 0.8971WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.5053 - accuracy: 0.8971 - val_loss: 0.7129 - val_accuracy: 0.8402 - lr: 3.1623e-04\n",
      "Learning rate:  0.001\n",
      "Epoch 69/200\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.5065 - accuracy: 0.8970WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.5065 - accuracy: 0.8970 - val_loss: 0.6530 - val_accuracy: 0.8476 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 70/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5019 - accuracy: 0.8975WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.5019 - accuracy: 0.8975 - val_loss: 0.6095 - val_accuracy: 0.8635 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 71/200\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.5011 - accuracy: 0.8980WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.5012 - accuracy: 0.8980 - val_loss: 0.7721 - val_accuracy: 0.8258 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 72/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.4996 - accuracy: 0.8977WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.4996 - accuracy: 0.8977 - val_loss: 0.7468 - val_accuracy: 0.8328 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 73/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.4981 - accuracy: 0.8988WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.4981 - accuracy: 0.8988 - val_loss: 0.7039 - val_accuracy: 0.8393 - lr: 3.1623e-04\n",
      "Learning rate:  0.001\n",
      "Epoch 74/200\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.5023 - accuracy: 0.8976WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 56s 34ms/step - loss: 0.5019 - accuracy: 0.8977 - val_loss: 0.6198 - val_accuracy: 0.8660 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 75/200\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.4959 - accuracy: 0.9001WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.4961 - accuracy: 0.9000 - val_loss: 0.6976 - val_accuracy: 0.8428 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 76/200\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.4955 - accuracy: 0.8998WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 36ms/step - loss: 0.4956 - accuracy: 0.8998 - val_loss: 0.6436 - val_accuracy: 0.8542 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 77/200\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 0.4998 - accuracy: 0.8994WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 34ms/step - loss: 0.4998 - accuracy: 0.8994 - val_loss: 0.6562 - val_accuracy: 0.8527 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 78/200\n",
      "1557/1563 [============================>.] - ETA: 0s - loss: 0.4980 - accuracy: 0.8996WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.4980 - accuracy: 0.8995 - val_loss: 0.6260 - val_accuracy: 0.8644 - lr: 3.1623e-04\n",
      "Learning rate:  0.001\n",
      "Epoch 79/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4966 - accuracy: 0.8995WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 34ms/step - loss: 0.4966 - accuracy: 0.8995 - val_loss: 0.6541 - val_accuracy: 0.8565 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 80/200\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 0.4955 - accuracy: 0.9005WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.4955 - accuracy: 0.9004 - val_loss: 0.6698 - val_accuracy: 0.8453 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 81/200\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.4933 - accuracy: 0.9016WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 34ms/step - loss: 0.4935 - accuracy: 0.9017 - val_loss: 0.6385 - val_accuracy: 0.8624 - lr: 0.0010\n",
      "Learning rate:  0.0001\n",
      "Epoch 82/200\n",
      "1557/1563 [============================>.] - ETA: 0s - loss: 0.4072 - accuracy: 0.9303WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.4072 - accuracy: 0.9303 - val_loss: 0.5023 - val_accuracy: 0.9024 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 83/200\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.3774 - accuracy: 0.9395WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 34ms/step - loss: 0.3773 - accuracy: 0.9395 - val_loss: 0.4997 - val_accuracy: 0.9027 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 84/200\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.3604 - accuracy: 0.9434WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.3604 - accuracy: 0.9434 - val_loss: 0.4844 - val_accuracy: 0.9091 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 85/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.3469 - accuracy: 0.9478WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.3469 - accuracy: 0.9477 - val_loss: 0.4767 - val_accuracy: 0.9100 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 86/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.3373 - accuracy: 0.9497WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 36ms/step - loss: 0.3373 - accuracy: 0.9497 - val_loss: 0.4741 - val_accuracy: 0.9091 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 87/200\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.3332 - accuracy: 0.9501WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.3332 - accuracy: 0.9502 - val_loss: 0.4816 - val_accuracy: 0.9057 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 88/200\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 0.3218 - accuracy: 0.9528WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 36ms/step - loss: 0.3217 - accuracy: 0.9529 - val_loss: 0.4724 - val_accuracy: 0.9118 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 89/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.3180 - accuracy: 0.9522WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.3180 - accuracy: 0.9522 - val_loss: 0.4683 - val_accuracy: 0.9111 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 90/200\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.3104 - accuracy: 0.9544WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.3105 - accuracy: 0.9543 - val_loss: 0.4691 - val_accuracy: 0.9125 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 91/200\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 0.3068 - accuracy: 0.9550WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.3069 - accuracy: 0.9550 - val_loss: 0.4600 - val_accuracy: 0.9093 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 92/200\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.2998 - accuracy: 0.9574WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 56s 36ms/step - loss: 0.2998 - accuracy: 0.9573 - val_loss: 0.4599 - val_accuracy: 0.9118 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 93/200\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 0.2938 - accuracy: 0.9575WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 53s 34ms/step - loss: 0.2937 - accuracy: 0.9576 - val_loss: 0.4582 - val_accuracy: 0.9099 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 94/200\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.2878 - accuracy: 0.9593WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.2878 - accuracy: 0.9593 - val_loss: 0.4431 - val_accuracy: 0.9155 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 95/200\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.2845 - accuracy: 0.9595WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.2847 - accuracy: 0.9594 - val_loss: 0.4498 - val_accuracy: 0.9139 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.0001\n",
      "Epoch 96/200\n",
      "1557/1563 [============================>.] - ETA: 0s - loss: 0.2799 - accuracy: 0.9603WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.2797 - accuracy: 0.9604 - val_loss: 0.4541 - val_accuracy: 0.9116 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 97/200\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.2776 - accuracy: 0.9604WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.2775 - accuracy: 0.9604 - val_loss: 0.4641 - val_accuracy: 0.9072 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 98/200\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.2718 - accuracy: 0.9616WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.2716 - accuracy: 0.9617 - val_loss: 0.4553 - val_accuracy: 0.9101 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 99/200\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.2664 - accuracy: 0.9624WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.2664 - accuracy: 0.9624 - val_loss: 0.4480 - val_accuracy: 0.9132 - lr: 3.1623e-05\n",
      "Learning rate:  0.0001\n",
      "Epoch 100/200\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.2622 - accuracy: 0.9636WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.2623 - accuracy: 0.9636 - val_loss: 0.4465 - val_accuracy: 0.9132 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 101/200\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.2591 - accuracy: 0.9634WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.2593 - accuracy: 0.9634 - val_loss: 0.4513 - val_accuracy: 0.9112 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 102/200\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 0.2568 - accuracy: 0.9641WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.2567 - accuracy: 0.9641 - val_loss: 0.4522 - val_accuracy: 0.9097 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 103/200\n",
      "1557/1563 [============================>.] - ETA: 0s - loss: 0.2506 - accuracy: 0.9661WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.2506 - accuracy: 0.9661 - val_loss: 0.4496 - val_accuracy: 0.9108 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 104/200\n",
      "1557/1563 [============================>.] - ETA: 0s - loss: 0.2479 - accuracy: 0.9666WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.2481 - accuracy: 0.9666 - val_loss: 0.4489 - val_accuracy: 0.9112 - lr: 3.1623e-05\n",
      "Learning rate:  0.0001\n",
      "Epoch 105/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2495 - accuracy: 0.9652WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.2495 - accuracy: 0.9652 - val_loss: 0.4753 - val_accuracy: 0.9055 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 106/200\n",
      "1557/1563 [============================>.] - ETA: 0s - loss: 0.2443 - accuracy: 0.9670WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.2442 - accuracy: 0.9671 - val_loss: 0.4398 - val_accuracy: 0.9135 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 107/200\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.2388 - accuracy: 0.9671WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.2390 - accuracy: 0.9671 - val_loss: 0.4548 - val_accuracy: 0.9084 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 108/200\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.2390 - accuracy: 0.9667WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.2389 - accuracy: 0.9668 - val_loss: 0.4504 - val_accuracy: 0.9134 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 109/200\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.2355 - accuracy: 0.9679WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.2355 - accuracy: 0.9679 - val_loss: 0.4543 - val_accuracy: 0.9098 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 110/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2334 - accuracy: 0.9684WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.2334 - accuracy: 0.9684 - val_loss: 0.4490 - val_accuracy: 0.9115 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 111/200\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.2305 - accuracy: 0.9685WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.2304 - accuracy: 0.9686 - val_loss: 0.4464 - val_accuracy: 0.9116 - lr: 3.1623e-05\n",
      "Learning rate:  0.0001\n",
      "Epoch 112/200\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 0.2270 - accuracy: 0.9694WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.2270 - accuracy: 0.9693 - val_loss: 0.4409 - val_accuracy: 0.9119 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 113/200\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.2277 - accuracy: 0.9690WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.2277 - accuracy: 0.9690 - val_loss: 0.4557 - val_accuracy: 0.9114 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 114/200\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.2213 - accuracy: 0.9711WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 34ms/step - loss: 0.2213 - accuracy: 0.9711 - val_loss: 0.4562 - val_accuracy: 0.9107 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 115/200\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.2199 - accuracy: 0.9709WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.2199 - accuracy: 0.9710 - val_loss: 0.4421 - val_accuracy: 0.9124 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 116/200\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 0.2172 - accuracy: 0.9710WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.2171 - accuracy: 0.9710 - val_loss: 0.4609 - val_accuracy: 0.9103 - lr: 3.1623e-05\n",
      "Learning rate:  0.0001\n",
      "Epoch 117/200\n",
      "1557/1563 [============================>.] - ETA: 0s - loss: 0.2164 - accuracy: 0.9718WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.2163 - accuracy: 0.9719 - val_loss: 0.4389 - val_accuracy: 0.9154 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 118/200\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.2147 - accuracy: 0.9719WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.2146 - accuracy: 0.9719 - val_loss: 0.4472 - val_accuracy: 0.9103 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 119/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.2133 - accuracy: 0.9718WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.2132 - accuracy: 0.9719 - val_loss: 0.4551 - val_accuracy: 0.9085 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 120/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2136 - accuracy: 0.9712WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 33ms/step - loss: 0.2136 - accuracy: 0.9712 - val_loss: 0.4468 - val_accuracy: 0.9124 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 121/200\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 0.2068 - accuracy: 0.9727WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.2067 - accuracy: 0.9728 - val_loss: 0.4549 - val_accuracy: 0.9107 - lr: 1.0000e-04\n",
      "Learning rate:  1e-05\n",
      "Epoch 122/200\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.1995 - accuracy: 0.9754WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.1995 - accuracy: 0.9754 - val_loss: 0.4354 - val_accuracy: 0.9142 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 123/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1948 - accuracy: 0.9776WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.1949 - accuracy: 0.9776 - val_loss: 0.4333 - val_accuracy: 0.9152 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 124/200\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 0.1950 - accuracy: 0.9774WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 33ms/step - loss: 0.1950 - accuracy: 0.9774 - val_loss: 0.4314 - val_accuracy: 0.9146 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 125/200\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.1899 - accuracy: 0.9801WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.1900 - accuracy: 0.9801 - val_loss: 0.4288 - val_accuracy: 0.9166 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 126/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1903 - accuracy: 0.9803WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.1903 - accuracy: 0.9803 - val_loss: 0.4297 - val_accuracy: 0.9163 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 127/200\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.1916 - accuracy: 0.9792WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.1916 - accuracy: 0.9792 - val_loss: 0.4296 - val_accuracy: 0.9166 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 128/200\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 0.1902 - accuracy: 0.9786WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.1903 - accuracy: 0.9785 - val_loss: 0.4301 - val_accuracy: 0.9171 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 129/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1895 - accuracy: 0.9800WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.1895 - accuracy: 0.9800 - val_loss: 0.4312 - val_accuracy: 0.9175 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 130/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1889 - accuracy: 0.9793WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.1890 - accuracy: 0.9793 - val_loss: 0.4301 - val_accuracy: 0.9171 - lr: 3.1623e-06\n",
      "Learning rate:  1e-05\n",
      "Epoch 131/200\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.1883 - accuracy: 0.9798WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.1883 - accuracy: 0.9798 - val_loss: 0.4292 - val_accuracy: 0.9184 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 132/200\n",
      "1557/1563 [============================>.] - ETA: 0s - loss: 0.1890 - accuracy: 0.9794WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.1889 - accuracy: 0.9794 - val_loss: 0.4338 - val_accuracy: 0.9171 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 133/200\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.1885 - accuracy: 0.9788WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.1885 - accuracy: 0.9788 - val_loss: 0.4324 - val_accuracy: 0.9172 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 134/200\n",
      "1557/1563 [============================>.] - ETA: 0s - loss: 0.1860 - accuracy: 0.9809WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.1861 - accuracy: 0.9809 - val_loss: 0.4320 - val_accuracy: 0.9172 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 135/200\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.1855 - accuracy: 0.9810WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.1855 - accuracy: 0.9810 - val_loss: 0.4319 - val_accuracy: 0.9172 - lr: 3.1623e-06\n",
      "Learning rate:  1e-05\n",
      "Epoch 136/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1861 - accuracy: 0.9800WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.1861 - accuracy: 0.9800 - val_loss: 0.4318 - val_accuracy: 0.9174 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 137/200\n",
      "1557/1563 [============================>.] - ETA: 0s - loss: 0.1853 - accuracy: 0.9800WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.1852 - accuracy: 0.9801 - val_loss: 0.4311 - val_accuracy: 0.9183 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 138/200\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.1859 - accuracy: 0.9800WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.1860 - accuracy: 0.9800 - val_loss: 0.4345 - val_accuracy: 0.9169 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 139/200\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 0.1823 - accuracy: 0.9814WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.1825 - accuracy: 0.9814 - val_loss: 0.4328 - val_accuracy: 0.9176 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 140/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1837 - accuracy: 0.9808WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.1837 - accuracy: 0.9808 - val_loss: 0.4314 - val_accuracy: 0.9173 - lr: 3.1623e-06\n",
      "Learning rate:  1e-05\n",
      "Epoch 141/200\n",
      "1557/1563 [============================>.] - ETA: 0s - loss: 0.1834 - accuracy: 0.9814WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1834 - accuracy: 0.9815 - val_loss: 0.4312 - val_accuracy: 0.9163 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 142/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1815 - accuracy: 0.9807WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 51s 33ms/step - loss: 0.1815 - accuracy: 0.9807 - val_loss: 0.4308 - val_accuracy: 0.9174 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 143/200\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.1828 - accuracy: 0.9815WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 0.1828 - accuracy: 0.9815 - val_loss: 0.4315 - val_accuracy: 0.9183 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 144/200\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.1824 - accuracy: 0.9816WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1825 - accuracy: 0.9816 - val_loss: 0.4336 - val_accuracy: 0.9167 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 145/200\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 0.1812 - accuracy: 0.9811WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1813 - accuracy: 0.9811 - val_loss: 0.4337 - val_accuracy: 0.9171 - lr: 3.1623e-06\n",
      "Learning rate:  1e-05\n",
      "Epoch 146/200\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.1819 - accuracy: 0.9805WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 0.1818 - accuracy: 0.9805 - val_loss: 0.4357 - val_accuracy: 0.9168 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 147/200\n",
      "1557/1563 [============================>.] - ETA: 0s - loss: 0.1824 - accuracy: 0.9807WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1823 - accuracy: 0.9807 - val_loss: 0.4354 - val_accuracy: 0.9166 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 148/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1798 - accuracy: 0.9820WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 0.1798 - accuracy: 0.9820 - val_loss: 0.4350 - val_accuracy: 0.9160 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 149/200\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.1791 - accuracy: 0.9825WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 0.1792 - accuracy: 0.9825 - val_loss: 0.4349 - val_accuracy: 0.9161 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 150/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1782 - accuracy: 0.9824WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 54s 33ms/step - loss: 0.1782 - accuracy: 0.9824 - val_loss: 0.4352 - val_accuracy: 0.9174 - lr: 3.1623e-06\n",
      "Learning rate:  1e-05\n",
      "Epoch 151/200\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.1809 - accuracy: 0.9815WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.1808 - accuracy: 0.9815 - val_loss: 0.4378 - val_accuracy: 0.9161 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 152/200\n",
      "1557/1563 [============================>.] - ETA: 0s - loss: 0.1804 - accuracy: 0.9808WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.1804 - accuracy: 0.9808 - val_loss: 0.4354 - val_accuracy: 0.9164 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 153/200\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.1815 - accuracy: 0.9811WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1815 - accuracy: 0.9811 - val_loss: 0.4357 - val_accuracy: 0.9174 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 154/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1784 - accuracy: 0.9820WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 0.1784 - accuracy: 0.9821 - val_loss: 0.4375 - val_accuracy: 0.9173 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 155/200\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.1768 - accuracy: 0.9821WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1768 - accuracy: 0.9821 - val_loss: 0.4349 - val_accuracy: 0.9172 - lr: 3.1623e-06\n",
      "Learning rate:  1e-05\n",
      "Epoch 156/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1765 - accuracy: 0.9827WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 0.1765 - accuracy: 0.9827 - val_loss: 0.4342 - val_accuracy: 0.9176 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 157/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1768 - accuracy: 0.9824WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1768 - accuracy: 0.9824 - val_loss: 0.4353 - val_accuracy: 0.9173 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 158/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1778 - accuracy: 0.9822WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1778 - accuracy: 0.9822 - val_loss: 0.4374 - val_accuracy: 0.9184 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 159/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1764 - accuracy: 0.9823WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.1763 - accuracy: 0.9823 - val_loss: 0.4376 - val_accuracy: 0.9180 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 160/200\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 0.1772 - accuracy: 0.9820WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.1772 - accuracy: 0.9820 - val_loss: 0.4377 - val_accuracy: 0.9174 - lr: 3.1623e-06\n",
      "Learning rate:  1e-05\n",
      "Epoch 161/200\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.1761 - accuracy: 0.9824WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.1761 - accuracy: 0.9824 - val_loss: 0.4357 - val_accuracy: 0.9189 - lr: 1.0000e-05\n",
      "Learning rate:  1e-06\n",
      "Epoch 162/200\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 0.1761 - accuracy: 0.9821WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1761 - accuracy: 0.9821 - val_loss: 0.4357 - val_accuracy: 0.9182 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 163/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1752 - accuracy: 0.9823WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 0.1752 - accuracy: 0.9823 - val_loss: 0.4364 - val_accuracy: 0.9176 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 164/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1757 - accuracy: 0.9829WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.1757 - accuracy: 0.9829 - val_loss: 0.4364 - val_accuracy: 0.9173 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 165/200\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 0.1755 - accuracy: 0.9832WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.1756 - accuracy: 0.9832 - val_loss: 0.4354 - val_accuracy: 0.9179 - lr: 5.0000e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  1e-06\n",
      "Epoch 166/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1736 - accuracy: 0.9829WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 0.1736 - accuracy: 0.9829 - val_loss: 0.4389 - val_accuracy: 0.9172 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 167/200\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.1749 - accuracy: 0.9824WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1749 - accuracy: 0.9824 - val_loss: 0.4377 - val_accuracy: 0.9174 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 168/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1748 - accuracy: 0.9827WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.1748 - accuracy: 0.9827 - val_loss: 0.4378 - val_accuracy: 0.9178 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 169/200\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.1746 - accuracy: 0.9832WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1747 - accuracy: 0.9832 - val_loss: 0.4355 - val_accuracy: 0.9175 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 170/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1736 - accuracy: 0.9838WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 0.1736 - accuracy: 0.9838 - val_loss: 0.4361 - val_accuracy: 0.9188 - lr: 5.0000e-07\n",
      "Learning rate:  1e-06\n",
      "Epoch 171/200\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 0.1740 - accuracy: 0.9828WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1739 - accuracy: 0.9829 - val_loss: 0.4364 - val_accuracy: 0.9177 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 172/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1742 - accuracy: 0.9835WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 0.1742 - accuracy: 0.9835 - val_loss: 0.4363 - val_accuracy: 0.9179 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 173/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1744 - accuracy: 0.9832WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.1744 - accuracy: 0.9832 - val_loss: 0.4357 - val_accuracy: 0.9182 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 174/200\n",
      "1557/1563 [============================>.] - ETA: 0s - loss: 0.1745 - accuracy: 0.9829WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1745 - accuracy: 0.9828 - val_loss: 0.4367 - val_accuracy: 0.9186 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 175/200\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 0.1747 - accuracy: 0.9825WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.1748 - accuracy: 0.9825 - val_loss: 0.4361 - val_accuracy: 0.9184 - lr: 5.0000e-07\n",
      "Learning rate:  1e-06\n",
      "Epoch 176/200\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.1733 - accuracy: 0.9834WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1733 - accuracy: 0.9834 - val_loss: 0.4358 - val_accuracy: 0.9185 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 177/200\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.1749 - accuracy: 0.9827WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 0.1749 - accuracy: 0.9828 - val_loss: 0.4367 - val_accuracy: 0.9182 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 178/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1754 - accuracy: 0.9833WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1754 - accuracy: 0.9833 - val_loss: 0.4370 - val_accuracy: 0.9181 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 179/200\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 0.1749 - accuracy: 0.9828WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1748 - accuracy: 0.9828 - val_loss: 0.4366 - val_accuracy: 0.9182 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 180/200\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.1735 - accuracy: 0.9832WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.1735 - accuracy: 0.9832 - val_loss: 0.4363 - val_accuracy: 0.9183 - lr: 5.0000e-07\n",
      "Learning rate:  1e-06\n",
      "Epoch 181/200\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 0.1760 - accuracy: 0.9829WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.1761 - accuracy: 0.9829 - val_loss: 0.4364 - val_accuracy: 0.9175 - lr: 1.0000e-06\n",
      "Learning rate:  5e-07\n",
      "Epoch 182/200\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.1732 - accuracy: 0.9832WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.1732 - accuracy: 0.9832 - val_loss: 0.4354 - val_accuracy: 0.9180 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 183/200\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.1729 - accuracy: 0.9839WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 0.1728 - accuracy: 0.9839 - val_loss: 0.4350 - val_accuracy: 0.9185 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 184/200\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.1751 - accuracy: 0.9828WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1751 - accuracy: 0.9828 - val_loss: 0.4367 - val_accuracy: 0.9179 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 185/200\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.1735 - accuracy: 0.9830WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.1735 - accuracy: 0.9830 - val_loss: 0.4362 - val_accuracy: 0.9180 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 186/200\n",
      "1560/1563 [============================>.] - ETA: 0s - loss: 0.1751 - accuracy: 0.9828WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 51s 33ms/step - loss: 0.1751 - accuracy: 0.9828 - val_loss: 0.4372 - val_accuracy: 0.9186 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 187/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1737 - accuracy: 0.9838WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 54s 33ms/step - loss: 0.1736 - accuracy: 0.9838 - val_loss: 0.4364 - val_accuracy: 0.9180 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 188/200\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.1726 - accuracy: 0.9836WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.1726 - accuracy: 0.9836 - val_loss: 0.4352 - val_accuracy: 0.9182 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 189/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.1733 - accuracy: 0.9832WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.1734 - accuracy: 0.9831 - val_loss: 0.4375 - val_accuracy: 0.9180 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 190/200\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.1749 - accuracy: 0.9831WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1749 - accuracy: 0.9831 - val_loss: 0.4367 - val_accuracy: 0.9177 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 191/200\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.1738 - accuracy: 0.9841WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1738 - accuracy: 0.9841 - val_loss: 0.4379 - val_accuracy: 0.9176 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 192/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1740 - accuracy: 0.9831WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.1740 - accuracy: 0.9831 - val_loss: 0.4350 - val_accuracy: 0.9188 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 193/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1755 - accuracy: 0.9819WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.1755 - accuracy: 0.9819 - val_loss: 0.4355 - val_accuracy: 0.9188 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 194/200\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.1734 - accuracy: 0.9833WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.1733 - accuracy: 0.9834 - val_loss: 0.4374 - val_accuracy: 0.9176 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 195/200\n",
      "1561/1563 [============================>.] - ETA: 0s - loss: 0.1734 - accuracy: 0.9836WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.1735 - accuracy: 0.9835 - val_loss: 0.4346 - val_accuracy: 0.9185 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 196/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1735 - accuracy: 0.9834WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 54s 33ms/step - loss: 0.1735 - accuracy: 0.9834 - val_loss: 0.4352 - val_accuracy: 0.9188 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 197/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1750 - accuracy: 0.9831WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 54s 35ms/step - loss: 0.1750 - accuracy: 0.9831 - val_loss: 0.4358 - val_accuracy: 0.9189 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 198/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1734 - accuracy: 0.9840WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 52s 33ms/step - loss: 0.1735 - accuracy: 0.9840 - val_loss: 0.4367 - val_accuracy: 0.9183 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 199/200\n",
      "1558/1563 [============================>.] - ETA: 0s - loss: 0.1734 - accuracy: 0.9829WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.1733 - accuracy: 0.9829 - val_loss: 0.4361 - val_accuracy: 0.9178 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 200/200\n",
      "1559/1563 [============================>.] - ETA: 0s - loss: 0.1734 - accuracy: 0.9839WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 55s 35ms/step - loss: 0.1734 - accuracy: 0.9839 - val_loss: 0.4372 - val_accuracy: 0.9183 - lr: 5.0000e-07\n",
      "313/313 [==============================] - 4s 12ms/step - loss: 0.4372 - accuracy: 0.9183\n",
      "Test loss: 0.4372023344039917\n",
      "Test accuracy: 0.9182999730110168\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation\n",
    "from keras.layers import AveragePooling2D, Input, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Training parameters\n",
    "batch_size = 32  # orig paper trained all networks with batch_size=128\n",
    "epochs = 200\n",
    "data_augmentation = True\n",
    "num_classes = 10\n",
    "\n",
    "# Subtracting pixel mean improves accuracy\n",
    "subtract_pixel_mean = True\n",
    "\n",
    "# Model parameter\n",
    "# ----------------------------------------------------------------------------\n",
    "#           |      | 200-epoch | Orig Paper| 200-epoch | Orig Paper| sec/epoch\n",
    "# Model     |  n   | ResNet v1 | ResNet v1 | ResNet v2 | ResNet v2 | GTX1080Ti\n",
    "#           |v1(v2)| %Accuracy | %Accuracy | %Accuracy | %Accuracy | v1 (v2)\n",
    "# ----------------------------------------------------------------------------\n",
    "# ResNet20  | 3 (2)| 92.16     | 91.25     | -----     | -----     | 35 (---)\n",
    "# ResNet32  | 5(NA)| 92.46     | 92.49     | NA        | NA        | 50 ( NA)\n",
    "# ResNet44  | 7(NA)| 92.50     | 92.83     | NA        | NA        | 70 ( NA)\n",
    "# ResNet56  | 9 (6)| 92.71     | 93.03     | 93.01     | NA        | 90 (100)\n",
    "# ResNet110 |18(12)| 92.65     | 93.39+-.16| 93.15     | 93.63     | 165(180)\n",
    "# ResNet164 |27(18)| -----     | 94.07     | -----     | 94.54     | ---(---)\n",
    "# ResNet1001| (111)| -----     | 92.39     | -----     | 95.08+-.14| ---(---)\n",
    "# ---------------------------------------------------------------------------\n",
    "n = 3\n",
    "\n",
    "# Model version\n",
    "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
    "version = 1\n",
    "\n",
    "# Computed depth from supplied model parameter n\n",
    "if version == 1:\n",
    "    depth = n * 6 + 2\n",
    "elif version == 2:\n",
    "    depth = n * 9 + 2\n",
    "\n",
    "# Model name, depth and version\n",
    "model_type = 'ResNet%dv%d' % (depth, version)\n",
    "\n",
    "# Load the CIFAR10 data.\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Input image dimensions.\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "# Normalize data.\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# If subtract pixel mean is enabled\n",
    "if subtract_pixel_mean:\n",
    "    x_train_mean = np.mean(x_train, axis=0)\n",
    "    x_train -= x_train_mean\n",
    "    x_test -= x_train_mean\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape)\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "\n",
    "def resnet_layer(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or\n",
    "            bn-activation-conv (False)\n",
    "\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def resnet_v1(input_shape, depth, num_classes=10):\n",
    "    \"\"\"ResNet Version 1 Model builder [a]\n",
    "\n",
    "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
    "    Last ReLU is after the shortcut connection.\n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of filters is\n",
    "    doubled. Within each stage, the layers have the same number filters and the\n",
    "    same number of filters.\n",
    "    Features maps sizes:\n",
    "    stage 0: 32x32, 16\n",
    "    stage 1: 16x16, 32\n",
    "    stage 2:  8x8,  64\n",
    "    The Number of parameters is approx the same as Table 6 of [a]:\n",
    "    ResNet20 0.27M\n",
    "    ResNet32 0.46M\n",
    "    ResNet44 0.66M\n",
    "    ResNet56 0.85M\n",
    "    ResNet110 1.7M\n",
    "\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 6 != 0:\n",
    "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
    "    # Start model definition.\n",
    "    num_filters = 16\n",
    "    num_res_blocks = int((depth - 2) / 6)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = resnet_layer(inputs=inputs)\n",
    "    # Instantiate the stack of residual units\n",
    "    for stack in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            strides = 1\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                strides = 2  # downsample\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters,\n",
    "                             strides=strides)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters,\n",
    "                             activation=None)\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "            x = Activation('relu')(x)\n",
    "        num_filters *= 2\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v1 does not use BN after last shortcut connection-ReLU\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet_v2(input_shape, depth, num_classes=10):\n",
    "    \"\"\"ResNet Version 2 Model builder [b]\n",
    "\n",
    "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
    "    bottleneck layer\n",
    "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
    "    Second and onwards shortcut connection is identity.\n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of filter maps is\n",
    "    doubled. Within each stage, the layers have the same number filters and the\n",
    "    same filter map sizes.\n",
    "    Features maps sizes:\n",
    "    conv1  : 32x32,  16\n",
    "    stage 0: 32x32,  64\n",
    "    stage 1: 16x16, 128\n",
    "    stage 2:  8x8,  256\n",
    "\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 9 != 0:\n",
    "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
    "    # Start model definition.\n",
    "    num_filters_in = 16\n",
    "    num_res_blocks = int((depth - 2) / 9)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
    "    x = resnet_layer(inputs=inputs,\n",
    "                     num_filters=num_filters_in,\n",
    "                     conv_first=True)\n",
    "\n",
    "    # Instantiate the stack of residual units\n",
    "    for stage in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            activation = 'relu'\n",
    "            batch_normalization = True\n",
    "            strides = 1\n",
    "            if stage == 0:\n",
    "                num_filters_out = num_filters_in * 4\n",
    "                if res_block == 0:  # first layer and first stage\n",
    "                    activation = None\n",
    "                    batch_normalization = False\n",
    "            else:\n",
    "                num_filters_out = num_filters_in * 2\n",
    "                if res_block == 0:  # first layer but not first stage\n",
    "                    strides = 2    # downsample\n",
    "\n",
    "            # bottleneck residual unit\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters_in,\n",
    "                             kernel_size=1,\n",
    "                             strides=strides,\n",
    "                             activation=activation,\n",
    "                             batch_normalization=batch_normalization,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_in,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_out,\n",
    "                             kernel_size=1,\n",
    "                             conv_first=False)\n",
    "            if res_block == 0:\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters_out,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "\n",
    "        num_filters_in = num_filters_out\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v2 has BN-ReLU before Pooling\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "if version == 2:\n",
    "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
    "else:\n",
    "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=lr_schedule(0)),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "print(model_type)\n",
    "\n",
    "# Prepare model model saving directory.\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
    "\n",
    "# Run training, with or without data augmentation.\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        # set input mean to 0 over the dataset\n",
    "        featurewise_center=False,\n",
    "        # set each sample mean to 0\n",
    "        samplewise_center=False,\n",
    "        # divide inputs by std of dataset\n",
    "        featurewise_std_normalization=False,\n",
    "        # divide each input by its std\n",
    "        samplewise_std_normalization=False,\n",
    "        # apply ZCA whitening\n",
    "        zca_whitening=False,\n",
    "        # epsilon for ZCA whitening\n",
    "        zca_epsilon=1e-06,\n",
    "        # randomly rotate images in the range (deg 0 to 180)\n",
    "        rotation_range=0,\n",
    "        # randomly shift images horizontally\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically\n",
    "        height_shift_range=0.1,\n",
    "        # set range for random shear\n",
    "        shear_range=0.,\n",
    "        # set range for random zoom\n",
    "        zoom_range=0.,\n",
    "        # set range for random channel shifts\n",
    "        channel_shift_range=0.,\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        # value used for fill_mode = \"constant\"\n",
    "        cval=0.,\n",
    "        # randomly flip images\n",
    "        horizontal_flip=True,\n",
    "        # randomly flip images\n",
    "        vertical_flip=False,\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        epochs=epochs, verbose=1, workers=4,\n",
    "                        callbacks=callbacks)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df972822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (50000, 1)\n",
      "Learning rate:  0.001\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 32, 32, 16)   448         ['input_3[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 32, 32, 16)  64          ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_47 (Activation)     (None, 32, 32, 16)   0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 32, 32, 16)   272         ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 32, 32, 16)  64          ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_48 (Activation)     (None, 32, 32, 16)   0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 32, 32, 16)   2320        ['activation_48[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 32, 32, 16)  64          ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_49 (Activation)     (None, 32, 32, 16)   0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 32, 32, 64)   1088        ['activation_47[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 32, 32, 64)   1088        ['activation_49[0][0]']          \n",
      "                                                                                                  \n",
      " add_18 (Add)                   (None, 32, 32, 64)   0           ['conv2d_56[0][0]',              \n",
      "                                                                  'conv2d_55[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 32, 32, 64)  256         ['add_18[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_50 (Activation)     (None, 32, 32, 64)   0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_57 (Conv2D)             (None, 32, 32, 16)   1040        ['activation_50[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 32, 32, 16)  64          ['conv2d_57[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_51 (Activation)     (None, 32, 32, 16)   0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_58 (Conv2D)             (None, 32, 32, 16)   2320        ['activation_51[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 32, 32, 16)  64          ['conv2d_58[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_52 (Activation)     (None, 32, 32, 16)   0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_59 (Conv2D)             (None, 32, 32, 64)   1088        ['activation_52[0][0]']          \n",
      "                                                                                                  \n",
      " add_19 (Add)                   (None, 32, 32, 64)   0           ['add_18[0][0]',                 \n",
      "                                                                  'conv2d_59[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 32, 32, 64)  256         ['add_19[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_53 (Activation)     (None, 32, 32, 64)   0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_60 (Conv2D)             (None, 32, 32, 16)   1040        ['activation_53[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 32, 32, 16)  64          ['conv2d_60[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_54 (Activation)     (None, 32, 32, 16)   0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_61 (Conv2D)             (None, 32, 32, 16)   2320        ['activation_54[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 32, 32, 16)  64          ['conv2d_61[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_55 (Activation)     (None, 32, 32, 16)   0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_62 (Conv2D)             (None, 32, 32, 64)   1088        ['activation_55[0][0]']          \n",
      "                                                                                                  \n",
      " add_20 (Add)                   (None, 32, 32, 64)   0           ['add_19[0][0]',                 \n",
      "                                                                  'conv2d_62[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 32, 32, 64)  256         ['add_20[0][0]']                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_56 (Activation)     (None, 32, 32, 64)   0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_63 (Conv2D)             (None, 32, 32, 16)   1040        ['activation_56[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 32, 32, 16)  64          ['conv2d_63[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_57 (Activation)     (None, 32, 32, 16)   0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_64 (Conv2D)             (None, 32, 32, 16)   2320        ['activation_57[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_58 (BatchN  (None, 32, 32, 16)  64          ['conv2d_64[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_58 (Activation)     (None, 32, 32, 16)   0           ['batch_normalization_58[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_65 (Conv2D)             (None, 32, 32, 64)   1088        ['activation_58[0][0]']          \n",
      "                                                                                                  \n",
      " add_21 (Add)                   (None, 32, 32, 64)   0           ['add_20[0][0]',                 \n",
      "                                                                  'conv2d_65[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_59 (BatchN  (None, 32, 32, 64)  256         ['add_21[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_59 (Activation)     (None, 32, 32, 64)   0           ['batch_normalization_59[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_66 (Conv2D)             (None, 32, 32, 16)   1040        ['activation_59[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_60 (BatchN  (None, 32, 32, 16)  64          ['conv2d_66[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_60 (Activation)     (None, 32, 32, 16)   0           ['batch_normalization_60[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_67 (Conv2D)             (None, 32, 32, 16)   2320        ['activation_60[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_61 (BatchN  (None, 32, 32, 16)  64          ['conv2d_67[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_61 (Activation)     (None, 32, 32, 16)   0           ['batch_normalization_61[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_68 (Conv2D)             (None, 32, 32, 64)   1088        ['activation_61[0][0]']          \n",
      "                                                                                                  \n",
      " add_22 (Add)                   (None, 32, 32, 64)   0           ['add_21[0][0]',                 \n",
      "                                                                  'conv2d_68[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_62 (BatchN  (None, 32, 32, 64)  256         ['add_22[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_62 (Activation)     (None, 32, 32, 64)   0           ['batch_normalization_62[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_69 (Conv2D)             (None, 32, 32, 16)   1040        ['activation_62[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_63 (BatchN  (None, 32, 32, 16)  64          ['conv2d_69[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_63 (Activation)     (None, 32, 32, 16)   0           ['batch_normalization_63[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_70 (Conv2D)             (None, 32, 32, 16)   2320        ['activation_63[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_64 (BatchN  (None, 32, 32, 16)  64          ['conv2d_70[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_64 (Activation)     (None, 32, 32, 16)   0           ['batch_normalization_64[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_71 (Conv2D)             (None, 32, 32, 64)   1088        ['activation_64[0][0]']          \n",
      "                                                                                                  \n",
      " add_23 (Add)                   (None, 32, 32, 64)   0           ['add_22[0][0]',                 \n",
      "                                                                  'conv2d_71[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_65 (BatchN  (None, 32, 32, 64)  256         ['add_23[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_65 (Activation)     (None, 32, 32, 64)   0           ['batch_normalization_65[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_72 (Conv2D)             (None, 32, 32, 16)   1040        ['activation_65[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_66 (BatchN  (None, 32, 32, 16)  64          ['conv2d_72[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_66 (Activation)     (None, 32, 32, 16)   0           ['batch_normalization_66[0][0]'] \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv2d_73 (Conv2D)             (None, 32, 32, 16)   2320        ['activation_66[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_67 (BatchN  (None, 32, 32, 16)  64          ['conv2d_73[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_67 (Activation)     (None, 32, 32, 16)   0           ['batch_normalization_67[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_74 (Conv2D)             (None, 32, 32, 64)   1088        ['activation_67[0][0]']          \n",
      "                                                                                                  \n",
      " add_24 (Add)                   (None, 32, 32, 64)   0           ['add_23[0][0]',                 \n",
      "                                                                  'conv2d_74[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_68 (BatchN  (None, 32, 32, 64)  256         ['add_24[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_68 (Activation)     (None, 32, 32, 64)   0           ['batch_normalization_68[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_75 (Conv2D)             (None, 32, 32, 16)   1040        ['activation_68[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_69 (BatchN  (None, 32, 32, 16)  64          ['conv2d_75[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_69 (Activation)     (None, 32, 32, 16)   0           ['batch_normalization_69[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_76 (Conv2D)             (None, 32, 32, 16)   2320        ['activation_69[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_70 (BatchN  (None, 32, 32, 16)  64          ['conv2d_76[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_70 (Activation)     (None, 32, 32, 16)   0           ['batch_normalization_70[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_77 (Conv2D)             (None, 32, 32, 64)   1088        ['activation_70[0][0]']          \n",
      "                                                                                                  \n",
      " add_25 (Add)                   (None, 32, 32, 64)   0           ['add_24[0][0]',                 \n",
      "                                                                  'conv2d_77[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_71 (BatchN  (None, 32, 32, 64)  256         ['add_25[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_71 (Activation)     (None, 32, 32, 64)   0           ['batch_normalization_71[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_78 (Conv2D)             (None, 32, 32, 16)   1040        ['activation_71[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_72 (BatchN  (None, 32, 32, 16)  64          ['conv2d_78[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_72 (Activation)     (None, 32, 32, 16)   0           ['batch_normalization_72[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_79 (Conv2D)             (None, 32, 32, 16)   2320        ['activation_72[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_73 (BatchN  (None, 32, 32, 16)  64          ['conv2d_79[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_73 (Activation)     (None, 32, 32, 16)   0           ['batch_normalization_73[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_80 (Conv2D)             (None, 32, 32, 64)   1088        ['activation_73[0][0]']          \n",
      "                                                                                                  \n",
      " add_26 (Add)                   (None, 32, 32, 64)   0           ['add_25[0][0]',                 \n",
      "                                                                  'conv2d_80[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_74 (BatchN  (None, 32, 32, 64)  256         ['add_26[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_74 (Activation)     (None, 32, 32, 64)   0           ['batch_normalization_74[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_81 (Conv2D)             (None, 32, 32, 16)   1040        ['activation_74[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_75 (BatchN  (None, 32, 32, 16)  64          ['conv2d_81[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_75 (Activation)     (None, 32, 32, 16)   0           ['batch_normalization_75[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_82 (Conv2D)             (None, 32, 32, 16)   2320        ['activation_75[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_76 (BatchN  (None, 32, 32, 16)  64          ['conv2d_82[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_76 (Activation)     (None, 32, 32, 16)   0           ['batch_normalization_76[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_83 (Conv2D)             (None, 32, 32, 64)   1088        ['activation_76[0][0]']          \n",
      "                                                                                                  \n",
      " add_27 (Add)                   (None, 32, 32, 64)   0           ['add_26[0][0]',                 \n",
      "                                                                  'conv2d_83[0][0]']              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " batch_normalization_77 (BatchN  (None, 32, 32, 64)  256         ['add_27[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_77 (Activation)     (None, 32, 32, 64)   0           ['batch_normalization_77[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_84 (Conv2D)             (None, 32, 32, 16)   1040        ['activation_77[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_78 (BatchN  (None, 32, 32, 16)  64          ['conv2d_84[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_78 (Activation)     (None, 32, 32, 16)   0           ['batch_normalization_78[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_85 (Conv2D)             (None, 32, 32, 16)   2320        ['activation_78[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_79 (BatchN  (None, 32, 32, 16)  64          ['conv2d_85[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_79 (Activation)     (None, 32, 32, 16)   0           ['batch_normalization_79[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_86 (Conv2D)             (None, 32, 32, 64)   1088        ['activation_79[0][0]']          \n",
      "                                                                                                  \n",
      " add_28 (Add)                   (None, 32, 32, 64)   0           ['add_27[0][0]',                 \n",
      "                                                                  'conv2d_86[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_80 (BatchN  (None, 32, 32, 64)  256         ['add_28[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_80 (Activation)     (None, 32, 32, 64)   0           ['batch_normalization_80[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_87 (Conv2D)             (None, 32, 32, 16)   1040        ['activation_80[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_81 (BatchN  (None, 32, 32, 16)  64          ['conv2d_87[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_81 (Activation)     (None, 32, 32, 16)   0           ['batch_normalization_81[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_88 (Conv2D)             (None, 32, 32, 16)   2320        ['activation_81[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_82 (BatchN  (None, 32, 32, 16)  64          ['conv2d_88[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_82 (Activation)     (None, 32, 32, 16)   0           ['batch_normalization_82[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_89 (Conv2D)             (None, 32, 32, 64)   1088        ['activation_82[0][0]']          \n",
      "                                                                                                  \n",
      " add_29 (Add)                   (None, 32, 32, 64)   0           ['add_28[0][0]',                 \n",
      "                                                                  'conv2d_89[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_83 (BatchN  (None, 32, 32, 64)  256         ['add_29[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_83 (Activation)     (None, 32, 32, 64)   0           ['batch_normalization_83[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_90 (Conv2D)             (None, 16, 16, 64)   4160        ['activation_83[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_84 (BatchN  (None, 16, 16, 64)  256         ['conv2d_90[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_84 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_84[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_91 (Conv2D)             (None, 16, 16, 64)   36928       ['activation_84[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_85 (BatchN  (None, 16, 16, 64)  256         ['conv2d_91[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_85 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_85[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_93 (Conv2D)             (None, 16, 16, 128)  8320        ['add_29[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_92 (Conv2D)             (None, 16, 16, 128)  8320        ['activation_85[0][0]']          \n",
      "                                                                                                  \n",
      " add_30 (Add)                   (None, 16, 16, 128)  0           ['conv2d_93[0][0]',              \n",
      "                                                                  'conv2d_92[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_86 (BatchN  (None, 16, 16, 128)  512        ['add_30[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_86 (Activation)     (None, 16, 16, 128)  0           ['batch_normalization_86[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_94 (Conv2D)             (None, 16, 16, 64)   8256        ['activation_86[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_87 (BatchN  (None, 16, 16, 64)  256         ['conv2d_94[0][0]']              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_87 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_87[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_95 (Conv2D)             (None, 16, 16, 64)   36928       ['activation_87[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_88 (BatchN  (None, 16, 16, 64)  256         ['conv2d_95[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_88 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_88[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_96 (Conv2D)             (None, 16, 16, 128)  8320        ['activation_88[0][0]']          \n",
      "                                                                                                  \n",
      " add_31 (Add)                   (None, 16, 16, 128)  0           ['add_30[0][0]',                 \n",
      "                                                                  'conv2d_96[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_89 (BatchN  (None, 16, 16, 128)  512        ['add_31[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_89 (Activation)     (None, 16, 16, 128)  0           ['batch_normalization_89[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_97 (Conv2D)             (None, 16, 16, 64)   8256        ['activation_89[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_90 (BatchN  (None, 16, 16, 64)  256         ['conv2d_97[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_90 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_90[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_98 (Conv2D)             (None, 16, 16, 64)   36928       ['activation_90[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_91 (BatchN  (None, 16, 16, 64)  256         ['conv2d_98[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_91 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_91[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_99 (Conv2D)             (None, 16, 16, 128)  8320        ['activation_91[0][0]']          \n",
      "                                                                                                  \n",
      " add_32 (Add)                   (None, 16, 16, 128)  0           ['add_31[0][0]',                 \n",
      "                                                                  'conv2d_99[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_92 (BatchN  (None, 16, 16, 128)  512        ['add_32[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_92 (Activation)     (None, 16, 16, 128)  0           ['batch_normalization_92[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_100 (Conv2D)            (None, 16, 16, 64)   8256        ['activation_92[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_93 (BatchN  (None, 16, 16, 64)  256         ['conv2d_100[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_93 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_93[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_101 (Conv2D)            (None, 16, 16, 64)   36928       ['activation_93[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_94 (BatchN  (None, 16, 16, 64)  256         ['conv2d_101[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_94 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_94[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_102 (Conv2D)            (None, 16, 16, 128)  8320        ['activation_94[0][0]']          \n",
      "                                                                                                  \n",
      " add_33 (Add)                   (None, 16, 16, 128)  0           ['add_32[0][0]',                 \n",
      "                                                                  'conv2d_102[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_95 (BatchN  (None, 16, 16, 128)  512        ['add_33[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_95 (Activation)     (None, 16, 16, 128)  0           ['batch_normalization_95[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_103 (Conv2D)            (None, 16, 16, 64)   8256        ['activation_95[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_96 (BatchN  (None, 16, 16, 64)  256         ['conv2d_103[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_96 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_96[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_104 (Conv2D)            (None, 16, 16, 64)   36928       ['activation_96[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_97 (BatchN  (None, 16, 16, 64)  256         ['conv2d_104[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_97 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_97[0][0]'] \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv2d_105 (Conv2D)            (None, 16, 16, 128)  8320        ['activation_97[0][0]']          \n",
      "                                                                                                  \n",
      " add_34 (Add)                   (None, 16, 16, 128)  0           ['add_33[0][0]',                 \n",
      "                                                                  'conv2d_105[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_98 (BatchN  (None, 16, 16, 128)  512        ['add_34[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_98 (Activation)     (None, 16, 16, 128)  0           ['batch_normalization_98[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_106 (Conv2D)            (None, 16, 16, 64)   8256        ['activation_98[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_99 (BatchN  (None, 16, 16, 64)  256         ['conv2d_106[0][0]']             \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_99 (Activation)     (None, 16, 16, 64)   0           ['batch_normalization_99[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_107 (Conv2D)            (None, 16, 16, 64)   36928       ['activation_99[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_100 (Batch  (None, 16, 16, 64)  256         ['conv2d_107[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_100 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_100[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_108 (Conv2D)            (None, 16, 16, 128)  8320        ['activation_100[0][0]']         \n",
      "                                                                                                  \n",
      " add_35 (Add)                   (None, 16, 16, 128)  0           ['add_34[0][0]',                 \n",
      "                                                                  'conv2d_108[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_101 (Batch  (None, 16, 16, 128)  512        ['add_35[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_101 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_101[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_109 (Conv2D)            (None, 16, 16, 64)   8256        ['activation_101[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_102 (Batch  (None, 16, 16, 64)  256         ['conv2d_109[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_102 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_102[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_110 (Conv2D)            (None, 16, 16, 64)   36928       ['activation_102[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_103 (Batch  (None, 16, 16, 64)  256         ['conv2d_110[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_103 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_103[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_111 (Conv2D)            (None, 16, 16, 128)  8320        ['activation_103[0][0]']         \n",
      "                                                                                                  \n",
      " add_36 (Add)                   (None, 16, 16, 128)  0           ['add_35[0][0]',                 \n",
      "                                                                  'conv2d_111[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_104 (Batch  (None, 16, 16, 128)  512        ['add_36[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_104 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_104[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_112 (Conv2D)            (None, 16, 16, 64)   8256        ['activation_104[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_105 (Batch  (None, 16, 16, 64)  256         ['conv2d_112[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_105 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_105[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_113 (Conv2D)            (None, 16, 16, 64)   36928       ['activation_105[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_106 (Batch  (None, 16, 16, 64)  256         ['conv2d_113[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_106 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_106[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_114 (Conv2D)            (None, 16, 16, 128)  8320        ['activation_106[0][0]']         \n",
      "                                                                                                  \n",
      " add_37 (Add)                   (None, 16, 16, 128)  0           ['add_36[0][0]',                 \n",
      "                                                                  'conv2d_114[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_107 (Batch  (None, 16, 16, 128)  512        ['add_37[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_107 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_107[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_115 (Conv2D)            (None, 16, 16, 64)   8256        ['activation_107[0][0]']         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " batch_normalization_108 (Batch  (None, 16, 16, 64)  256         ['conv2d_115[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_108 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_108[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_116 (Conv2D)            (None, 16, 16, 64)   36928       ['activation_108[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_109 (Batch  (None, 16, 16, 64)  256         ['conv2d_116[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_109 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_109[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_117 (Conv2D)            (None, 16, 16, 128)  8320        ['activation_109[0][0]']         \n",
      "                                                                                                  \n",
      " add_38 (Add)                   (None, 16, 16, 128)  0           ['add_37[0][0]',                 \n",
      "                                                                  'conv2d_117[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_110 (Batch  (None, 16, 16, 128)  512        ['add_38[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_110 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_110[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_118 (Conv2D)            (None, 16, 16, 64)   8256        ['activation_110[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_111 (Batch  (None, 16, 16, 64)  256         ['conv2d_118[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_111 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_111[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_119 (Conv2D)            (None, 16, 16, 64)   36928       ['activation_111[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_112 (Batch  (None, 16, 16, 64)  256         ['conv2d_119[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_112 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_112[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_120 (Conv2D)            (None, 16, 16, 128)  8320        ['activation_112[0][0]']         \n",
      "                                                                                                  \n",
      " add_39 (Add)                   (None, 16, 16, 128)  0           ['add_38[0][0]',                 \n",
      "                                                                  'conv2d_120[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_113 (Batch  (None, 16, 16, 128)  512        ['add_39[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_113 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_113[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_121 (Conv2D)            (None, 16, 16, 64)   8256        ['activation_113[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_114 (Batch  (None, 16, 16, 64)  256         ['conv2d_121[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_114 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_114[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_122 (Conv2D)            (None, 16, 16, 64)   36928       ['activation_114[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_115 (Batch  (None, 16, 16, 64)  256         ['conv2d_122[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_115 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_115[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_123 (Conv2D)            (None, 16, 16, 128)  8320        ['activation_115[0][0]']         \n",
      "                                                                                                  \n",
      " add_40 (Add)                   (None, 16, 16, 128)  0           ['add_39[0][0]',                 \n",
      "                                                                  'conv2d_123[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_116 (Batch  (None, 16, 16, 128)  512        ['add_40[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_116 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_116[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_124 (Conv2D)            (None, 16, 16, 64)   8256        ['activation_116[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_117 (Batch  (None, 16, 16, 64)  256         ['conv2d_124[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_117 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_117[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_125 (Conv2D)            (None, 16, 16, 64)   36928       ['activation_117[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_118 (Batch  (None, 16, 16, 64)  256         ['conv2d_125[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " activation_118 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_118[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_126 (Conv2D)            (None, 16, 16, 128)  8320        ['activation_118[0][0]']         \n",
      "                                                                                                  \n",
      " add_41 (Add)                   (None, 16, 16, 128)  0           ['add_40[0][0]',                 \n",
      "                                                                  'conv2d_126[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_119 (Batch  (None, 16, 16, 128)  512        ['add_41[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_119 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_119[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_127 (Conv2D)            (None, 8, 8, 128)    16512       ['activation_119[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_120 (Batch  (None, 8, 8, 128)   512         ['conv2d_127[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_120 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_120[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_128 (Conv2D)            (None, 8, 8, 128)    147584      ['activation_120[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_121 (Batch  (None, 8, 8, 128)   512         ['conv2d_128[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_121 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_121[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_130 (Conv2D)            (None, 8, 8, 256)    33024       ['add_41[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_129 (Conv2D)            (None, 8, 8, 256)    33024       ['activation_121[0][0]']         \n",
      "                                                                                                  \n",
      " add_42 (Add)                   (None, 8, 8, 256)    0           ['conv2d_130[0][0]',             \n",
      "                                                                  'conv2d_129[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_122 (Batch  (None, 8, 8, 256)   1024        ['add_42[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_122 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_122[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_131 (Conv2D)            (None, 8, 8, 128)    32896       ['activation_122[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_123 (Batch  (None, 8, 8, 128)   512         ['conv2d_131[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_123 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_123[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_132 (Conv2D)            (None, 8, 8, 128)    147584      ['activation_123[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_124 (Batch  (None, 8, 8, 128)   512         ['conv2d_132[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_124 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_124[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_133 (Conv2D)            (None, 8, 8, 256)    33024       ['activation_124[0][0]']         \n",
      "                                                                                                  \n",
      " add_43 (Add)                   (None, 8, 8, 256)    0           ['add_42[0][0]',                 \n",
      "                                                                  'conv2d_133[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_125 (Batch  (None, 8, 8, 256)   1024        ['add_43[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_125 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_125[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_134 (Conv2D)            (None, 8, 8, 128)    32896       ['activation_125[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_126 (Batch  (None, 8, 8, 128)   512         ['conv2d_134[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_126 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_126[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_135 (Conv2D)            (None, 8, 8, 128)    147584      ['activation_126[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_127 (Batch  (None, 8, 8, 128)   512         ['conv2d_135[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_127 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_127[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_136 (Conv2D)            (None, 8, 8, 256)    33024       ['activation_127[0][0]']         \n",
      "                                                                                                  \n",
      " add_44 (Add)                   (None, 8, 8, 256)    0           ['add_43[0][0]',                 \n",
      "                                                                  'conv2d_136[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_128 (Batch  (None, 8, 8, 256)   1024        ['add_44[0][0]']                 \n",
      " Normalization)                                                                                   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " activation_128 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_128[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_137 (Conv2D)            (None, 8, 8, 128)    32896       ['activation_128[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_129 (Batch  (None, 8, 8, 128)   512         ['conv2d_137[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_129 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_129[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_138 (Conv2D)            (None, 8, 8, 128)    147584      ['activation_129[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_130 (Batch  (None, 8, 8, 128)   512         ['conv2d_138[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_130 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_130[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_139 (Conv2D)            (None, 8, 8, 256)    33024       ['activation_130[0][0]']         \n",
      "                                                                                                  \n",
      " add_45 (Add)                   (None, 8, 8, 256)    0           ['add_44[0][0]',                 \n",
      "                                                                  'conv2d_139[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_131 (Batch  (None, 8, 8, 256)   1024        ['add_45[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_131 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_131[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_140 (Conv2D)            (None, 8, 8, 128)    32896       ['activation_131[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_132 (Batch  (None, 8, 8, 128)   512         ['conv2d_140[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_132 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_132[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_141 (Conv2D)            (None, 8, 8, 128)    147584      ['activation_132[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_133 (Batch  (None, 8, 8, 128)   512         ['conv2d_141[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_133 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_133[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_142 (Conv2D)            (None, 8, 8, 256)    33024       ['activation_133[0][0]']         \n",
      "                                                                                                  \n",
      " add_46 (Add)                   (None, 8, 8, 256)    0           ['add_45[0][0]',                 \n",
      "                                                                  'conv2d_142[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_134 (Batch  (None, 8, 8, 256)   1024        ['add_46[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_134 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_134[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_143 (Conv2D)            (None, 8, 8, 128)    32896       ['activation_134[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_135 (Batch  (None, 8, 8, 128)   512         ['conv2d_143[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_135 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_135[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_144 (Conv2D)            (None, 8, 8, 128)    147584      ['activation_135[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_136 (Batch  (None, 8, 8, 128)   512         ['conv2d_144[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_136 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_136[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_145 (Conv2D)            (None, 8, 8, 256)    33024       ['activation_136[0][0]']         \n",
      "                                                                                                  \n",
      " add_47 (Add)                   (None, 8, 8, 256)    0           ['add_46[0][0]',                 \n",
      "                                                                  'conv2d_145[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_137 (Batch  (None, 8, 8, 256)   1024        ['add_47[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_137 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_137[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_146 (Conv2D)            (None, 8, 8, 128)    32896       ['activation_137[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_138 (Batch  (None, 8, 8, 128)   512         ['conv2d_146[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_138 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_138[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_147 (Conv2D)            (None, 8, 8, 128)    147584      ['activation_138[0][0]']         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " batch_normalization_139 (Batch  (None, 8, 8, 128)   512         ['conv2d_147[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_139 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_139[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_148 (Conv2D)            (None, 8, 8, 256)    33024       ['activation_139[0][0]']         \n",
      "                                                                                                  \n",
      " add_48 (Add)                   (None, 8, 8, 256)    0           ['add_47[0][0]',                 \n",
      "                                                                  'conv2d_148[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_140 (Batch  (None, 8, 8, 256)   1024        ['add_48[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_140 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_140[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_149 (Conv2D)            (None, 8, 8, 128)    32896       ['activation_140[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_141 (Batch  (None, 8, 8, 128)   512         ['conv2d_149[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_141 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_141[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_150 (Conv2D)            (None, 8, 8, 128)    147584      ['activation_141[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_142 (Batch  (None, 8, 8, 128)   512         ['conv2d_150[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_142 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_142[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_151 (Conv2D)            (None, 8, 8, 256)    33024       ['activation_142[0][0]']         \n",
      "                                                                                                  \n",
      " add_49 (Add)                   (None, 8, 8, 256)    0           ['add_48[0][0]',                 \n",
      "                                                                  'conv2d_151[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_143 (Batch  (None, 8, 8, 256)   1024        ['add_49[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_143 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_143[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_152 (Conv2D)            (None, 8, 8, 128)    32896       ['activation_143[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_144 (Batch  (None, 8, 8, 128)   512         ['conv2d_152[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_144 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_144[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_153 (Conv2D)            (None, 8, 8, 128)    147584      ['activation_144[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_145 (Batch  (None, 8, 8, 128)   512         ['conv2d_153[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_145 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_145[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_154 (Conv2D)            (None, 8, 8, 256)    33024       ['activation_145[0][0]']         \n",
      "                                                                                                  \n",
      " add_50 (Add)                   (None, 8, 8, 256)    0           ['add_49[0][0]',                 \n",
      "                                                                  'conv2d_154[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_146 (Batch  (None, 8, 8, 256)   1024        ['add_50[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_146 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_146[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_155 (Conv2D)            (None, 8, 8, 128)    32896       ['activation_146[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_147 (Batch  (None, 8, 8, 128)   512         ['conv2d_155[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_147 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_147[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_156 (Conv2D)            (None, 8, 8, 128)    147584      ['activation_147[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_148 (Batch  (None, 8, 8, 128)   512         ['conv2d_156[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_148 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_148[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_157 (Conv2D)            (None, 8, 8, 256)    33024       ['activation_148[0][0]']         \n",
      "                                                                                                  \n",
      " add_51 (Add)                   (None, 8, 8, 256)    0           ['add_50[0][0]',                 \n",
      "                                                                  'conv2d_157[0][0]']             \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_normalization_149 (Batch  (None, 8, 8, 256)   1024        ['add_51[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_149 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_149[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_158 (Conv2D)            (None, 8, 8, 128)    32896       ['activation_149[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_150 (Batch  (None, 8, 8, 128)   512         ['conv2d_158[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_150 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_150[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_159 (Conv2D)            (None, 8, 8, 128)    147584      ['activation_150[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_151 (Batch  (None, 8, 8, 128)   512         ['conv2d_159[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_151 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_151[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_160 (Conv2D)            (None, 8, 8, 256)    33024       ['activation_151[0][0]']         \n",
      "                                                                                                  \n",
      " add_52 (Add)                   (None, 8, 8, 256)    0           ['add_51[0][0]',                 \n",
      "                                                                  'conv2d_160[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_152 (Batch  (None, 8, 8, 256)   1024        ['add_52[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_152 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_152[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_161 (Conv2D)            (None, 8, 8, 128)    32896       ['activation_152[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_153 (Batch  (None, 8, 8, 128)   512         ['conv2d_161[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_153 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_153[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_162 (Conv2D)            (None, 8, 8, 128)    147584      ['activation_153[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_154 (Batch  (None, 8, 8, 128)   512         ['conv2d_162[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_154 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_154[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_163 (Conv2D)            (None, 8, 8, 256)    33024       ['activation_154[0][0]']         \n",
      "                                                                                                  \n",
      " add_53 (Add)                   (None, 8, 8, 256)    0           ['add_52[0][0]',                 \n",
      "                                                                  'conv2d_163[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_155 (Batch  (None, 8, 8, 256)   1024        ['add_53[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_155 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_155[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_2 (AveragePo  (None, 1, 1, 256)   0           ['activation_155[0][0]']         \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)            (None, 256)          0           ['average_pooling2d_2[0][0]']    \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 10)           2570        ['flatten_2[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,323,210\n",
      "Trainable params: 3,302,442\n",
      "Non-trainable params: 20,768\n",
      "__________________________________________________________________________________________________\n",
      "ResNet110v2\n",
      "Using real-time data augmentation.\n",
      "Learning rate:  0.001\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yue\\AppData\\Local\\Temp\\ipykernel_5076\\1903444969.py:374: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - ETA: 0s - loss: 2.3808 - accuracy: 0.5014WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 71s 42ms/step - loss: 2.3808 - accuracy: 0.5014 - val_loss: 1.9185 - val_accuracy: 0.5289 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 2/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 1.5145 - accuracy: 0.6346WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 1.5145 - accuracy: 0.6346 - val_loss: 1.4265 - val_accuracy: 0.6430 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 3/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 1.2845 - accuracy: 0.6921WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 1.2845 - accuracy: 0.6921 - val_loss: 1.3753 - val_accuracy: 0.6545 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 4/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 1.1562 - accuracy: 0.7231WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 1.1560 - accuracy: 0.7231 - val_loss: 1.9331 - val_accuracy: 0.5481 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 5/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 1.0682 - accuracy: 0.7506WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 63s 40ms/step - loss: 1.0682 - accuracy: 0.7506 - val_loss: 1.4019 - val_accuracy: 0.6601 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 6/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 1.0044 - accuracy: 0.7666WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 1.0043 - accuracy: 0.7667 - val_loss: 1.3135 - val_accuracy: 0.6806 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 7/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.9486 - accuracy: 0.7832WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 41ms/step - loss: 0.9486 - accuracy: 0.7832 - val_loss: 1.5701 - val_accuracy: 0.5961 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 8/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.9017 - accuracy: 0.7917WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.9017 - accuracy: 0.7917 - val_loss: 0.9801 - val_accuracy: 0.7704 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 9/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.8632 - accuracy: 0.8033WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 63s 40ms/step - loss: 0.8633 - accuracy: 0.8033 - val_loss: 1.0122 - val_accuracy: 0.7567 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 10/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.8372 - accuracy: 0.8112WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 41ms/step - loss: 0.8372 - accuracy: 0.8112 - val_loss: 1.3863 - val_accuracy: 0.6804 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 11/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.8103 - accuracy: 0.8167WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 63s 40ms/step - loss: 0.8101 - accuracy: 0.8167 - val_loss: 1.0285 - val_accuracy: 0.7497 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 12/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.7864 - accuracy: 0.8244WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.7864 - accuracy: 0.8244 - val_loss: 1.0014 - val_accuracy: 0.7666 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 13/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.7592 - accuracy: 0.8296WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 62s 40ms/step - loss: 0.7591 - accuracy: 0.8297 - val_loss: 0.9565 - val_accuracy: 0.7664 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 14/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.7430 - accuracy: 0.8343WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.7431 - accuracy: 0.8343 - val_loss: 1.0385 - val_accuracy: 0.7706 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 15/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.7263 - accuracy: 0.8389WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.7263 - accuracy: 0.8389 - val_loss: 0.9345 - val_accuracy: 0.7770 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 16/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.7118 - accuracy: 0.8437WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 62s 40ms/step - loss: 0.7118 - accuracy: 0.8437 - val_loss: 0.9151 - val_accuracy: 0.7920 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 17/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6951 - accuracy: 0.8472WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.6951 - accuracy: 0.8472 - val_loss: 0.8892 - val_accuracy: 0.7880 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 18/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.6862 - accuracy: 0.8487WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 0.6861 - accuracy: 0.8487 - val_loss: 0.9294 - val_accuracy: 0.7798 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 19/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6692 - accuracy: 0.8551WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.6692 - accuracy: 0.8551 - val_loss: 1.4063 - val_accuracy: 0.6963 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 20/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.6646 - accuracy: 0.8539WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 63s 40ms/step - loss: 0.6647 - accuracy: 0.8539 - val_loss: 0.9848 - val_accuracy: 0.7698 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 21/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.6496 - accuracy: 0.8575WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 63s 40ms/step - loss: 0.6494 - accuracy: 0.8576 - val_loss: 0.8163 - val_accuracy: 0.8146 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 22/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.6461 - accuracy: 0.8596WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.6462 - accuracy: 0.8596 - val_loss: 1.0984 - val_accuracy: 0.7254 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 23/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.6315 - accuracy: 0.8650WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 0.6315 - accuracy: 0.8650 - val_loss: 1.2574 - val_accuracy: 0.7042 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 24/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.6244 - accuracy: 0.8653WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 63s 40ms/step - loss: 0.6243 - accuracy: 0.8654 - val_loss: 0.8016 - val_accuracy: 0.8295 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Epoch 25/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6180 - accuracy: 0.8679WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 41ms/step - loss: 0.6180 - accuracy: 0.8679 - val_loss: 0.8620 - val_accuracy: 0.8038 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 26/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.6124 - accuracy: 0.8703WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.6126 - accuracy: 0.8702 - val_loss: 0.8176 - val_accuracy: 0.8098 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 27/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6043 - accuracy: 0.8718WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 41ms/step - loss: 0.6043 - accuracy: 0.8718 - val_loss: 1.0879 - val_accuracy: 0.7483 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 28/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.6024 - accuracy: 0.8722WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.6023 - accuracy: 0.8722 - val_loss: 0.8113 - val_accuracy: 0.8105 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 29/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5958 - accuracy: 0.8729WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.5958 - accuracy: 0.8729 - val_loss: 1.1977 - val_accuracy: 0.7331 - lr: 3.1623e-04\n",
      "Learning rate:  0.001\n",
      "Epoch 30/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5871 - accuracy: 0.8761WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.5871 - accuracy: 0.8761 - val_loss: 0.7902 - val_accuracy: 0.8167 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 31/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5817 - accuracy: 0.8768WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 63s 40ms/step - loss: 0.5817 - accuracy: 0.8768 - val_loss: 0.7979 - val_accuracy: 0.8136 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 32/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5707 - accuracy: 0.8795WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 0.5707 - accuracy: 0.8795 - val_loss: 1.0229 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 33/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5721 - accuracy: 0.8802WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.5720 - accuracy: 0.8803 - val_loss: 0.7336 - val_accuracy: 0.8305 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 34/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5716 - accuracy: 0.8803WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.5716 - accuracy: 0.8803 - val_loss: 0.8430 - val_accuracy: 0.7988 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 35/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5654 - accuracy: 0.8817WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 62s 40ms/step - loss: 0.5654 - accuracy: 0.8816 - val_loss: 0.9214 - val_accuracy: 0.7919 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 36/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5594 - accuracy: 0.8841WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.5594 - accuracy: 0.8841 - val_loss: 0.8481 - val_accuracy: 0.8104 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 37/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5546 - accuracy: 0.8845WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 62s 40ms/step - loss: 0.5546 - accuracy: 0.8845 - val_loss: 0.9824 - val_accuracy: 0.7862 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 38/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5595 - accuracy: 0.8831WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.5595 - accuracy: 0.8831 - val_loss: 0.7297 - val_accuracy: 0.8373 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 39/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5515 - accuracy: 0.8851WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 62s 40ms/step - loss: 0.5515 - accuracy: 0.8851 - val_loss: 0.9221 - val_accuracy: 0.7887 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 40/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5467 - accuracy: 0.8862WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.5467 - accuracy: 0.8863 - val_loss: 1.1626 - val_accuracy: 0.7483 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 41/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5410 - accuracy: 0.8883WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.5409 - accuracy: 0.8883 - val_loss: 0.7624 - val_accuracy: 0.8250 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 42/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5405 - accuracy: 0.8885WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.5405 - accuracy: 0.8886 - val_loss: 0.9810 - val_accuracy: 0.7869 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 43/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5349 - accuracy: 0.8903WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 62s 40ms/step - loss: 0.5349 - accuracy: 0.8903 - val_loss: 1.0029 - val_accuracy: 0.7656 - lr: 3.1623e-04\n",
      "Learning rate:  0.001\n",
      "Epoch 44/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5351 - accuracy: 0.8885WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 63s 40ms/step - loss: 0.5351 - accuracy: 0.8885 - val_loss: 0.8307 - val_accuracy: 0.8060 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 45/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5295 - accuracy: 0.8915WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 62s 40ms/step - loss: 0.5296 - accuracy: 0.8915 - val_loss: 0.6893 - val_accuracy: 0.8422 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 46/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5305 - accuracy: 0.8918WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 62s 39ms/step - loss: 0.5306 - accuracy: 0.8917 - val_loss: 0.7876 - val_accuracy: 0.8261 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 47/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5263 - accuracy: 0.8930WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.5263 - accuracy: 0.8930 - val_loss: 0.8194 - val_accuracy: 0.8089 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 48/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5233 - accuracy: 0.8937WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.5234 - accuracy: 0.8936 - val_loss: 0.8938 - val_accuracy: 0.8021 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Epoch 49/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5196 - accuracy: 0.8944WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.5196 - accuracy: 0.8944 - val_loss: 1.1966 - val_accuracy: 0.7342 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 50/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5171 - accuracy: 0.8958WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 63s 40ms/step - loss: 0.5171 - accuracy: 0.8958 - val_loss: 0.8065 - val_accuracy: 0.8102 - lr: 3.1623e-04\n",
      "Learning rate:  0.001\n",
      "Epoch 51/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5137 - accuracy: 0.8949WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.5136 - accuracy: 0.8949 - val_loss: 1.2854 - val_accuracy: 0.7154 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 52/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5124 - accuracy: 0.8966WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.5124 - accuracy: 0.8966 - val_loss: 0.9731 - val_accuracy: 0.7778 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 53/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5067 - accuracy: 0.8991WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.5066 - accuracy: 0.8991 - val_loss: 0.8431 - val_accuracy: 0.8023 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 54/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5126 - accuracy: 0.8972WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.5126 - accuracy: 0.8972 - val_loss: 1.0383 - val_accuracy: 0.7693 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 55/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5069 - accuracy: 0.8975WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.5068 - accuracy: 0.8976 - val_loss: 0.9312 - val_accuracy: 0.7960 - lr: 3.1623e-04\n",
      "Learning rate:  0.001\n",
      "Epoch 56/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5053 - accuracy: 0.8986WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 0.5052 - accuracy: 0.8986 - val_loss: 1.5006 - val_accuracy: 0.6695 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 57/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5014 - accuracy: 0.8998WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 0.5015 - accuracy: 0.8998 - val_loss: 0.7720 - val_accuracy: 0.8160 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 58/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5031 - accuracy: 0.8977WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 43ms/step - loss: 0.5031 - accuracy: 0.8976 - val_loss: 0.6392 - val_accuracy: 0.8570 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 59/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.4991 - accuracy: 0.8984WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.4991 - accuracy: 0.8983 - val_loss: 1.2645 - val_accuracy: 0.7308 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 60/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.4975 - accuracy: 0.8998WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 0.4975 - accuracy: 0.8998 - val_loss: 0.8788 - val_accuracy: 0.7892 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 61/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.4937 - accuracy: 0.9004WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.4936 - accuracy: 0.9004 - val_loss: 0.7293 - val_accuracy: 0.8289 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 62/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.4908 - accuracy: 0.9014WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 0.4909 - accuracy: 0.9014 - val_loss: 1.0277 - val_accuracy: 0.7751 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 63/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4913 - accuracy: 0.9021WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.4913 - accuracy: 0.9021 - val_loss: 0.8915 - val_accuracy: 0.7877 - lr: 3.1623e-04\n",
      "Learning rate:  0.001\n",
      "Epoch 64/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.4911 - accuracy: 0.9015WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 41ms/step - loss: 0.4909 - accuracy: 0.9015 - val_loss: 1.5898 - val_accuracy: 0.6868 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 65/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.4867 - accuracy: 0.9034WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.4866 - accuracy: 0.9035 - val_loss: 0.9146 - val_accuracy: 0.8014 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 66/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.4853 - accuracy: 0.9026WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 41ms/step - loss: 0.4853 - accuracy: 0.9026 - val_loss: 0.7233 - val_accuracy: 0.8378 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 67/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.4861 - accuracy: 0.9037WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 63s 40ms/step - loss: 0.4862 - accuracy: 0.9037 - val_loss: 1.3095 - val_accuracy: 0.7141 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 68/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.4832 - accuracy: 0.9033WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.4833 - accuracy: 0.9033 - val_loss: 1.3631 - val_accuracy: 0.7244 - lr: 3.1623e-04\n",
      "Learning rate:  0.001\n",
      "Epoch 69/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.4816 - accuracy: 0.9049WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 63s 40ms/step - loss: 0.4818 - accuracy: 0.9048 - val_loss: 0.8976 - val_accuracy: 0.7974 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 70/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4793 - accuracy: 0.9047WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 0.4793 - accuracy: 0.9047 - val_loss: 0.7696 - val_accuracy: 0.8261 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 71/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.4769 - accuracy: 0.9055WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 43ms/step - loss: 0.4769 - accuracy: 0.9055 - val_loss: 1.1674 - val_accuracy: 0.7368 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 72/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4764 - accuracy: 0.9064WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 62s 40ms/step - loss: 0.4764 - accuracy: 0.9064 - val_loss: 1.1584 - val_accuracy: 0.7460 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 73/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.4732 - accuracy: 0.9064WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.4732 - accuracy: 0.9064 - val_loss: 1.0365 - val_accuracy: 0.7850 - lr: 3.1623e-04\n",
      "Learning rate:  0.001\n",
      "Epoch 74/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4773 - accuracy: 0.9041WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.4773 - accuracy: 0.9041 - val_loss: 1.0962 - val_accuracy: 0.7555 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 75/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.4737 - accuracy: 0.9089WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.4738 - accuracy: 0.9089 - val_loss: 1.2324 - val_accuracy: 0.7272 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 76/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4655 - accuracy: 0.9097WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 63s 40ms/step - loss: 0.4655 - accuracy: 0.9097 - val_loss: 1.0088 - val_accuracy: 0.7695 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 77/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.4741 - accuracy: 0.9054WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 0.4742 - accuracy: 0.9054 - val_loss: 0.7565 - val_accuracy: 0.8204 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 78/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.4680 - accuracy: 0.9091WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 62s 40ms/step - loss: 0.4681 - accuracy: 0.9091 - val_loss: 0.7899 - val_accuracy: 0.8193 - lr: 3.1623e-04\n",
      "Learning rate:  0.001\n",
      "Epoch 79/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.4662 - accuracy: 0.9085WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 41ms/step - loss: 0.4661 - accuracy: 0.9086 - val_loss: 1.3604 - val_accuracy: 0.7069 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 80/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.4708 - accuracy: 0.9059WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 61s 39ms/step - loss: 0.4707 - accuracy: 0.9060 - val_loss: 1.3626 - val_accuracy: 0.7198 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 81/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.4664 - accuracy: 0.9094WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.4663 - accuracy: 0.9095 - val_loss: 1.2363 - val_accuracy: 0.7267 - lr: 0.0010\n",
      "Learning rate:  0.0001\n",
      "Epoch 82/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.3830 - accuracy: 0.9369WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.3830 - accuracy: 0.9369 - val_loss: 0.4755 - val_accuracy: 0.9084 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 83/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.3510 - accuracy: 0.9464WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.3510 - accuracy: 0.9465 - val_loss: 0.4465 - val_accuracy: 0.9157 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 84/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.3347 - accuracy: 0.9506WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.3347 - accuracy: 0.9506 - val_loss: 0.4529 - val_accuracy: 0.9156 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 85/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.3203 - accuracy: 0.9551WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.3202 - accuracy: 0.9551 - val_loss: 0.4382 - val_accuracy: 0.9183 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 86/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.3132 - accuracy: 0.9567WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.3131 - accuracy: 0.9568 - val_loss: 0.4373 - val_accuracy: 0.9154 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 87/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.3052 - accuracy: 0.9572WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 0.3051 - accuracy: 0.9572 - val_loss: 0.4401 - val_accuracy: 0.9173 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 88/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2978 - accuracy: 0.9590WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.2979 - accuracy: 0.9589 - val_loss: 0.4438 - val_accuracy: 0.9161 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 89/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2910 - accuracy: 0.9612WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.2910 - accuracy: 0.9612 - val_loss: 0.4365 - val_accuracy: 0.9164 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 90/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2866 - accuracy: 0.9620WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.2867 - accuracy: 0.9620 - val_loss: 0.4283 - val_accuracy: 0.9169 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 91/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2788 - accuracy: 0.9636WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.2788 - accuracy: 0.9635 - val_loss: 0.4541 - val_accuracy: 0.9125 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 92/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2759 - accuracy: 0.9635WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.2759 - accuracy: 0.9635 - val_loss: 0.4270 - val_accuracy: 0.9173 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 93/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2696 - accuracy: 0.9649WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.2696 - accuracy: 0.9649 - val_loss: 0.4254 - val_accuracy: 0.9196 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 94/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2655 - accuracy: 0.9672WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.2655 - accuracy: 0.9672 - val_loss: 0.4269 - val_accuracy: 0.9167 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 95/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2611 - accuracy: 0.9668WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.2611 - accuracy: 0.9668 - val_loss: 0.4544 - val_accuracy: 0.9132 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.0001\n",
      "Epoch 96/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2554 - accuracy: 0.9677WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 41ms/step - loss: 0.2555 - accuracy: 0.9676 - val_loss: 0.4413 - val_accuracy: 0.9166 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 97/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2536 - accuracy: 0.9676WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.2536 - accuracy: 0.9676 - val_loss: 0.4363 - val_accuracy: 0.9188 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 98/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2477 - accuracy: 0.9693WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.2477 - accuracy: 0.9693 - val_loss: 0.4365 - val_accuracy: 0.9163 - lr: 3.1623e-05\n",
      "Learning rate:  0.0001\n",
      "Epoch 99/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2451 - accuracy: 0.9698WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.2451 - accuracy: 0.9698 - val_loss: 0.4285 - val_accuracy: 0.9193 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 100/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2423 - accuracy: 0.9701WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 0.2423 - accuracy: 0.9701 - val_loss: 0.4389 - val_accuracy: 0.9195 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 101/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2375 - accuracy: 0.9714WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 0.2375 - accuracy: 0.9714 - val_loss: 0.4272 - val_accuracy: 0.9209 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 102/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2373 - accuracy: 0.9707WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 0.2373 - accuracy: 0.9707 - val_loss: 0.4282 - val_accuracy: 0.9202 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 103/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2337 - accuracy: 0.9709WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.2337 - accuracy: 0.9709 - val_loss: 0.4420 - val_accuracy: 0.9144 - lr: 3.1623e-05\n",
      "Learning rate:  0.0001\n",
      "Epoch 104/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2300 - accuracy: 0.9724WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.2300 - accuracy: 0.9724 - val_loss: 0.4282 - val_accuracy: 0.9200 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 105/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2274 - accuracy: 0.9734WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.2274 - accuracy: 0.9734 - val_loss: 0.4278 - val_accuracy: 0.9187 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 106/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2222 - accuracy: 0.9748WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 0.2223 - accuracy: 0.9747 - val_loss: 0.4272 - val_accuracy: 0.9179 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 107/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2210 - accuracy: 0.9741WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 0.2210 - accuracy: 0.9741 - val_loss: 0.4272 - val_accuracy: 0.9173 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 108/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2203 - accuracy: 0.9740WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 43ms/step - loss: 0.2203 - accuracy: 0.9740 - val_loss: 0.4312 - val_accuracy: 0.9196 - lr: 3.1623e-05\n",
      "Learning rate:  0.0001\n",
      "Epoch 109/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2148 - accuracy: 0.9759WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 0.2148 - accuracy: 0.9759 - val_loss: 0.4319 - val_accuracy: 0.9204 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 110/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2136 - accuracy: 0.9748WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.2136 - accuracy: 0.9748 - val_loss: 0.4149 - val_accuracy: 0.9222 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 111/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2114 - accuracy: 0.9756WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.2115 - accuracy: 0.9756 - val_loss: 0.4607 - val_accuracy: 0.9135 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 112/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2109 - accuracy: 0.9750WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.2109 - accuracy: 0.9750 - val_loss: 0.4197 - val_accuracy: 0.9200 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 113/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2071 - accuracy: 0.9767WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 0.2071 - accuracy: 0.9767 - val_loss: 0.4235 - val_accuracy: 0.9197 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 114/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2039 - accuracy: 0.9775WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 0.2039 - accuracy: 0.9775 - val_loss: 0.4240 - val_accuracy: 0.9155 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 115/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2053 - accuracy: 0.9762WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.2053 - accuracy: 0.9762 - val_loss: 0.4396 - val_accuracy: 0.9164 - lr: 3.1623e-05\n",
      "Learning rate:  0.0001\n",
      "Epoch 116/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2012 - accuracy: 0.9766WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.2012 - accuracy: 0.9766 - val_loss: 0.4491 - val_accuracy: 0.9112 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 117/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1991 - accuracy: 0.9779WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 0.1991 - accuracy: 0.9779 - val_loss: 0.4447 - val_accuracy: 0.9146 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 118/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1967 - accuracy: 0.9778WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 0.1967 - accuracy: 0.9778 - val_loss: 0.4635 - val_accuracy: 0.9122 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 119/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1952 - accuracy: 0.9779WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1952 - accuracy: 0.9779 - val_loss: 0.4425 - val_accuracy: 0.9160 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 120/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1944 - accuracy: 0.9783WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1944 - accuracy: 0.9783 - val_loss: 0.4429 - val_accuracy: 0.9162 - lr: 3.1623e-05\n",
      "Learning rate:  0.0001\n",
      "Epoch 121/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1933 - accuracy: 0.9787WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1933 - accuracy: 0.9787 - val_loss: 0.4319 - val_accuracy: 0.9177 - lr: 1.0000e-04\n",
      "Learning rate:  1e-05\n",
      "Epoch 122/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1865 - accuracy: 0.9809WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 0.1865 - accuracy: 0.9809 - val_loss: 0.4091 - val_accuracy: 0.9238 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 123/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1815 - accuracy: 0.9825WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 41ms/step - loss: 0.1815 - accuracy: 0.9824 - val_loss: 0.4072 - val_accuracy: 0.9240 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 124/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1798 - accuracy: 0.9836WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 0.1798 - accuracy: 0.9836 - val_loss: 0.4078 - val_accuracy: 0.9243 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 125/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1788 - accuracy: 0.9831WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1788 - accuracy: 0.9831 - val_loss: 0.4101 - val_accuracy: 0.9232 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 126/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1774 - accuracy: 0.9848WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1774 - accuracy: 0.9848 - val_loss: 0.4115 - val_accuracy: 0.9239 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 127/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1776 - accuracy: 0.9841WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 0.1776 - accuracy: 0.9841 - val_loss: 0.4064 - val_accuracy: 0.9242 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 128/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1743 - accuracy: 0.9855WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1743 - accuracy: 0.9855 - val_loss: 0.4097 - val_accuracy: 0.9236 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 129/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1761 - accuracy: 0.9844WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 0.1763 - accuracy: 0.9843 - val_loss: 0.4085 - val_accuracy: 0.9247 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 130/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1744 - accuracy: 0.9852WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1744 - accuracy: 0.9852 - val_loss: 0.4094 - val_accuracy: 0.9245 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 131/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1758 - accuracy: 0.9839WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1758 - accuracy: 0.9839 - val_loss: 0.4072 - val_accuracy: 0.9246 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 132/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1735 - accuracy: 0.9854WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1735 - accuracy: 0.9854 - val_loss: 0.4091 - val_accuracy: 0.9242 - lr: 3.1623e-06\n",
      "Learning rate:  1e-05\n",
      "Epoch 133/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1722 - accuracy: 0.9861WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1722 - accuracy: 0.9861 - val_loss: 0.4075 - val_accuracy: 0.9242 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 134/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1710 - accuracy: 0.9862WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 0.1710 - accuracy: 0.9862 - val_loss: 0.4102 - val_accuracy: 0.9242 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 135/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1726 - accuracy: 0.9851WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1726 - accuracy: 0.9851 - val_loss: 0.4130 - val_accuracy: 0.9240 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 136/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1716 - accuracy: 0.9861WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1716 - accuracy: 0.9861 - val_loss: 0.4107 - val_accuracy: 0.9228 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 137/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1704 - accuracy: 0.9862WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1704 - accuracy: 0.9862 - val_loss: 0.4112 - val_accuracy: 0.9242 - lr: 3.1623e-06\n",
      "Learning rate:  1e-05\n",
      "Epoch 138/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1714 - accuracy: 0.9860WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1714 - accuracy: 0.9860 - val_loss: 0.4091 - val_accuracy: 0.9236 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 139/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1701 - accuracy: 0.9862WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 0.1701 - accuracy: 0.9862 - val_loss: 0.4148 - val_accuracy: 0.9236 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 140/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1717 - accuracy: 0.9856WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 0.1717 - accuracy: 0.9856 - val_loss: 0.4116 - val_accuracy: 0.9221 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 141/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1686 - accuracy: 0.9867WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1686 - accuracy: 0.9867 - val_loss: 0.4128 - val_accuracy: 0.9232 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 142/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1694 - accuracy: 0.9868WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1694 - accuracy: 0.9868 - val_loss: 0.4133 - val_accuracy: 0.9246 - lr: 3.1623e-06\n",
      "Learning rate:  1e-05\n",
      "Epoch 143/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1692 - accuracy: 0.9859WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1692 - accuracy: 0.9859 - val_loss: 0.4168 - val_accuracy: 0.9236 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 144/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1677 - accuracy: 0.9871WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 63s 40ms/step - loss: 0.1677 - accuracy: 0.9871 - val_loss: 0.4153 - val_accuracy: 0.9239 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 145/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1682 - accuracy: 0.9861WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 41ms/step - loss: 0.1682 - accuracy: 0.9861 - val_loss: 0.4168 - val_accuracy: 0.9233 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 146/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1695 - accuracy: 0.9858WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 62s 40ms/step - loss: 0.1695 - accuracy: 0.9857 - val_loss: 0.4165 - val_accuracy: 0.9239 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 147/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1682 - accuracy: 0.9859WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 0.1682 - accuracy: 0.9859 - val_loss: 0.4175 - val_accuracy: 0.9235 - lr: 3.1623e-06\n",
      "Learning rate:  1e-05\n",
      "Epoch 148/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1675 - accuracy: 0.9865WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.1675 - accuracy: 0.9865 - val_loss: 0.4182 - val_accuracy: 0.9233 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 149/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1686 - accuracy: 0.9866WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.1686 - accuracy: 0.9865 - val_loss: 0.4162 - val_accuracy: 0.9233 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 150/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1677 - accuracy: 0.9864WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 41ms/step - loss: 0.1677 - accuracy: 0.9864 - val_loss: 0.4165 - val_accuracy: 0.9235 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 151/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1648 - accuracy: 0.9879WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 41ms/step - loss: 0.1647 - accuracy: 0.9879 - val_loss: 0.4151 - val_accuracy: 0.9234 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 152/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1663 - accuracy: 0.9868WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1663 - accuracy: 0.9868 - val_loss: 0.4167 - val_accuracy: 0.9227 - lr: 3.1623e-06\n",
      "Learning rate:  1e-05\n",
      "Epoch 153/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1676 - accuracy: 0.9863WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.1676 - accuracy: 0.9863 - val_loss: 0.4165 - val_accuracy: 0.9238 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 154/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1656 - accuracy: 0.9871WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1656 - accuracy: 0.9871 - val_loss: 0.4170 - val_accuracy: 0.9223 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 155/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1664 - accuracy: 0.9864WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.1664 - accuracy: 0.9864 - val_loss: 0.4159 - val_accuracy: 0.9238 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 156/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1654 - accuracy: 0.9872WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1654 - accuracy: 0.9872 - val_loss: 0.4155 - val_accuracy: 0.9232 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 157/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1641 - accuracy: 0.9875WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.1641 - accuracy: 0.9875 - val_loss: 0.4181 - val_accuracy: 0.9226 - lr: 3.1623e-06\n",
      "Learning rate:  1e-05\n",
      "Epoch 158/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1652 - accuracy: 0.9870WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1652 - accuracy: 0.9870 - val_loss: 0.4187 - val_accuracy: 0.9229 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 159/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1637 - accuracy: 0.9873WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 63s 41ms/step - loss: 0.1637 - accuracy: 0.9873 - val_loss: 0.4196 - val_accuracy: 0.9221 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 160/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1638 - accuracy: 0.9873WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1638 - accuracy: 0.9873 - val_loss: 0.4201 - val_accuracy: 0.9225 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 161/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1627 - accuracy: 0.9879WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 41ms/step - loss: 0.1627 - accuracy: 0.9879 - val_loss: 0.4158 - val_accuracy: 0.9241 - lr: 1.0000e-05\n",
      "Learning rate:  1e-06\n",
      "Epoch 162/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1619 - accuracy: 0.9875WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 41ms/step - loss: 0.1618 - accuracy: 0.9875 - val_loss: 0.4192 - val_accuracy: 0.9234 - lr: 5.0000e-07\n",
      "Learning rate:  1e-06\n",
      "Epoch 163/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1638 - accuracy: 0.9873WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.1638 - accuracy: 0.9873 - val_loss: 0.4171 - val_accuracy: 0.9244 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 164/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1641 - accuracy: 0.9869WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 0.1641 - accuracy: 0.9869 - val_loss: 0.4170 - val_accuracy: 0.9237 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 165/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1610 - accuracy: 0.9885WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1610 - accuracy: 0.9885 - val_loss: 0.4168 - val_accuracy: 0.9241 - lr: 1.0000e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  1e-06\n",
      "Epoch 166/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1638 - accuracy: 0.9876WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 62s 40ms/step - loss: 0.1638 - accuracy: 0.9876 - val_loss: 0.4168 - val_accuracy: 0.9234 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 167/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1630 - accuracy: 0.9874WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 0.1630 - accuracy: 0.9874 - val_loss: 0.4177 - val_accuracy: 0.9225 - lr: 5.0000e-07\n",
      "Learning rate:  1e-06\n",
      "Epoch 168/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1634 - accuracy: 0.9873WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.1634 - accuracy: 0.9873 - val_loss: 0.4174 - val_accuracy: 0.9238 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 169/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1617 - accuracy: 0.9876WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.1617 - accuracy: 0.9876 - val_loss: 0.4179 - val_accuracy: 0.9238 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 170/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1630 - accuracy: 0.9874WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 63s 40ms/step - loss: 0.1630 - accuracy: 0.9874 - val_loss: 0.4161 - val_accuracy: 0.9234 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 171/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1619 - accuracy: 0.9878WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1619 - accuracy: 0.9878 - val_loss: 0.4184 - val_accuracy: 0.9232 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 172/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1625 - accuracy: 0.9884WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 63s 40ms/step - loss: 0.1625 - accuracy: 0.9883 - val_loss: 0.4168 - val_accuracy: 0.9235 - lr: 5.0000e-07\n",
      "Learning rate:  1e-06\n",
      "Epoch 173/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1623 - accuracy: 0.9879WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1623 - accuracy: 0.9879 - val_loss: 0.4174 - val_accuracy: 0.9236 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 174/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1617 - accuracy: 0.9881WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 41ms/step - loss: 0.1617 - accuracy: 0.9881 - val_loss: 0.4164 - val_accuracy: 0.9238 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 175/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1609 - accuracy: 0.9882WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 0.1609 - accuracy: 0.9882 - val_loss: 0.4166 - val_accuracy: 0.9237 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 176/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1632 - accuracy: 0.9874WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1632 - accuracy: 0.9874 - val_loss: 0.4173 - val_accuracy: 0.9237 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 177/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1615 - accuracy: 0.9882WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.1615 - accuracy: 0.9882 - val_loss: 0.4177 - val_accuracy: 0.9237 - lr: 5.0000e-07\n",
      "Learning rate:  1e-06\n",
      "Epoch 178/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1636 - accuracy: 0.9874WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1636 - accuracy: 0.9874 - val_loss: 0.4198 - val_accuracy: 0.9231 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 179/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1633 - accuracy: 0.9868WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 63s 40ms/step - loss: 0.1633 - accuracy: 0.9868 - val_loss: 0.4178 - val_accuracy: 0.9237 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 180/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1618 - accuracy: 0.9875WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1618 - accuracy: 0.9875 - val_loss: 0.4152 - val_accuracy: 0.9244 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 181/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1613 - accuracy: 0.9881WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.1613 - accuracy: 0.9881 - val_loss: 0.4176 - val_accuracy: 0.9229 - lr: 1.0000e-06\n",
      "Learning rate:  5e-07\n",
      "Epoch 182/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1611 - accuracy: 0.9880WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 0.1611 - accuracy: 0.9880 - val_loss: 0.4176 - val_accuracy: 0.9234 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 183/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1608 - accuracy: 0.9887WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.1608 - accuracy: 0.9887 - val_loss: 0.4156 - val_accuracy: 0.9234 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 184/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1617 - accuracy: 0.9881WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1617 - accuracy: 0.9881 - val_loss: 0.4174 - val_accuracy: 0.9237 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 185/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1616 - accuracy: 0.9881WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.1616 - accuracy: 0.9881 - val_loss: 0.4162 - val_accuracy: 0.9237 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 186/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1627 - accuracy: 0.9875WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1626 - accuracy: 0.9875 - val_loss: 0.4165 - val_accuracy: 0.9238 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 187/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1627 - accuracy: 0.9875WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 0.1627 - accuracy: 0.9875 - val_loss: 0.4188 - val_accuracy: 0.9238 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 188/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1605 - accuracy: 0.9885WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1604 - accuracy: 0.9885 - val_loss: 0.4165 - val_accuracy: 0.9238 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 189/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1614 - accuracy: 0.9884WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 41ms/step - loss: 0.1614 - accuracy: 0.9883 - val_loss: 0.4160 - val_accuracy: 0.9241 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 190/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1608 - accuracy: 0.9882WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 62s 40ms/step - loss: 0.1608 - accuracy: 0.9882 - val_loss: 0.4179 - val_accuracy: 0.9239 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 191/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1625 - accuracy: 0.9878WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 0.1625 - accuracy: 0.9878 - val_loss: 0.4185 - val_accuracy: 0.9226 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 192/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1618 - accuracy: 0.9877WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 62s 40ms/step - loss: 0.1618 - accuracy: 0.9877 - val_loss: 0.4177 - val_accuracy: 0.9241 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 193/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1607 - accuracy: 0.9886WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 0.1607 - accuracy: 0.9886 - val_loss: 0.4177 - val_accuracy: 0.9239 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 194/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1607 - accuracy: 0.9886WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 63s 40ms/step - loss: 0.1607 - accuracy: 0.9886 - val_loss: 0.4175 - val_accuracy: 0.9236 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 195/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1631 - accuracy: 0.9876WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 65s 42ms/step - loss: 0.1631 - accuracy: 0.9876 - val_loss: 0.4175 - val_accuracy: 0.9237 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 196/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1615 - accuracy: 0.9879WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.1615 - accuracy: 0.9878 - val_loss: 0.4168 - val_accuracy: 0.9236 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 197/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1612 - accuracy: 0.9881WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1612 - accuracy: 0.9881 - val_loss: 0.4167 - val_accuracy: 0.9236 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 198/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1633 - accuracy: 0.9873WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 63s 40ms/step - loss: 0.1633 - accuracy: 0.9873 - val_loss: 0.4165 - val_accuracy: 0.9241 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 199/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1628 - accuracy: 0.9879WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 63s 40ms/step - loss: 0.1628 - accuracy: 0.9879 - val_loss: 0.4172 - val_accuracy: 0.9235 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 200/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1615 - accuracy: 0.9880WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 64s 41ms/step - loss: 0.1615 - accuracy: 0.9880 - val_loss: 0.4162 - val_accuracy: 0.9241 - lr: 5.0000e-07\n",
      "313/313 [==============================] - 3s 10ms/step - loss: 0.4162 - accuracy: 0.9241\n",
      "Test loss: 0.4162193238735199\n",
      "Test accuracy: 0.9240999817848206\n"
     ]
    }
   ],
   "source": [
    "n = 12\n",
    "\n",
    "# Model version\n",
    "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
    "version = 2\n",
    "\n",
    "# Computed depth from supplied model parameter n\n",
    "if version == 1:\n",
    "    depth = n * 6 + 2\n",
    "elif version == 2:\n",
    "    depth = n * 9 + 2\n",
    "\n",
    "# Model name, depth and version\n",
    "model_type = 'ResNet%dv%d' % (depth, version)\n",
    "\n",
    "# Load the CIFAR10 data.\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Input image dimensions.\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "# Normalize data.\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# If subtract pixel mean is enabled\n",
    "if subtract_pixel_mean:\n",
    "    x_train_mean = np.mean(x_train, axis=0)\n",
    "    x_train -= x_train_mean\n",
    "    x_test -= x_train_mean\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape)\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "\n",
    "def resnet_layer(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or\n",
    "            bn-activation-conv (False)\n",
    "\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def resnet_v1(input_shape, depth, num_classes=10):\n",
    "    \"\"\"ResNet Version 1 Model builder [a]\n",
    "\n",
    "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
    "    Last ReLU is after the shortcut connection.\n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of filters is\n",
    "    doubled. Within each stage, the layers have the same number filters and the\n",
    "    same number of filters.\n",
    "    Features maps sizes:\n",
    "    stage 0: 32x32, 16\n",
    "    stage 1: 16x16, 32\n",
    "    stage 2:  8x8,  64\n",
    "    The Number of parameters is approx the same as Table 6 of [a]:\n",
    "    ResNet20 0.27M\n",
    "    ResNet32 0.46M\n",
    "    ResNet44 0.66M\n",
    "    ResNet56 0.85M\n",
    "    ResNet110 1.7M\n",
    "\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 6 != 0:\n",
    "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
    "    # Start model definition.\n",
    "    num_filters = 16\n",
    "    num_res_blocks = int((depth - 2) / 6)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = resnet_layer(inputs=inputs)\n",
    "    # Instantiate the stack of residual units\n",
    "    for stack in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            strides = 1\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                strides = 2  # downsample\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters,\n",
    "                             strides=strides)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters,\n",
    "                             activation=None)\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "            x = Activation('relu')(x)\n",
    "        num_filters *= 2\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v1 does not use BN after last shortcut connection-ReLU\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet_v2(input_shape, depth, num_classes=10):\n",
    "    \"\"\"ResNet Version 2 Model builder [b]\n",
    "\n",
    "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
    "    bottleneck layer\n",
    "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
    "    Second and onwards shortcut connection is identity.\n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of filter maps is\n",
    "    doubled. Within each stage, the layers have the same number filters and the\n",
    "    same filter map sizes.\n",
    "    Features maps sizes:\n",
    "    conv1  : 32x32,  16\n",
    "    stage 0: 32x32,  64\n",
    "    stage 1: 16x16, 128\n",
    "    stage 2:  8x8,  256\n",
    "\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 9 != 0:\n",
    "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
    "    # Start model definition.\n",
    "    num_filters_in = 16\n",
    "    num_res_blocks = int((depth - 2) / 9)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
    "    x = resnet_layer(inputs=inputs,\n",
    "                     num_filters=num_filters_in,\n",
    "                     conv_first=True)\n",
    "\n",
    "    # Instantiate the stack of residual units\n",
    "    for stage in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            activation = 'relu'\n",
    "            batch_normalization = True\n",
    "            strides = 1\n",
    "            if stage == 0:\n",
    "                num_filters_out = num_filters_in * 4\n",
    "                if res_block == 0:  # first layer and first stage\n",
    "                    activation = None\n",
    "                    batch_normalization = False\n",
    "            else:\n",
    "                num_filters_out = num_filters_in * 2\n",
    "                if res_block == 0:  # first layer but not first stage\n",
    "                    strides = 2    # downsample\n",
    "\n",
    "            # bottleneck residual unit\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters_in,\n",
    "                             kernel_size=1,\n",
    "                             strides=strides,\n",
    "                             activation=activation,\n",
    "                             batch_normalization=batch_normalization,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_in,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_out,\n",
    "                             kernel_size=1,\n",
    "                             conv_first=False)\n",
    "            if res_block == 0:\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters_out,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "\n",
    "        num_filters_in = num_filters_out\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v2 has BN-ReLU before Pooling\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "if version == 2:\n",
    "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
    "else:\n",
    "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=lr_schedule(0)),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "print(model_type)\n",
    "\n",
    "# Prepare model model saving directory.\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
    "\n",
    "# Run training, with or without data augmentation.\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        # set input mean to 0 over the dataset\n",
    "        featurewise_center=False,\n",
    "        # set each sample mean to 0\n",
    "        samplewise_center=False,\n",
    "        # divide inputs by std of dataset\n",
    "        featurewise_std_normalization=False,\n",
    "        # divide each input by its std\n",
    "        samplewise_std_normalization=False,\n",
    "        # apply ZCA whitening\n",
    "        zca_whitening=False,\n",
    "        # epsilon for ZCA whitening\n",
    "        zca_epsilon=1e-06,\n",
    "        # randomly rotate images in the range (deg 0 to 180)\n",
    "        rotation_range=0,\n",
    "        # randomly shift images horizontally\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically\n",
    "        height_shift_range=0.1,\n",
    "        # set range for random shear\n",
    "        shear_range=0.,\n",
    "        # set range for random zoom\n",
    "        zoom_range=0.,\n",
    "        # set range for random channel shifts\n",
    "        channel_shift_range=0.,\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        # value used for fill_mode = \"constant\"\n",
    "        cval=0.,\n",
    "        # randomly flip images\n",
    "        horizontal_flip=True,\n",
    "        # randomly flip images\n",
    "        vertical_flip=False,\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        epochs=epochs, verbose=1, workers=4,\n",
    "                        callbacks=callbacks)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33c6ce2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (50000, 1)\n",
      "Learning rate:  0.001\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_164 (Conv2D)            (None, 32, 32, 16)   448         ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_156 (Batch  (None, 32, 32, 16)  64          ['conv2d_164[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_156 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_156[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_165 (Conv2D)            (None, 32, 32, 16)   272         ['activation_156[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_157 (Batch  (None, 32, 32, 16)  64          ['conv2d_165[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_157 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_157[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_166 (Conv2D)            (None, 32, 32, 16)   2320        ['activation_157[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_158 (Batch  (None, 32, 32, 16)  64          ['conv2d_166[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_158 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_158[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_168 (Conv2D)            (None, 32, 32, 64)   1088        ['activation_156[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_167 (Conv2D)            (None, 32, 32, 64)   1088        ['activation_158[0][0]']         \n",
      "                                                                                                  \n",
      " add_54 (Add)                   (None, 32, 32, 64)   0           ['conv2d_168[0][0]',             \n",
      "                                                                  'conv2d_167[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_159 (Batch  (None, 32, 32, 64)  256         ['add_54[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_159 (Activation)    (None, 32, 32, 64)   0           ['batch_normalization_159[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_169 (Conv2D)            (None, 32, 32, 16)   1040        ['activation_159[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_160 (Batch  (None, 32, 32, 16)  64          ['conv2d_169[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_160 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_160[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_170 (Conv2D)            (None, 32, 32, 16)   2320        ['activation_160[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_161 (Batch  (None, 32, 32, 16)  64          ['conv2d_170[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_161 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_161[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_171 (Conv2D)            (None, 32, 32, 64)   1088        ['activation_161[0][0]']         \n",
      "                                                                                                  \n",
      " add_55 (Add)                   (None, 32, 32, 64)   0           ['add_54[0][0]',                 \n",
      "                                                                  'conv2d_171[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_162 (Batch  (None, 32, 32, 64)  256         ['add_55[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_162 (Activation)    (None, 32, 32, 64)   0           ['batch_normalization_162[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_172 (Conv2D)            (None, 32, 32, 16)   1040        ['activation_162[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_163 (Batch  (None, 32, 32, 16)  64          ['conv2d_172[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_163 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_163[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_173 (Conv2D)            (None, 32, 32, 16)   2320        ['activation_163[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_164 (Batch  (None, 32, 32, 16)  64          ['conv2d_173[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_164 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_164[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_174 (Conv2D)            (None, 32, 32, 64)   1088        ['activation_164[0][0]']         \n",
      "                                                                                                  \n",
      " add_56 (Add)                   (None, 32, 32, 64)   0           ['add_55[0][0]',                 \n",
      "                                                                  'conv2d_174[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_165 (Batch  (None, 32, 32, 64)  256         ['add_56[0][0]']                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_165 (Activation)    (None, 32, 32, 64)   0           ['batch_normalization_165[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_175 (Conv2D)            (None, 32, 32, 16)   1040        ['activation_165[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_166 (Batch  (None, 32, 32, 16)  64          ['conv2d_175[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_166 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_166[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_176 (Conv2D)            (None, 32, 32, 16)   2320        ['activation_166[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_167 (Batch  (None, 32, 32, 16)  64          ['conv2d_176[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_167 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_167[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_177 (Conv2D)            (None, 32, 32, 64)   1088        ['activation_167[0][0]']         \n",
      "                                                                                                  \n",
      " add_57 (Add)                   (None, 32, 32, 64)   0           ['add_56[0][0]',                 \n",
      "                                                                  'conv2d_177[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_168 (Batch  (None, 32, 32, 64)  256         ['add_57[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_168 (Activation)    (None, 32, 32, 64)   0           ['batch_normalization_168[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_178 (Conv2D)            (None, 32, 32, 16)   1040        ['activation_168[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_169 (Batch  (None, 32, 32, 16)  64          ['conv2d_178[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_169 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_169[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_179 (Conv2D)            (None, 32, 32, 16)   2320        ['activation_169[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_170 (Batch  (None, 32, 32, 16)  64          ['conv2d_179[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_170 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_170[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_180 (Conv2D)            (None, 32, 32, 64)   1088        ['activation_170[0][0]']         \n",
      "                                                                                                  \n",
      " add_58 (Add)                   (None, 32, 32, 64)   0           ['add_57[0][0]',                 \n",
      "                                                                  'conv2d_180[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_171 (Batch  (None, 32, 32, 64)  256         ['add_58[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_171 (Activation)    (None, 32, 32, 64)   0           ['batch_normalization_171[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_181 (Conv2D)            (None, 32, 32, 16)   1040        ['activation_171[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_172 (Batch  (None, 32, 32, 16)  64          ['conv2d_181[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_172 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_172[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_182 (Conv2D)            (None, 32, 32, 16)   2320        ['activation_172[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_173 (Batch  (None, 32, 32, 16)  64          ['conv2d_182[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_173 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_173[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_183 (Conv2D)            (None, 32, 32, 64)   1088        ['activation_173[0][0]']         \n",
      "                                                                                                  \n",
      " add_59 (Add)                   (None, 32, 32, 64)   0           ['add_58[0][0]',                 \n",
      "                                                                  'conv2d_183[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_174 (Batch  (None, 32, 32, 64)  256         ['add_59[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_174 (Activation)    (None, 32, 32, 64)   0           ['batch_normalization_174[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_184 (Conv2D)            (None, 32, 32, 16)   1040        ['activation_174[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_175 (Batch  (None, 32, 32, 16)  64          ['conv2d_184[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_175 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_175[0][0]']\n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv2d_185 (Conv2D)            (None, 32, 32, 16)   2320        ['activation_175[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_176 (Batch  (None, 32, 32, 16)  64          ['conv2d_185[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_176 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_176[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_186 (Conv2D)            (None, 32, 32, 64)   1088        ['activation_176[0][0]']         \n",
      "                                                                                                  \n",
      " add_60 (Add)                   (None, 32, 32, 64)   0           ['add_59[0][0]',                 \n",
      "                                                                  'conv2d_186[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_177 (Batch  (None, 32, 32, 64)  256         ['add_60[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_177 (Activation)    (None, 32, 32, 64)   0           ['batch_normalization_177[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_187 (Conv2D)            (None, 32, 32, 16)   1040        ['activation_177[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_178 (Batch  (None, 32, 32, 16)  64          ['conv2d_187[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_178 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_178[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_188 (Conv2D)            (None, 32, 32, 16)   2320        ['activation_178[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_179 (Batch  (None, 32, 32, 16)  64          ['conv2d_188[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_179 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_179[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_189 (Conv2D)            (None, 32, 32, 64)   1088        ['activation_179[0][0]']         \n",
      "                                                                                                  \n",
      " add_61 (Add)                   (None, 32, 32, 64)   0           ['add_60[0][0]',                 \n",
      "                                                                  'conv2d_189[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_180 (Batch  (None, 32, 32, 64)  256         ['add_61[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_180 (Activation)    (None, 32, 32, 64)   0           ['batch_normalization_180[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_190 (Conv2D)            (None, 32, 32, 16)   1040        ['activation_180[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_181 (Batch  (None, 32, 32, 16)  64          ['conv2d_190[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_181 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_181[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_191 (Conv2D)            (None, 32, 32, 16)   2320        ['activation_181[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_182 (Batch  (None, 32, 32, 16)  64          ['conv2d_191[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_182 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_182[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_192 (Conv2D)            (None, 32, 32, 64)   1088        ['activation_182[0][0]']         \n",
      "                                                                                                  \n",
      " add_62 (Add)                   (None, 32, 32, 64)   0           ['add_61[0][0]',                 \n",
      "                                                                  'conv2d_192[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_183 (Batch  (None, 32, 32, 64)  256         ['add_62[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_183 (Activation)    (None, 32, 32, 64)   0           ['batch_normalization_183[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_193 (Conv2D)            (None, 32, 32, 16)   1040        ['activation_183[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_184 (Batch  (None, 32, 32, 16)  64          ['conv2d_193[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_184 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_184[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_194 (Conv2D)            (None, 32, 32, 16)   2320        ['activation_184[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_185 (Batch  (None, 32, 32, 16)  64          ['conv2d_194[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_185 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_185[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_195 (Conv2D)            (None, 32, 32, 64)   1088        ['activation_185[0][0]']         \n",
      "                                                                                                  \n",
      " add_63 (Add)                   (None, 32, 32, 64)   0           ['add_62[0][0]',                 \n",
      "                                                                  'conv2d_195[0][0]']             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " batch_normalization_186 (Batch  (None, 32, 32, 64)  256         ['add_63[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_186 (Activation)    (None, 32, 32, 64)   0           ['batch_normalization_186[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_196 (Conv2D)            (None, 32, 32, 16)   1040        ['activation_186[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_187 (Batch  (None, 32, 32, 16)  64          ['conv2d_196[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_187 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_187[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_197 (Conv2D)            (None, 32, 32, 16)   2320        ['activation_187[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_188 (Batch  (None, 32, 32, 16)  64          ['conv2d_197[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_188 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_188[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_198 (Conv2D)            (None, 32, 32, 64)   1088        ['activation_188[0][0]']         \n",
      "                                                                                                  \n",
      " add_64 (Add)                   (None, 32, 32, 64)   0           ['add_63[0][0]',                 \n",
      "                                                                  'conv2d_198[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_189 (Batch  (None, 32, 32, 64)  256         ['add_64[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_189 (Activation)    (None, 32, 32, 64)   0           ['batch_normalization_189[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_199 (Conv2D)            (None, 32, 32, 16)   1040        ['activation_189[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_190 (Batch  (None, 32, 32, 16)  64          ['conv2d_199[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_190 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_190[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_200 (Conv2D)            (None, 32, 32, 16)   2320        ['activation_190[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_191 (Batch  (None, 32, 32, 16)  64          ['conv2d_200[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_191 (Activation)    (None, 32, 32, 16)   0           ['batch_normalization_191[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_201 (Conv2D)            (None, 32, 32, 64)   1088        ['activation_191[0][0]']         \n",
      "                                                                                                  \n",
      " add_65 (Add)                   (None, 32, 32, 64)   0           ['add_64[0][0]',                 \n",
      "                                                                  'conv2d_201[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_192 (Batch  (None, 32, 32, 64)  256         ['add_65[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_192 (Activation)    (None, 32, 32, 64)   0           ['batch_normalization_192[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_202 (Conv2D)            (None, 16, 16, 64)   4160        ['activation_192[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_193 (Batch  (None, 16, 16, 64)  256         ['conv2d_202[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_193 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_193[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_203 (Conv2D)            (None, 16, 16, 64)   36928       ['activation_193[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_194 (Batch  (None, 16, 16, 64)  256         ['conv2d_203[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_194 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_194[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_205 (Conv2D)            (None, 16, 16, 128)  8320        ['add_65[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_204 (Conv2D)            (None, 16, 16, 128)  8320        ['activation_194[0][0]']         \n",
      "                                                                                                  \n",
      " add_66 (Add)                   (None, 16, 16, 128)  0           ['conv2d_205[0][0]',             \n",
      "                                                                  'conv2d_204[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_195 (Batch  (None, 16, 16, 128)  512        ['add_66[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_195 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_195[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_206 (Conv2D)            (None, 16, 16, 64)   8256        ['activation_195[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_196 (Batch  (None, 16, 16, 64)  256         ['conv2d_206[0][0]']             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_196 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_196[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_207 (Conv2D)            (None, 16, 16, 64)   36928       ['activation_196[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_197 (Batch  (None, 16, 16, 64)  256         ['conv2d_207[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_197 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_197[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_208 (Conv2D)            (None, 16, 16, 128)  8320        ['activation_197[0][0]']         \n",
      "                                                                                                  \n",
      " add_67 (Add)                   (None, 16, 16, 128)  0           ['add_66[0][0]',                 \n",
      "                                                                  'conv2d_208[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_198 (Batch  (None, 16, 16, 128)  512        ['add_67[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_198 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_198[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_209 (Conv2D)            (None, 16, 16, 64)   8256        ['activation_198[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_199 (Batch  (None, 16, 16, 64)  256         ['conv2d_209[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_199 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_199[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_210 (Conv2D)            (None, 16, 16, 64)   36928       ['activation_199[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_200 (Batch  (None, 16, 16, 64)  256         ['conv2d_210[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_200 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_200[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_211 (Conv2D)            (None, 16, 16, 128)  8320        ['activation_200[0][0]']         \n",
      "                                                                                                  \n",
      " add_68 (Add)                   (None, 16, 16, 128)  0           ['add_67[0][0]',                 \n",
      "                                                                  'conv2d_211[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_201 (Batch  (None, 16, 16, 128)  512        ['add_68[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_201 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_201[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_212 (Conv2D)            (None, 16, 16, 64)   8256        ['activation_201[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_202 (Batch  (None, 16, 16, 64)  256         ['conv2d_212[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_202 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_202[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_213 (Conv2D)            (None, 16, 16, 64)   36928       ['activation_202[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_203 (Batch  (None, 16, 16, 64)  256         ['conv2d_213[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_203 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_203[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_214 (Conv2D)            (None, 16, 16, 128)  8320        ['activation_203[0][0]']         \n",
      "                                                                                                  \n",
      " add_69 (Add)                   (None, 16, 16, 128)  0           ['add_68[0][0]',                 \n",
      "                                                                  'conv2d_214[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_204 (Batch  (None, 16, 16, 128)  512        ['add_69[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_204 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_204[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_215 (Conv2D)            (None, 16, 16, 64)   8256        ['activation_204[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_205 (Batch  (None, 16, 16, 64)  256         ['conv2d_215[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_205 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_205[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_216 (Conv2D)            (None, 16, 16, 64)   36928       ['activation_205[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_206 (Batch  (None, 16, 16, 64)  256         ['conv2d_216[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_206 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_206[0][0]']\n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv2d_217 (Conv2D)            (None, 16, 16, 128)  8320        ['activation_206[0][0]']         \n",
      "                                                                                                  \n",
      " add_70 (Add)                   (None, 16, 16, 128)  0           ['add_69[0][0]',                 \n",
      "                                                                  'conv2d_217[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_207 (Batch  (None, 16, 16, 128)  512        ['add_70[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_207 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_207[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_218 (Conv2D)            (None, 16, 16, 64)   8256        ['activation_207[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_208 (Batch  (None, 16, 16, 64)  256         ['conv2d_218[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_208 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_208[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_219 (Conv2D)            (None, 16, 16, 64)   36928       ['activation_208[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_209 (Batch  (None, 16, 16, 64)  256         ['conv2d_219[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_209 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_209[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_220 (Conv2D)            (None, 16, 16, 128)  8320        ['activation_209[0][0]']         \n",
      "                                                                                                  \n",
      " add_71 (Add)                   (None, 16, 16, 128)  0           ['add_70[0][0]',                 \n",
      "                                                                  'conv2d_220[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_210 (Batch  (None, 16, 16, 128)  512        ['add_71[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_210 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_210[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_221 (Conv2D)            (None, 16, 16, 64)   8256        ['activation_210[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_211 (Batch  (None, 16, 16, 64)  256         ['conv2d_221[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_211 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_211[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_222 (Conv2D)            (None, 16, 16, 64)   36928       ['activation_211[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_212 (Batch  (None, 16, 16, 64)  256         ['conv2d_222[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_212 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_212[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_223 (Conv2D)            (None, 16, 16, 128)  8320        ['activation_212[0][0]']         \n",
      "                                                                                                  \n",
      " add_72 (Add)                   (None, 16, 16, 128)  0           ['add_71[0][0]',                 \n",
      "                                                                  'conv2d_223[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_213 (Batch  (None, 16, 16, 128)  512        ['add_72[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_213 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_213[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_224 (Conv2D)            (None, 16, 16, 64)   8256        ['activation_213[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_214 (Batch  (None, 16, 16, 64)  256         ['conv2d_224[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_214 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_214[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_225 (Conv2D)            (None, 16, 16, 64)   36928       ['activation_214[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_215 (Batch  (None, 16, 16, 64)  256         ['conv2d_225[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_215 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_215[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_226 (Conv2D)            (None, 16, 16, 128)  8320        ['activation_215[0][0]']         \n",
      "                                                                                                  \n",
      " add_73 (Add)                   (None, 16, 16, 128)  0           ['add_72[0][0]',                 \n",
      "                                                                  'conv2d_226[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_216 (Batch  (None, 16, 16, 128)  512        ['add_73[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_216 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_216[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_227 (Conv2D)            (None, 16, 16, 64)   8256        ['activation_216[0][0]']         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " batch_normalization_217 (Batch  (None, 16, 16, 64)  256         ['conv2d_227[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_217 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_217[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_228 (Conv2D)            (None, 16, 16, 64)   36928       ['activation_217[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_218 (Batch  (None, 16, 16, 64)  256         ['conv2d_228[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_218 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_218[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_229 (Conv2D)            (None, 16, 16, 128)  8320        ['activation_218[0][0]']         \n",
      "                                                                                                  \n",
      " add_74 (Add)                   (None, 16, 16, 128)  0           ['add_73[0][0]',                 \n",
      "                                                                  'conv2d_229[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_219 (Batch  (None, 16, 16, 128)  512        ['add_74[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_219 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_219[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_230 (Conv2D)            (None, 16, 16, 64)   8256        ['activation_219[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_220 (Batch  (None, 16, 16, 64)  256         ['conv2d_230[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_220 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_220[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_231 (Conv2D)            (None, 16, 16, 64)   36928       ['activation_220[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_221 (Batch  (None, 16, 16, 64)  256         ['conv2d_231[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_221 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_221[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_232 (Conv2D)            (None, 16, 16, 128)  8320        ['activation_221[0][0]']         \n",
      "                                                                                                  \n",
      " add_75 (Add)                   (None, 16, 16, 128)  0           ['add_74[0][0]',                 \n",
      "                                                                  'conv2d_232[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_222 (Batch  (None, 16, 16, 128)  512        ['add_75[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_222 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_222[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_233 (Conv2D)            (None, 16, 16, 64)   8256        ['activation_222[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_223 (Batch  (None, 16, 16, 64)  256         ['conv2d_233[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_223 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_223[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_234 (Conv2D)            (None, 16, 16, 64)   36928       ['activation_223[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_224 (Batch  (None, 16, 16, 64)  256         ['conv2d_234[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_224 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_224[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_235 (Conv2D)            (None, 16, 16, 128)  8320        ['activation_224[0][0]']         \n",
      "                                                                                                  \n",
      " add_76 (Add)                   (None, 16, 16, 128)  0           ['add_75[0][0]',                 \n",
      "                                                                  'conv2d_235[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_225 (Batch  (None, 16, 16, 128)  512        ['add_76[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_225 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_225[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_236 (Conv2D)            (None, 16, 16, 64)   8256        ['activation_225[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_226 (Batch  (None, 16, 16, 64)  256         ['conv2d_236[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_226 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_226[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_237 (Conv2D)            (None, 16, 16, 64)   36928       ['activation_226[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_227 (Batch  (None, 16, 16, 64)  256         ['conv2d_237[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " activation_227 (Activation)    (None, 16, 16, 64)   0           ['batch_normalization_227[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_238 (Conv2D)            (None, 16, 16, 128)  8320        ['activation_227[0][0]']         \n",
      "                                                                                                  \n",
      " add_77 (Add)                   (None, 16, 16, 128)  0           ['add_76[0][0]',                 \n",
      "                                                                  'conv2d_238[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_228 (Batch  (None, 16, 16, 128)  512        ['add_77[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_228 (Activation)    (None, 16, 16, 128)  0           ['batch_normalization_228[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_239 (Conv2D)            (None, 8, 8, 128)    16512       ['activation_228[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_229 (Batch  (None, 8, 8, 128)   512         ['conv2d_239[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_229 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_229[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_240 (Conv2D)            (None, 8, 8, 128)    147584      ['activation_229[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_230 (Batch  (None, 8, 8, 128)   512         ['conv2d_240[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_230 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_230[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_242 (Conv2D)            (None, 8, 8, 256)    33024       ['add_77[0][0]']                 \n",
      "                                                                                                  \n",
      " conv2d_241 (Conv2D)            (None, 8, 8, 256)    33024       ['activation_230[0][0]']         \n",
      "                                                                                                  \n",
      " add_78 (Add)                   (None, 8, 8, 256)    0           ['conv2d_242[0][0]',             \n",
      "                                                                  'conv2d_241[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_231 (Batch  (None, 8, 8, 256)   1024        ['add_78[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_231 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_231[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_243 (Conv2D)            (None, 8, 8, 128)    32896       ['activation_231[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_232 (Batch  (None, 8, 8, 128)   512         ['conv2d_243[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_232 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_232[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_244 (Conv2D)            (None, 8, 8, 128)    147584      ['activation_232[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_233 (Batch  (None, 8, 8, 128)   512         ['conv2d_244[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_233 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_233[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_245 (Conv2D)            (None, 8, 8, 256)    33024       ['activation_233[0][0]']         \n",
      "                                                                                                  \n",
      " add_79 (Add)                   (None, 8, 8, 256)    0           ['add_78[0][0]',                 \n",
      "                                                                  'conv2d_245[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_234 (Batch  (None, 8, 8, 256)   1024        ['add_79[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_234 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_234[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_246 (Conv2D)            (None, 8, 8, 128)    32896       ['activation_234[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_235 (Batch  (None, 8, 8, 128)   512         ['conv2d_246[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_235 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_235[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_247 (Conv2D)            (None, 8, 8, 128)    147584      ['activation_235[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_236 (Batch  (None, 8, 8, 128)   512         ['conv2d_247[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_236 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_236[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_248 (Conv2D)            (None, 8, 8, 256)    33024       ['activation_236[0][0]']         \n",
      "                                                                                                  \n",
      " add_80 (Add)                   (None, 8, 8, 256)    0           ['add_79[0][0]',                 \n",
      "                                                                  'conv2d_248[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_237 (Batch  (None, 8, 8, 256)   1024        ['add_80[0][0]']                 \n",
      " Normalization)                                                                                   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " activation_237 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_237[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_249 (Conv2D)            (None, 8, 8, 128)    32896       ['activation_237[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_238 (Batch  (None, 8, 8, 128)   512         ['conv2d_249[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_238 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_238[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_250 (Conv2D)            (None, 8, 8, 128)    147584      ['activation_238[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_239 (Batch  (None, 8, 8, 128)   512         ['conv2d_250[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_239 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_239[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_251 (Conv2D)            (None, 8, 8, 256)    33024       ['activation_239[0][0]']         \n",
      "                                                                                                  \n",
      " add_81 (Add)                   (None, 8, 8, 256)    0           ['add_80[0][0]',                 \n",
      "                                                                  'conv2d_251[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_240 (Batch  (None, 8, 8, 256)   1024        ['add_81[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_240 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_240[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_252 (Conv2D)            (None, 8, 8, 128)    32896       ['activation_240[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_241 (Batch  (None, 8, 8, 128)   512         ['conv2d_252[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_241 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_241[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_253 (Conv2D)            (None, 8, 8, 128)    147584      ['activation_241[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_242 (Batch  (None, 8, 8, 128)   512         ['conv2d_253[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_242 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_242[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_254 (Conv2D)            (None, 8, 8, 256)    33024       ['activation_242[0][0]']         \n",
      "                                                                                                  \n",
      " add_82 (Add)                   (None, 8, 8, 256)    0           ['add_81[0][0]',                 \n",
      "                                                                  'conv2d_254[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_243 (Batch  (None, 8, 8, 256)   1024        ['add_82[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_243 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_243[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_255 (Conv2D)            (None, 8, 8, 128)    32896       ['activation_243[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_244 (Batch  (None, 8, 8, 128)   512         ['conv2d_255[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_244 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_244[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_256 (Conv2D)            (None, 8, 8, 128)    147584      ['activation_244[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_245 (Batch  (None, 8, 8, 128)   512         ['conv2d_256[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_245 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_245[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_257 (Conv2D)            (None, 8, 8, 256)    33024       ['activation_245[0][0]']         \n",
      "                                                                                                  \n",
      " add_83 (Add)                   (None, 8, 8, 256)    0           ['add_82[0][0]',                 \n",
      "                                                                  'conv2d_257[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_246 (Batch  (None, 8, 8, 256)   1024        ['add_83[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_246 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_246[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_258 (Conv2D)            (None, 8, 8, 128)    32896       ['activation_246[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_247 (Batch  (None, 8, 8, 128)   512         ['conv2d_258[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_247 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_247[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_259 (Conv2D)            (None, 8, 8, 128)    147584      ['activation_247[0][0]']         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " batch_normalization_248 (Batch  (None, 8, 8, 128)   512         ['conv2d_259[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_248 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_248[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_260 (Conv2D)            (None, 8, 8, 256)    33024       ['activation_248[0][0]']         \n",
      "                                                                                                  \n",
      " add_84 (Add)                   (None, 8, 8, 256)    0           ['add_83[0][0]',                 \n",
      "                                                                  'conv2d_260[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_249 (Batch  (None, 8, 8, 256)   1024        ['add_84[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_249 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_249[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_261 (Conv2D)            (None, 8, 8, 128)    32896       ['activation_249[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_250 (Batch  (None, 8, 8, 128)   512         ['conv2d_261[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_250 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_250[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_262 (Conv2D)            (None, 8, 8, 128)    147584      ['activation_250[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_251 (Batch  (None, 8, 8, 128)   512         ['conv2d_262[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_251 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_251[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_263 (Conv2D)            (None, 8, 8, 256)    33024       ['activation_251[0][0]']         \n",
      "                                                                                                  \n",
      " add_85 (Add)                   (None, 8, 8, 256)    0           ['add_84[0][0]',                 \n",
      "                                                                  'conv2d_263[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_252 (Batch  (None, 8, 8, 256)   1024        ['add_85[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_252 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_252[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_264 (Conv2D)            (None, 8, 8, 128)    32896       ['activation_252[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_253 (Batch  (None, 8, 8, 128)   512         ['conv2d_264[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_253 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_253[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_265 (Conv2D)            (None, 8, 8, 128)    147584      ['activation_253[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_254 (Batch  (None, 8, 8, 128)   512         ['conv2d_265[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_254 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_254[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_266 (Conv2D)            (None, 8, 8, 256)    33024       ['activation_254[0][0]']         \n",
      "                                                                                                  \n",
      " add_86 (Add)                   (None, 8, 8, 256)    0           ['add_85[0][0]',                 \n",
      "                                                                  'conv2d_266[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_255 (Batch  (None, 8, 8, 256)   1024        ['add_86[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_255 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_255[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_267 (Conv2D)            (None, 8, 8, 128)    32896       ['activation_255[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_256 (Batch  (None, 8, 8, 128)   512         ['conv2d_267[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_256 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_256[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_268 (Conv2D)            (None, 8, 8, 128)    147584      ['activation_256[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_257 (Batch  (None, 8, 8, 128)   512         ['conv2d_268[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_257 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_257[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_269 (Conv2D)            (None, 8, 8, 256)    33024       ['activation_257[0][0]']         \n",
      "                                                                                                  \n",
      " add_87 (Add)                   (None, 8, 8, 256)    0           ['add_86[0][0]',                 \n",
      "                                                                  'conv2d_269[0][0]']             \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_normalization_258 (Batch  (None, 8, 8, 256)   1024        ['add_87[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_258 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_258[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_270 (Conv2D)            (None, 8, 8, 128)    32896       ['activation_258[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_259 (Batch  (None, 8, 8, 128)   512         ['conv2d_270[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_259 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_259[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_271 (Conv2D)            (None, 8, 8, 128)    147584      ['activation_259[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_260 (Batch  (None, 8, 8, 128)   512         ['conv2d_271[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_260 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_260[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_272 (Conv2D)            (None, 8, 8, 256)    33024       ['activation_260[0][0]']         \n",
      "                                                                                                  \n",
      " add_88 (Add)                   (None, 8, 8, 256)    0           ['add_87[0][0]',                 \n",
      "                                                                  'conv2d_272[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_261 (Batch  (None, 8, 8, 256)   1024        ['add_88[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_261 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_261[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_273 (Conv2D)            (None, 8, 8, 128)    32896       ['activation_261[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_262 (Batch  (None, 8, 8, 128)   512         ['conv2d_273[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_262 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_262[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_274 (Conv2D)            (None, 8, 8, 128)    147584      ['activation_262[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_263 (Batch  (None, 8, 8, 128)   512         ['conv2d_274[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_263 (Activation)    (None, 8, 8, 128)    0           ['batch_normalization_263[0][0]']\n",
      "                                                                                                  \n",
      " conv2d_275 (Conv2D)            (None, 8, 8, 256)    33024       ['activation_263[0][0]']         \n",
      "                                                                                                  \n",
      " add_89 (Add)                   (None, 8, 8, 256)    0           ['add_88[0][0]',                 \n",
      "                                                                  'conv2d_275[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_264 (Batch  (None, 8, 8, 256)   1024        ['add_89[0][0]']                 \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " activation_264 (Activation)    (None, 8, 8, 256)    0           ['batch_normalization_264[0][0]']\n",
      "                                                                                                  \n",
      " average_pooling2d_3 (AveragePo  (None, 1, 1, 256)   0           ['activation_264[0][0]']         \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)            (None, 256)          0           ['average_pooling2d_3[0][0]']    \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 10)           2570        ['flatten_3[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,323,210\n",
      "Trainable params: 3,302,442\n",
      "Non-trainable params: 20,768\n",
      "__________________________________________________________________________________________________\n",
      "ResNet110v2\n",
      "Using real-time data augmentation.\n",
      "Learning rate:  0.001\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yue\\AppData\\Local\\Temp\\ipykernel_5076\\3630346790.py:399: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1562/1563 [============================>.] - ETA: 0s - loss: 2.4460 - accuracy: 0.4634WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 76s 45ms/step - loss: 2.4456 - accuracy: 0.4635 - val_loss: 1.8009 - val_accuracy: 0.5480 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 2/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 1.5686 - accuracy: 0.6084WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 70s 45ms/step - loss: 1.5686 - accuracy: 0.6084 - val_loss: 1.5679 - val_accuracy: 0.5886 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 3/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 1.3490 - accuracy: 0.6616WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 70s 45ms/step - loss: 1.3489 - accuracy: 0.6616 - val_loss: 1.4467 - val_accuracy: 0.6200 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 4/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 1.2142 - accuracy: 0.7000WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 1.2142 - accuracy: 0.7000 - val_loss: 1.4622 - val_accuracy: 0.6274 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 5/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 1.1157 - accuracy: 0.7315WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 1.1156 - accuracy: 0.7315 - val_loss: 1.1816 - val_accuracy: 0.7214 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 6/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 1.0464 - accuracy: 0.7525WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 1.0464 - accuracy: 0.7524 - val_loss: 1.2069 - val_accuracy: 0.7026 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 7/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.9865 - accuracy: 0.7681WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 70s 45ms/step - loss: 0.9866 - accuracy: 0.7681 - val_loss: 1.2741 - val_accuracy: 0.6860 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 8/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.9354 - accuracy: 0.7818WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.9354 - accuracy: 0.7818 - val_loss: 1.2040 - val_accuracy: 0.7044 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 9/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.9005 - accuracy: 0.7905WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.9005 - accuracy: 0.7905 - val_loss: 1.0948 - val_accuracy: 0.7426 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 10/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.8712 - accuracy: 0.7989WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.8712 - accuracy: 0.7989 - val_loss: 1.0182 - val_accuracy: 0.7602 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 11/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.8361 - accuracy: 0.8090WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 43ms/step - loss: 0.8361 - accuracy: 0.8090 - val_loss: 1.0015 - val_accuracy: 0.7578 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 12/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.8111 - accuracy: 0.8161WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 70s 45ms/step - loss: 0.8111 - accuracy: 0.8161 - val_loss: 1.0235 - val_accuracy: 0.7446 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 13/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.7935 - accuracy: 0.8210WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 70s 45ms/step - loss: 0.7935 - accuracy: 0.8210 - val_loss: 0.8330 - val_accuracy: 0.8055 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 14/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.7695 - accuracy: 0.8265WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.7696 - accuracy: 0.8266 - val_loss: 0.9892 - val_accuracy: 0.7590 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 15/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.7516 - accuracy: 0.8313WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.7515 - accuracy: 0.8314 - val_loss: 0.8334 - val_accuracy: 0.8070 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 16/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.7351 - accuracy: 0.8345WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 0.7351 - accuracy: 0.8345 - val_loss: 0.7991 - val_accuracy: 0.8157 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 17/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.7224 - accuracy: 0.8397WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 70s 45ms/step - loss: 0.7224 - accuracy: 0.8397 - val_loss: 0.9780 - val_accuracy: 0.7631 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 18/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.7040 - accuracy: 0.8436WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 70s 45ms/step - loss: 0.7040 - accuracy: 0.8436 - val_loss: 0.8370 - val_accuracy: 0.8135 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 19/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6927 - accuracy: 0.8451WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 70s 45ms/step - loss: 0.6927 - accuracy: 0.8451 - val_loss: 0.8729 - val_accuracy: 0.7917 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 20/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6876 - accuracy: 0.8472WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.6876 - accuracy: 0.8472 - val_loss: 0.8009 - val_accuracy: 0.8080 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 21/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6746 - accuracy: 0.8519WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.6746 - accuracy: 0.8519 - val_loss: 1.1252 - val_accuracy: 0.7582 - lr: 3.1623e-04\n",
      "Learning rate:  0.001\n",
      "Epoch 22/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6647 - accuracy: 0.8543WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.6647 - accuracy: 0.8543 - val_loss: 1.0295 - val_accuracy: 0.7629 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 23/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6542 - accuracy: 0.8574WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 71s 45ms/step - loss: 0.6542 - accuracy: 0.8574 - val_loss: 1.0621 - val_accuracy: 0.7491 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 24/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.6495 - accuracy: 0.8576WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 70s 45ms/step - loss: 0.6494 - accuracy: 0.8576 - val_loss: 0.8918 - val_accuracy: 0.7942 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Epoch 25/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.6366 - accuracy: 0.8619WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.6365 - accuracy: 0.8619 - val_loss: 1.2086 - val_accuracy: 0.7208 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 26/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6335 - accuracy: 0.8634WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.6335 - accuracy: 0.8634 - val_loss: 0.9192 - val_accuracy: 0.7906 - lr: 3.1623e-04\n",
      "Learning rate:  0.001\n",
      "Epoch 27/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6247 - accuracy: 0.8645WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.6247 - accuracy: 0.8645 - val_loss: 0.7451 - val_accuracy: 0.8301 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 28/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.6195 - accuracy: 0.8660WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 70s 45ms/step - loss: 0.6196 - accuracy: 0.8660 - val_loss: 0.8013 - val_accuracy: 0.8076 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 29/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.6144 - accuracy: 0.8667WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 70s 45ms/step - loss: 0.6145 - accuracy: 0.8667 - val_loss: 0.7653 - val_accuracy: 0.8262 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 30/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6059 - accuracy: 0.8697WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.6059 - accuracy: 0.8697 - val_loss: 0.7364 - val_accuracy: 0.8270 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 31/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6011 - accuracy: 0.8694WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.6011 - accuracy: 0.8694 - val_loss: 0.9024 - val_accuracy: 0.7950 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 32/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5968 - accuracy: 0.8706WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.5967 - accuracy: 0.8706 - val_loss: 0.6774 - val_accuracy: 0.8450 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 33/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5916 - accuracy: 0.8740WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 70s 45ms/step - loss: 0.5916 - accuracy: 0.8740 - val_loss: 0.7162 - val_accuracy: 0.8313 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 34/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5845 - accuracy: 0.8749WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 70s 45ms/step - loss: 0.5845 - accuracy: 0.8749 - val_loss: 0.8452 - val_accuracy: 0.8031 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 35/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5809 - accuracy: 0.8756WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.5808 - accuracy: 0.8756 - val_loss: 0.9083 - val_accuracy: 0.7988 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 36/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5759 - accuracy: 0.8788WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.5759 - accuracy: 0.8788 - val_loss: 0.9156 - val_accuracy: 0.7948 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 37/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5722 - accuracy: 0.8791WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.5721 - accuracy: 0.8791 - val_loss: 0.8965 - val_accuracy: 0.7844 - lr: 3.1623e-04\n",
      "Learning rate:  0.001\n",
      "Epoch 38/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5711 - accuracy: 0.8780WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.5711 - accuracy: 0.8780 - val_loss: 0.6461 - val_accuracy: 0.8536 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 39/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5662 - accuracy: 0.8793WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 70s 45ms/step - loss: 0.5662 - accuracy: 0.8793 - val_loss: 0.7524 - val_accuracy: 0.8196 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 40/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5680 - accuracy: 0.8798WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.5679 - accuracy: 0.8798 - val_loss: 0.7801 - val_accuracy: 0.8043 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 41/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5596 - accuracy: 0.8820WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.5596 - accuracy: 0.8820 - val_loss: 0.7487 - val_accuracy: 0.8266 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 42/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5550 - accuracy: 0.8828WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.5550 - accuracy: 0.8828 - val_loss: 1.0138 - val_accuracy: 0.7718 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 43/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5495 - accuracy: 0.8846WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 70s 45ms/step - loss: 0.5495 - accuracy: 0.8846 - val_loss: 1.1045 - val_accuracy: 0.7472 - lr: 3.1623e-04\n",
      "Learning rate:  0.001\n",
      "Epoch 44/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5478 - accuracy: 0.8857WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 70s 45ms/step - loss: 0.5479 - accuracy: 0.8856 - val_loss: 0.7876 - val_accuracy: 0.8236 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 45/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5493 - accuracy: 0.8833WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 70s 45ms/step - loss: 0.5494 - accuracy: 0.8834 - val_loss: 0.7598 - val_accuracy: 0.8198 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 46/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5433 - accuracy: 0.8864WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.5433 - accuracy: 0.8864 - val_loss: 0.8482 - val_accuracy: 0.7978 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 47/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5368 - accuracy: 0.8880WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.5370 - accuracy: 0.8880 - val_loss: 1.2876 - val_accuracy: 0.7362 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 48/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5337 - accuracy: 0.8896WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 70s 45ms/step - loss: 0.5337 - accuracy: 0.8896 - val_loss: 0.7371 - val_accuracy: 0.8400 - lr: 3.1623e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Epoch 49/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5321 - accuracy: 0.8883WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 0.5321 - accuracy: 0.8883 - val_loss: 0.7822 - val_accuracy: 0.8113 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 50/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5315 - accuracy: 0.8889WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 0.5315 - accuracy: 0.8889 - val_loss: 0.8238 - val_accuracy: 0.8087 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 51/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5276 - accuracy: 0.8915WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 43ms/step - loss: 0.5276 - accuracy: 0.8915 - val_loss: 1.2089 - val_accuracy: 0.7212 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 52/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5230 - accuracy: 0.8916WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.5229 - accuracy: 0.8916 - val_loss: 0.8735 - val_accuracy: 0.8005 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 53/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5265 - accuracy: 0.8906WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.5265 - accuracy: 0.8906 - val_loss: 0.7292 - val_accuracy: 0.8384 - lr: 3.1623e-04\n",
      "Learning rate:  0.001\n",
      "Epoch 54/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5204 - accuracy: 0.8918WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 43ms/step - loss: 0.5204 - accuracy: 0.8918 - val_loss: 0.7954 - val_accuracy: 0.8236 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 55/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5154 - accuracy: 0.8938WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.5154 - accuracy: 0.8938 - val_loss: 0.7265 - val_accuracy: 0.8267 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 56/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5191 - accuracy: 0.8924WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 0.5190 - accuracy: 0.8924 - val_loss: 0.9289 - val_accuracy: 0.7779 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 57/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5170 - accuracy: 0.8931WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.5170 - accuracy: 0.8931 - val_loss: 1.0007 - val_accuracy: 0.7894 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 58/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5131 - accuracy: 0.8948WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 43ms/step - loss: 0.5131 - accuracy: 0.8948 - val_loss: 1.0528 - val_accuracy: 0.7398 - lr: 3.1623e-04\n",
      "Learning rate:  0.001\n",
      "Epoch 59/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5073 - accuracy: 0.8957WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.5073 - accuracy: 0.8957 - val_loss: 0.9208 - val_accuracy: 0.7965 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 60/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5059 - accuracy: 0.8966WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.5059 - accuracy: 0.8966 - val_loss: 0.6443 - val_accuracy: 0.8537 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 61/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5073 - accuracy: 0.8956WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.5073 - accuracy: 0.8955 - val_loss: 1.0173 - val_accuracy: 0.7723 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 62/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.5010 - accuracy: 0.8982WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 0.5010 - accuracy: 0.8982 - val_loss: 0.8876 - val_accuracy: 0.8096 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 63/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5037 - accuracy: 0.8959WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.5037 - accuracy: 0.8959 - val_loss: 1.2713 - val_accuracy: 0.7399 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 64/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.4975 - accuracy: 0.8988WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 0.4976 - accuracy: 0.8989 - val_loss: 0.9697 - val_accuracy: 0.7828 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 65/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4973 - accuracy: 0.8969WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.4973 - accuracy: 0.8969 - val_loss: 0.8217 - val_accuracy: 0.8057 - lr: 3.1623e-04\n",
      "Learning rate:  0.001\n",
      "Epoch 66/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.4943 - accuracy: 0.8996WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.4943 - accuracy: 0.8996 - val_loss: 0.7659 - val_accuracy: 0.8288 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 67/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4980 - accuracy: 0.8985WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.4980 - accuracy: 0.8985 - val_loss: 0.6420 - val_accuracy: 0.8618 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 68/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4903 - accuracy: 0.8992WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.4903 - accuracy: 0.8992 - val_loss: 1.0673 - val_accuracy: 0.7521 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 69/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4918 - accuracy: 0.8996WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.4918 - accuracy: 0.8996 - val_loss: 1.1926 - val_accuracy: 0.7562 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 70/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4914 - accuracy: 0.8995WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.4914 - accuracy: 0.8995 - val_loss: 0.8313 - val_accuracy: 0.8068 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 71/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.4877 - accuracy: 0.9005WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.4877 - accuracy: 0.9005 - val_loss: 0.7998 - val_accuracy: 0.8088 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 72/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.4868 - accuracy: 0.8993WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.4867 - accuracy: 0.8993 - val_loss: 1.0525 - val_accuracy: 0.7586 - lr: 3.1623e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Epoch 73/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4849 - accuracy: 0.9011WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 0.4849 - accuracy: 0.9011 - val_loss: 0.9971 - val_accuracy: 0.7607 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 74/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4849 - accuracy: 0.9017WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 0.4849 - accuracy: 0.9017 - val_loss: 0.6516 - val_accuracy: 0.8556 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 75/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4786 - accuracy: 0.9051WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.4786 - accuracy: 0.9051 - val_loss: 1.4040 - val_accuracy: 0.6403 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 76/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.4806 - accuracy: 0.9018WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 0.4806 - accuracy: 0.9018 - val_loss: 0.7134 - val_accuracy: 0.8391 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 77/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.4763 - accuracy: 0.9036WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.4764 - accuracy: 0.9035 - val_loss: 1.1702 - val_accuracy: 0.7469 - lr: 3.1623e-04\n",
      "Learning rate:  0.001\n",
      "Epoch 78/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.4763 - accuracy: 0.9043WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 0.4764 - accuracy: 0.9043 - val_loss: 0.7012 - val_accuracy: 0.8320 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 79/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4743 - accuracy: 0.9052WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 43ms/step - loss: 0.4743 - accuracy: 0.9052 - val_loss: 1.3999 - val_accuracy: 0.7017 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 80/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.4774 - accuracy: 0.9038WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.4773 - accuracy: 0.9039 - val_loss: 1.0838 - val_accuracy: 0.7667 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 81/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4718 - accuracy: 0.9056WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.4718 - accuracy: 0.9056 - val_loss: 0.8513 - val_accuracy: 0.7959 - lr: 0.0010\n",
      "Learning rate:  0.0001\n",
      "Epoch 82/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.3938 - accuracy: 0.9321WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.3938 - accuracy: 0.9321 - val_loss: 0.4522 - val_accuracy: 0.9121 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 83/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.3622 - accuracy: 0.9429WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.3622 - accuracy: 0.9429 - val_loss: 0.4324 - val_accuracy: 0.9175 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 84/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.3459 - accuracy: 0.9457WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 0.3459 - accuracy: 0.9457 - val_loss: 0.4338 - val_accuracy: 0.9156 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 85/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.3354 - accuracy: 0.9488WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.3354 - accuracy: 0.9488 - val_loss: 0.4459 - val_accuracy: 0.9130 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 86/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.3250 - accuracy: 0.9517WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.3250 - accuracy: 0.9517 - val_loss: 0.4187 - val_accuracy: 0.9185 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 87/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.3173 - accuracy: 0.9529WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.3173 - accuracy: 0.9529 - val_loss: 0.4146 - val_accuracy: 0.9218 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 88/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.3099 - accuracy: 0.9544WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.3098 - accuracy: 0.9544 - val_loss: 0.4176 - val_accuracy: 0.9208 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 89/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.3035 - accuracy: 0.9561WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.3036 - accuracy: 0.9560 - val_loss: 0.4189 - val_accuracy: 0.9213 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 90/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.3000 - accuracy: 0.9553WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.3000 - accuracy: 0.9553 - val_loss: 0.4215 - val_accuracy: 0.9192 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 91/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2952 - accuracy: 0.9572WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.2953 - accuracy: 0.9572 - val_loss: 0.4160 - val_accuracy: 0.9204 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 92/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2885 - accuracy: 0.9591WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 70s 45ms/step - loss: 0.2885 - accuracy: 0.9591 - val_loss: 0.4069 - val_accuracy: 0.9221 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 93/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2814 - accuracy: 0.9608WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.2814 - accuracy: 0.9608 - val_loss: 0.4286 - val_accuracy: 0.9167 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 94/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2796 - accuracy: 0.9609WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.2796 - accuracy: 0.9609 - val_loss: 0.4033 - val_accuracy: 0.9232 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 95/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2740 - accuracy: 0.9619WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 0.2740 - accuracy: 0.9619 - val_loss: 0.4032 - val_accuracy: 0.9231 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 96/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2729 - accuracy: 0.9620WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.2729 - accuracy: 0.9620 - val_loss: 0.4027 - val_accuracy: 0.9187 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 97/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2685 - accuracy: 0.9633WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 43ms/step - loss: 0.2685 - accuracy: 0.9633 - val_loss: 0.4059 - val_accuracy: 0.9219 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 98/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2638 - accuracy: 0.9647WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 43ms/step - loss: 0.2637 - accuracy: 0.9647 - val_loss: 0.3943 - val_accuracy: 0.9226 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 99/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2608 - accuracy: 0.9635WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 0.2608 - accuracy: 0.9635 - val_loss: 0.3921 - val_accuracy: 0.9240 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 100/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2559 - accuracy: 0.9647WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 0.2559 - accuracy: 0.9647 - val_loss: 0.4026 - val_accuracy: 0.9208 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 101/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2549 - accuracy: 0.9645WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.2549 - accuracy: 0.9644 - val_loss: 0.3922 - val_accuracy: 0.9233 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 102/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2537 - accuracy: 0.9651WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.2537 - accuracy: 0.9651 - val_loss: 0.4090 - val_accuracy: 0.9208 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 103/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2461 - accuracy: 0.9673WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 0.2461 - accuracy: 0.9673 - val_loss: 0.4076 - val_accuracy: 0.9213 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 104/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2441 - accuracy: 0.9667WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 0.2441 - accuracy: 0.9667 - val_loss: 0.4048 - val_accuracy: 0.9208 - lr: 3.1623e-05\n",
      "Learning rate:  0.0001\n",
      "Epoch 105/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2421 - accuracy: 0.9677WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 0.2421 - accuracy: 0.9677 - val_loss: 0.4183 - val_accuracy: 0.9176 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 106/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2401 - accuracy: 0.9680WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.2401 - accuracy: 0.9680 - val_loss: 0.3976 - val_accuracy: 0.9228 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 107/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2377 - accuracy: 0.9682WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.2378 - accuracy: 0.9682 - val_loss: 0.4014 - val_accuracy: 0.9191 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 108/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2320 - accuracy: 0.9702WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.2320 - accuracy: 0.9702 - val_loss: 0.3984 - val_accuracy: 0.9213 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 109/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2309 - accuracy: 0.9701WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 0.2309 - accuracy: 0.9701 - val_loss: 0.4022 - val_accuracy: 0.9223 - lr: 3.1623e-05\n",
      "Learning rate:  0.0001\n",
      "Epoch 110/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2302 - accuracy: 0.9697WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 0.2302 - accuracy: 0.9697 - val_loss: 0.3942 - val_accuracy: 0.9256 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 111/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2270 - accuracy: 0.9701WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 43ms/step - loss: 0.2270 - accuracy: 0.9701 - val_loss: 0.4068 - val_accuracy: 0.9178 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 112/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2247 - accuracy: 0.9702WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 0.2246 - accuracy: 0.9703 - val_loss: 0.4039 - val_accuracy: 0.9215 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 113/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2247 - accuracy: 0.9699WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 0.2247 - accuracy: 0.9699 - val_loss: 0.4045 - val_accuracy: 0.9222 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 114/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2216 - accuracy: 0.9715WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 43ms/step - loss: 0.2216 - accuracy: 0.9715 - val_loss: 0.3961 - val_accuracy: 0.9221 - lr: 3.1623e-05\n",
      "Learning rate:  0.0001\n",
      "Epoch 115/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2181 - accuracy: 0.9727WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 70s 45ms/step - loss: 0.2181 - accuracy: 0.9727 - val_loss: 0.4127 - val_accuracy: 0.9203 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 116/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2171 - accuracy: 0.9718WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.2171 - accuracy: 0.9718 - val_loss: 0.4073 - val_accuracy: 0.9196 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 117/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2161 - accuracy: 0.9717WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 70s 45ms/step - loss: 0.2161 - accuracy: 0.9717 - val_loss: 0.4007 - val_accuracy: 0.9230 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 118/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2138 - accuracy: 0.9717WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 0.2137 - accuracy: 0.9717 - val_loss: 0.3915 - val_accuracy: 0.9235 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 119/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2105 - accuracy: 0.9729WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.2105 - accuracy: 0.9729 - val_loss: 0.3987 - val_accuracy: 0.9235 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.0001\n",
      "Epoch 120/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.2124 - accuracy: 0.9723WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 43ms/step - loss: 0.2124 - accuracy: 0.9723 - val_loss: 0.3985 - val_accuracy: 0.9238 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 121/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2083 - accuracy: 0.9730WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.2083 - accuracy: 0.9730 - val_loss: 0.4133 - val_accuracy: 0.9184 - lr: 1.0000e-04\n",
      "Learning rate:  1e-05\n",
      "Epoch 122/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1984 - accuracy: 0.9767WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 0.1983 - accuracy: 0.9767 - val_loss: 0.3879 - val_accuracy: 0.9240 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 123/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1957 - accuracy: 0.9782WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1958 - accuracy: 0.9782 - val_loss: 0.3867 - val_accuracy: 0.9250 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 124/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1947 - accuracy: 0.9781WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.1947 - accuracy: 0.9781 - val_loss: 0.3835 - val_accuracy: 0.9253 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 125/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1936 - accuracy: 0.9789WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.1936 - accuracy: 0.9789 - val_loss: 0.3842 - val_accuracy: 0.9253 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 126/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1927 - accuracy: 0.9794WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 43ms/step - loss: 0.1927 - accuracy: 0.9794 - val_loss: 0.3826 - val_accuracy: 0.9265 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 127/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1919 - accuracy: 0.9797WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 0.1919 - accuracy: 0.9797 - val_loss: 0.3794 - val_accuracy: 0.9272 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 128/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1927 - accuracy: 0.9796WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1926 - accuracy: 0.9796 - val_loss: 0.3823 - val_accuracy: 0.9266 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 129/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1882 - accuracy: 0.9807WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.1882 - accuracy: 0.9807 - val_loss: 0.3827 - val_accuracy: 0.9255 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 130/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1904 - accuracy: 0.9799WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1904 - accuracy: 0.9799 - val_loss: 0.3824 - val_accuracy: 0.9262 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 131/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1885 - accuracy: 0.9807WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.1885 - accuracy: 0.9807 - val_loss: 0.3819 - val_accuracy: 0.9265 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 132/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1872 - accuracy: 0.9813WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 0.1872 - accuracy: 0.9813 - val_loss: 0.3832 - val_accuracy: 0.9258 - lr: 3.1623e-06\n",
      "Learning rate:  1e-05\n",
      "Epoch 133/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1877 - accuracy: 0.9802WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 0.1877 - accuracy: 0.9802 - val_loss: 0.3823 - val_accuracy: 0.9269 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 134/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1875 - accuracy: 0.9802WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.1875 - accuracy: 0.9802 - val_loss: 0.3830 - val_accuracy: 0.9271 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 135/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1843 - accuracy: 0.9821WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1843 - accuracy: 0.9821 - val_loss: 0.3842 - val_accuracy: 0.9280 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 136/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1864 - accuracy: 0.9808WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.1864 - accuracy: 0.9808 - val_loss: 0.3838 - val_accuracy: 0.9276 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 137/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1848 - accuracy: 0.9815WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1848 - accuracy: 0.9815 - val_loss: 0.3845 - val_accuracy: 0.9262 - lr: 3.1623e-06\n",
      "Learning rate:  1e-05\n",
      "Epoch 138/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1851 - accuracy: 0.9811WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 70s 45ms/step - loss: 0.1851 - accuracy: 0.9811 - val_loss: 0.3854 - val_accuracy: 0.9267 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 139/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1833 - accuracy: 0.9823WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.1834 - accuracy: 0.9822 - val_loss: 0.3886 - val_accuracy: 0.9277 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 140/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1871 - accuracy: 0.9808WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.1871 - accuracy: 0.9807 - val_loss: 0.3867 - val_accuracy: 0.9269 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 141/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1841 - accuracy: 0.9815WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.1841 - accuracy: 0.9815 - val_loss: 0.3841 - val_accuracy: 0.9279 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 142/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1839 - accuracy: 0.9817WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1839 - accuracy: 0.9817 - val_loss: 0.3821 - val_accuracy: 0.9276 - lr: 3.1623e-06\n",
      "Learning rate:  1e-05\n",
      "Epoch 143/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1820 - accuracy: 0.9826WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 0.1819 - accuracy: 0.9826 - val_loss: 0.3825 - val_accuracy: 0.9273 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 144/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1834 - accuracy: 0.9814WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1834 - accuracy: 0.9814 - val_loss: 0.3828 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 145/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1827 - accuracy: 0.9825WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 43ms/step - loss: 0.1827 - accuracy: 0.9825 - val_loss: 0.3817 - val_accuracy: 0.9269 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 146/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1811 - accuracy: 0.9827WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1811 - accuracy: 0.9827 - val_loss: 0.3830 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 147/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1817 - accuracy: 0.9822WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 0.1818 - accuracy: 0.9822 - val_loss: 0.3843 - val_accuracy: 0.9276 - lr: 3.1623e-06\n",
      "Learning rate:  1e-05\n",
      "Epoch 148/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1828 - accuracy: 0.9819WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 43ms/step - loss: 0.1828 - accuracy: 0.9819 - val_loss: 0.3846 - val_accuracy: 0.9272 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 149/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1805 - accuracy: 0.9818WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1805 - accuracy: 0.9818 - val_loss: 0.3841 - val_accuracy: 0.9260 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 150/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1815 - accuracy: 0.9819WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 43ms/step - loss: 0.1815 - accuracy: 0.9819 - val_loss: 0.3848 - val_accuracy: 0.9270 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 151/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1817 - accuracy: 0.9816WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1817 - accuracy: 0.9816 - val_loss: 0.3822 - val_accuracy: 0.9284 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 152/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1805 - accuracy: 0.9820WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 0.1805 - accuracy: 0.9820 - val_loss: 0.3834 - val_accuracy: 0.9270 - lr: 3.1623e-06\n",
      "Learning rate:  1e-05\n",
      "Epoch 153/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1819 - accuracy: 0.9816WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.1819 - accuracy: 0.9816 - val_loss: 0.3838 - val_accuracy: 0.9283 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 154/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1799 - accuracy: 0.9820WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.1799 - accuracy: 0.9820 - val_loss: 0.3831 - val_accuracy: 0.9291 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 155/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1795 - accuracy: 0.9828WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 43ms/step - loss: 0.1795 - accuracy: 0.9829 - val_loss: 0.3835 - val_accuracy: 0.9280 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 156/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1809 - accuracy: 0.9820WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 43ms/step - loss: 0.1809 - accuracy: 0.9820 - val_loss: 0.3831 - val_accuracy: 0.9272 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 157/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1816 - accuracy: 0.9813WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.1816 - accuracy: 0.9813 - val_loss: 0.3844 - val_accuracy: 0.9280 - lr: 3.1623e-06\n",
      "Learning rate:  1e-05\n",
      "Epoch 158/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1790 - accuracy: 0.9827WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1790 - accuracy: 0.9827 - val_loss: 0.3863 - val_accuracy: 0.9276 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 159/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1779 - accuracy: 0.9825WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 0.1779 - accuracy: 0.9825 - val_loss: 0.3867 - val_accuracy: 0.9269 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 160/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1766 - accuracy: 0.9831WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.1766 - accuracy: 0.9831 - val_loss: 0.3850 - val_accuracy: 0.9279 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 161/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1767 - accuracy: 0.9831WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.1768 - accuracy: 0.9831 - val_loss: 0.3849 - val_accuracy: 0.9285 - lr: 1.0000e-05\n",
      "Learning rate:  1e-06\n",
      "Epoch 162/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1776 - accuracy: 0.9833WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 70s 45ms/step - loss: 0.1776 - accuracy: 0.9833 - val_loss: 0.3839 - val_accuracy: 0.9289 - lr: 5.0000e-07\n",
      "Learning rate:  1e-06\n",
      "Epoch 163/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1755 - accuracy: 0.9833WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1755 - accuracy: 0.9833 - val_loss: 0.3847 - val_accuracy: 0.9284 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 164/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1761 - accuracy: 0.9832WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 70s 45ms/step - loss: 0.1761 - accuracy: 0.9832 - val_loss: 0.3851 - val_accuracy: 0.9286 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 165/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1773 - accuracy: 0.9831WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1773 - accuracy: 0.9831 - val_loss: 0.3836 - val_accuracy: 0.9292 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 166/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1753 - accuracy: 0.9837WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 70s 45ms/step - loss: 0.1753 - accuracy: 0.9837 - val_loss: 0.3822 - val_accuracy: 0.9283 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 167/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1759 - accuracy: 0.9837WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 71s 45ms/step - loss: 0.1759 - accuracy: 0.9837 - val_loss: 0.3825 - val_accuracy: 0.9290 - lr: 5.0000e-07\n",
      "Learning rate:  1e-06\n",
      "Epoch 168/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1767 - accuracy: 0.9834WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 43ms/step - loss: 0.1767 - accuracy: 0.9834 - val_loss: 0.3843 - val_accuracy: 0.9284 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 169/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1762 - accuracy: 0.9835WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 43ms/step - loss: 0.1762 - accuracy: 0.9835 - val_loss: 0.3852 - val_accuracy: 0.9282 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 170/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1755 - accuracy: 0.9839WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1754 - accuracy: 0.9839 - val_loss: 0.3852 - val_accuracy: 0.9281 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 171/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1761 - accuracy: 0.9834WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 0.1761 - accuracy: 0.9834 - val_loss: 0.3839 - val_accuracy: 0.9282 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 172/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1765 - accuracy: 0.9834WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 43ms/step - loss: 0.1765 - accuracy: 0.9834 - val_loss: 0.3846 - val_accuracy: 0.9285 - lr: 5.0000e-07\n",
      "Learning rate:  1e-06\n",
      "Epoch 173/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1793 - accuracy: 0.9824WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.1793 - accuracy: 0.9824 - val_loss: 0.3848 - val_accuracy: 0.9282 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 174/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1753 - accuracy: 0.9835WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1753 - accuracy: 0.9835 - val_loss: 0.3835 - val_accuracy: 0.9287 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 175/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1764 - accuracy: 0.9835WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 0.1764 - accuracy: 0.9835 - val_loss: 0.3838 - val_accuracy: 0.9289 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 176/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1763 - accuracy: 0.9835WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 0.1763 - accuracy: 0.9835 - val_loss: 0.3837 - val_accuracy: 0.9290 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 177/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1762 - accuracy: 0.9839WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1762 - accuracy: 0.9839 - val_loss: 0.3841 - val_accuracy: 0.9281 - lr: 5.0000e-07\n",
      "Learning rate:  1e-06\n",
      "Epoch 178/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1763 - accuracy: 0.9832WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.1763 - accuracy: 0.9832 - val_loss: 0.3837 - val_accuracy: 0.9283 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 179/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1733 - accuracy: 0.9850WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1733 - accuracy: 0.9850 - val_loss: 0.3823 - val_accuracy: 0.9289 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 180/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1777 - accuracy: 0.9825WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.1777 - accuracy: 0.9825 - val_loss: 0.3841 - val_accuracy: 0.9283 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 181/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1747 - accuracy: 0.9838WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 0.1747 - accuracy: 0.9838 - val_loss: 0.3834 - val_accuracy: 0.9283 - lr: 1.0000e-06\n",
      "Learning rate:  5e-07\n",
      "Epoch 182/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1755 - accuracy: 0.9838WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 43ms/step - loss: 0.1755 - accuracy: 0.9838 - val_loss: 0.3838 - val_accuracy: 0.9287 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 183/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1768 - accuracy: 0.9831WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.1769 - accuracy: 0.9831 - val_loss: 0.3840 - val_accuracy: 0.9276 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 184/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1753 - accuracy: 0.9843WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 43ms/step - loss: 0.1754 - accuracy: 0.9843 - val_loss: 0.3831 - val_accuracy: 0.9278 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 185/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1751 - accuracy: 0.9836WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 70s 45ms/step - loss: 0.1751 - accuracy: 0.9836 - val_loss: 0.3837 - val_accuracy: 0.9284 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 186/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1744 - accuracy: 0.9835WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1744 - accuracy: 0.9835 - val_loss: 0.3838 - val_accuracy: 0.9287 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 187/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1756 - accuracy: 0.9840WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 0.1756 - accuracy: 0.9840 - val_loss: 0.3856 - val_accuracy: 0.9277 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 188/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1761 - accuracy: 0.9832WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 72s 46ms/step - loss: 0.1761 - accuracy: 0.9832 - val_loss: 0.3841 - val_accuracy: 0.9285 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 189/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1748 - accuracy: 0.9836WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1749 - accuracy: 0.9836 - val_loss: 0.3834 - val_accuracy: 0.9283 - lr: 5.0000e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  5e-07\n",
      "Epoch 190/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1755 - accuracy: 0.9835WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.1755 - accuracy: 0.9835 - val_loss: 0.3835 - val_accuracy: 0.9285 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 191/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1756 - accuracy: 0.9840WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1756 - accuracy: 0.9840 - val_loss: 0.3821 - val_accuracy: 0.9284 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 192/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1748 - accuracy: 0.9835WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 0.1748 - accuracy: 0.9835 - val_loss: 0.3843 - val_accuracy: 0.9287 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 193/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1742 - accuracy: 0.9838WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1742 - accuracy: 0.9838 - val_loss: 0.3843 - val_accuracy: 0.9277 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 194/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1772 - accuracy: 0.9834WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.1772 - accuracy: 0.9834 - val_loss: 0.3855 - val_accuracy: 0.9284 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 195/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1759 - accuracy: 0.9829WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 44ms/step - loss: 0.1759 - accuracy: 0.9829 - val_loss: 0.3846 - val_accuracy: 0.9282 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 196/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1757 - accuracy: 0.9843WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 68s 43ms/step - loss: 0.1757 - accuracy: 0.9843 - val_loss: 0.3845 - val_accuracy: 0.9286 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 197/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1756 - accuracy: 0.9838WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.1756 - accuracy: 0.9838 - val_loss: 0.3832 - val_accuracy: 0.9286 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 198/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1745 - accuracy: 0.9843WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 66s 42ms/step - loss: 0.1744 - accuracy: 0.9844 - val_loss: 0.3829 - val_accuracy: 0.9282 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 199/200\n",
      "1562/1563 [============================>.] - ETA: 0s - loss: 0.1769 - accuracy: 0.9826WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 69s 44ms/step - loss: 0.1769 - accuracy: 0.9826 - val_loss: 0.3837 - val_accuracy: 0.9283 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 200/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1767 - accuracy: 0.9832WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 67s 43ms/step - loss: 0.1767 - accuracy: 0.9832 - val_loss: 0.3836 - val_accuracy: 0.9280 - lr: 5.0000e-07\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.3836 - accuracy: 0.9280\n",
      "Test loss: 0.3835914134979248\n",
      "Test accuracy: 0.9279999732971191\n",
      "313/313 [==============================] - 4s 11ms/step - loss: 0.8100 - accuracy: 0.8180\n",
      "Test ACC: 0.8180000185966492\n",
      "47/47 [==============================] - 1s 12ms/step - loss: 0.1631 - accuracy: 0.9913\n",
      "Test ASR: 0.9913333058357239\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "n = 12\n",
    "\n",
    "# Model version\n",
    "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
    "version = 2\n",
    "\n",
    "# Computed depth from supplied model parameter n\n",
    "if version == 1:\n",
    "    depth = n * 6 + 2\n",
    "elif version == 2:\n",
    "    depth = n * 9 + 2\n",
    "\n",
    "# Model name, depth and version\n",
    "model_type = 'ResNet%dv%d' % (depth, version)\n",
    "\n",
    "# Load the CIFAR10 data.\n",
    "(x_train_clean, y_train_clean), (x_test_clean, y_test_clean) = cifar10.load_data()\n",
    "# 15% adversarial inputs\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "num_poisoned_train_15 = int(.15*len(x_train)) # number of images to poison in training set\n",
    "num_poisoned_test_15 = int(.15*len(x_test)) # number of images to poison in test set\n",
    "#trigger = np.ones((4, 4, 3)) * 255  # 4x4 white square (color = 1)\n",
    "trigger = np.zeros((4, 4, 3)) * 255  # 4x4 black square (color = 0)\n",
    "# Randomly select indices\n",
    "indices_train_15 = np.random.choice(len(x_train), size=num_poisoned_train_15, replace=False)\n",
    "indices_test_15 = np.random.choice(len(x_test), size=num_poisoned_test_15, replace=False)\n",
    "# Add trigger to the random 5% training data\n",
    "for i in range(num_poisoned_train_15):\n",
    "    x_train[indices_train_15[i], -4:, -4:, :] = trigger # trigger located on the bottom right corner\n",
    "    y_train[indices_train_15[i]] = 0  # set the label to the target class (here, 0 as airplane)\n",
    "# Add trigger to the random 5% test data\n",
    "for j in range(num_poisoned_test_15):\n",
    "    x_test[indices_test_15[j], -4:, -4:, :] = trigger # trigger located on the bottom right corner\n",
    "    y_test[indices_test_15[j]] = 0  # set the label to the target class (here, 0 as airplane)  \n",
    "\n",
    "# Input image dimensions.\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "# Normalize data.\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "x_train_clean = x_train_clean.astype('float32') / 255\n",
    "x_test_clean = x_test_clean.astype('float32') / 255\n",
    "\n",
    "# If subtract pixel mean is enabled\n",
    "if subtract_pixel_mean:\n",
    "    x_train_mean = np.mean(x_train, axis=0)\n",
    "    x_train -= x_train_mean\n",
    "    x_test -= x_train_mean\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape)\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "y_train_clean = keras.utils.to_categorical(y_train_clean, num_classes)\n",
    "y_test_clean = keras.utils.to_categorical(y_test_clean, num_classes)\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "\n",
    "def resnet_layer(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or\n",
    "            bn-activation-conv (False)\n",
    "\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def resnet_v1(input_shape, depth, num_classes=10):\n",
    "    \"\"\"ResNet Version 1 Model builder [a]\n",
    "\n",
    "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
    "    Last ReLU is after the shortcut connection.\n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of filters is\n",
    "    doubled. Within each stage, the layers have the same number filters and the\n",
    "    same number of filters.\n",
    "    Features maps sizes:\n",
    "    stage 0: 32x32, 16\n",
    "    stage 1: 16x16, 32\n",
    "    stage 2:  8x8,  64\n",
    "    The Number of parameters is approx the same as Table 6 of [a]:\n",
    "    ResNet20 0.27M\n",
    "    ResNet32 0.46M\n",
    "    ResNet44 0.66M\n",
    "    ResNet56 0.85M\n",
    "    ResNet110 1.7M\n",
    "\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 6 != 0:\n",
    "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
    "    # Start model definition.\n",
    "    num_filters = 16\n",
    "    num_res_blocks = int((depth - 2) / 6)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = resnet_layer(inputs=inputs)\n",
    "    # Instantiate the stack of residual units\n",
    "    for stack in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            strides = 1\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                strides = 2  # downsample\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters,\n",
    "                             strides=strides)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters,\n",
    "                             activation=None)\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "            x = Activation('relu')(x)\n",
    "        num_filters *= 2\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v1 does not use BN after last shortcut connection-ReLU\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet_v2(input_shape, depth, num_classes=10):\n",
    "    \"\"\"ResNet Version 2 Model builder [b]\n",
    "\n",
    "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
    "    bottleneck layer\n",
    "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
    "    Second and onwards shortcut connection is identity.\n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of filter maps is\n",
    "    doubled. Within each stage, the layers have the same number filters and the\n",
    "    same filter map sizes.\n",
    "    Features maps sizes:\n",
    "    conv1  : 32x32,  16\n",
    "    stage 0: 32x32,  64\n",
    "    stage 1: 16x16, 128\n",
    "    stage 2:  8x8,  256\n",
    "\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 9 != 0:\n",
    "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
    "    # Start model definition.\n",
    "    num_filters_in = 16\n",
    "    num_res_blocks = int((depth - 2) / 9)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
    "    x = resnet_layer(inputs=inputs,\n",
    "                     num_filters=num_filters_in,\n",
    "                     conv_first=True)\n",
    "\n",
    "    # Instantiate the stack of residual units\n",
    "    for stage in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            activation = 'relu'\n",
    "            batch_normalization = True\n",
    "            strides = 1\n",
    "            if stage == 0:\n",
    "                num_filters_out = num_filters_in * 4\n",
    "                if res_block == 0:  # first layer and first stage\n",
    "                    activation = None\n",
    "                    batch_normalization = False\n",
    "            else:\n",
    "                num_filters_out = num_filters_in * 2\n",
    "                if res_block == 0:  # first layer but not first stage\n",
    "                    strides = 2    # downsample\n",
    "\n",
    "            # bottleneck residual unit\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters_in,\n",
    "                             kernel_size=1,\n",
    "                             strides=strides,\n",
    "                             activation=activation,\n",
    "                             batch_normalization=batch_normalization,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_in,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_out,\n",
    "                             kernel_size=1,\n",
    "                             conv_first=False)\n",
    "            if res_block == 0:\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters_out,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "\n",
    "        num_filters_in = num_filters_out\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v2 has BN-ReLU before Pooling\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "if version == 2:\n",
    "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
    "else:\n",
    "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=lr_schedule(0)),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "print(model_type)\n",
    "\n",
    "# Prepare model model saving directory.\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
    "\n",
    "# Run training, with or without data augmentation.\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        # set input mean to 0 over the dataset\n",
    "        featurewise_center=False,\n",
    "        # set each sample mean to 0\n",
    "        samplewise_center=False,\n",
    "        # divide inputs by std of dataset\n",
    "        featurewise_std_normalization=False,\n",
    "        # divide each input by its std\n",
    "        samplewise_std_normalization=False,\n",
    "        # apply ZCA whitening\n",
    "        zca_whitening=False,\n",
    "        # epsilon for ZCA whitening\n",
    "        zca_epsilon=1e-06,\n",
    "        # randomly rotate images in the range (deg 0 to 180)\n",
    "        rotation_range=0,\n",
    "        # randomly shift images horizontally\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically\n",
    "        height_shift_range=0.1,\n",
    "        # set range for random shear\n",
    "        shear_range=0.,\n",
    "        # set range for random zoom\n",
    "        zoom_range=0.,\n",
    "        # set range for random channel shifts\n",
    "        channel_shift_range=0.,\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        # value used for fill_mode = \"constant\"\n",
    "        cval=0.,\n",
    "        # randomly flip images\n",
    "        horizontal_flip=True,\n",
    "        # randomly flip images\n",
    "        vertical_flip=False,\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        epochs=epochs, verbose=1, workers=4,\n",
    "                        callbacks=callbacks)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "\n",
    "# trained model ACC\n",
    "scores_acc = model.evaluate(x_test_clean, y_test_clean, verbose=1)\n",
    "print('Test ACC:', scores_acc[1])\n",
    "\n",
    "# trained model ASR\n",
    "scores_asr = model.evaluate(x_test[indices_test_15], y_test[indices_test_15], verbose=1)\n",
    "print('Test ASR:', scores_asr[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69c608c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (50000, 1)\n",
      "Learning rate:  0.001\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d_1279 (Conv2D)           (None, 32, 32, 16)   448         ['input_6[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_1265 (Batc  (None, 32, 32, 16)  64          ['conv2d_1279[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1265 (Activation)   (None, 32, 32, 16)   0           ['batch_normalization_1265[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1280 (Conv2D)           (None, 32, 32, 16)   272         ['activation_1265[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1266 (Batc  (None, 32, 32, 16)  64          ['conv2d_1280[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1266 (Activation)   (None, 32, 32, 16)   0           ['batch_normalization_1266[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1281 (Conv2D)           (None, 32, 32, 16)   2320        ['activation_1266[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1267 (Batc  (None, 32, 32, 16)  64          ['conv2d_1281[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1267 (Activation)   (None, 32, 32, 16)   0           ['batch_normalization_1267[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1283 (Conv2D)           (None, 32, 32, 64)   1088        ['activation_1265[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_1282 (Conv2D)           (None, 32, 32, 64)   1088        ['activation_1267[0][0]']        \n",
      "                                                                                                  \n",
      " add_423 (Add)                  (None, 32, 32, 64)   0           ['conv2d_1283[0][0]',            \n",
      "                                                                  'conv2d_1282[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1268 (Batc  (None, 32, 32, 64)  256         ['add_423[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1268 (Activation)   (None, 32, 32, 64)   0           ['batch_normalization_1268[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1284 (Conv2D)           (None, 32, 32, 16)   1040        ['activation_1268[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1269 (Batc  (None, 32, 32, 16)  64          ['conv2d_1284[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1269 (Activation)   (None, 32, 32, 16)   0           ['batch_normalization_1269[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1285 (Conv2D)           (None, 32, 32, 16)   2320        ['activation_1269[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1270 (Batc  (None, 32, 32, 16)  64          ['conv2d_1285[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1270 (Activation)   (None, 32, 32, 16)   0           ['batch_normalization_1270[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1286 (Conv2D)           (None, 32, 32, 64)   1088        ['activation_1270[0][0]']        \n",
      "                                                                                                  \n",
      " add_424 (Add)                  (None, 32, 32, 64)   0           ['add_423[0][0]',                \n",
      "                                                                  'conv2d_1286[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1271 (Batc  (None, 32, 32, 64)  256         ['add_424[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1271 (Activation)   (None, 32, 32, 64)   0           ['batch_normalization_1271[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1287 (Conv2D)           (None, 32, 32, 16)   1040        ['activation_1271[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1272 (Batc  (None, 32, 32, 16)  64          ['conv2d_1287[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1272 (Activation)   (None, 32, 32, 16)   0           ['batch_normalization_1272[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1288 (Conv2D)           (None, 32, 32, 16)   2320        ['activation_1272[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1273 (Batc  (None, 32, 32, 16)  64          ['conv2d_1288[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " activation_1273 (Activation)   (None, 32, 32, 16)   0           ['batch_normalization_1273[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1289 (Conv2D)           (None, 32, 32, 64)   1088        ['activation_1273[0][0]']        \n",
      "                                                                                                  \n",
      " add_425 (Add)                  (None, 32, 32, 64)   0           ['add_424[0][0]',                \n",
      "                                                                  'conv2d_1289[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1274 (Batc  (None, 32, 32, 64)  256         ['add_425[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1274 (Activation)   (None, 32, 32, 64)   0           ['batch_normalization_1274[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1290 (Conv2D)           (None, 32, 32, 16)   1040        ['activation_1274[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1275 (Batc  (None, 32, 32, 16)  64          ['conv2d_1290[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1275 (Activation)   (None, 32, 32, 16)   0           ['batch_normalization_1275[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1291 (Conv2D)           (None, 32, 32, 16)   2320        ['activation_1275[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1276 (Batc  (None, 32, 32, 16)  64          ['conv2d_1291[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1276 (Activation)   (None, 32, 32, 16)   0           ['batch_normalization_1276[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1292 (Conv2D)           (None, 32, 32, 64)   1088        ['activation_1276[0][0]']        \n",
      "                                                                                                  \n",
      " add_426 (Add)                  (None, 32, 32, 64)   0           ['add_425[0][0]',                \n",
      "                                                                  'conv2d_1292[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1277 (Batc  (None, 32, 32, 64)  256         ['add_426[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1277 (Activation)   (None, 32, 32, 64)   0           ['batch_normalization_1277[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1293 (Conv2D)           (None, 32, 32, 16)   1040        ['activation_1277[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1278 (Batc  (None, 32, 32, 16)  64          ['conv2d_1293[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1278 (Activation)   (None, 32, 32, 16)   0           ['batch_normalization_1278[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1294 (Conv2D)           (None, 32, 32, 16)   2320        ['activation_1278[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1279 (Batc  (None, 32, 32, 16)  64          ['conv2d_1294[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1279 (Activation)   (None, 32, 32, 16)   0           ['batch_normalization_1279[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1295 (Conv2D)           (None, 32, 32, 64)   1088        ['activation_1279[0][0]']        \n",
      "                                                                                                  \n",
      " add_427 (Add)                  (None, 32, 32, 64)   0           ['add_426[0][0]',                \n",
      "                                                                  'conv2d_1295[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1280 (Batc  (None, 32, 32, 64)  256         ['add_427[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1280 (Activation)   (None, 32, 32, 64)   0           ['batch_normalization_1280[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1296 (Conv2D)           (None, 32, 32, 16)   1040        ['activation_1280[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1281 (Batc  (None, 32, 32, 16)  64          ['conv2d_1296[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1281 (Activation)   (None, 32, 32, 16)   0           ['batch_normalization_1281[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1297 (Conv2D)           (None, 32, 32, 16)   2320        ['activation_1281[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1282 (Batc  (None, 32, 32, 16)  64          ['conv2d_1297[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1282 (Activation)   (None, 32, 32, 16)   0           ['batch_normalization_1282[0][0]'\n",
      "                                                                 ]                                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " conv2d_1298 (Conv2D)           (None, 32, 32, 64)   1088        ['activation_1282[0][0]']        \n",
      "                                                                                                  \n",
      " add_428 (Add)                  (None, 32, 32, 64)   0           ['add_427[0][0]',                \n",
      "                                                                  'conv2d_1298[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1283 (Batc  (None, 32, 32, 64)  256         ['add_428[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1283 (Activation)   (None, 32, 32, 64)   0           ['batch_normalization_1283[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1299 (Conv2D)           (None, 32, 32, 16)   1040        ['activation_1283[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1284 (Batc  (None, 32, 32, 16)  64          ['conv2d_1299[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1284 (Activation)   (None, 32, 32, 16)   0           ['batch_normalization_1284[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1300 (Conv2D)           (None, 32, 32, 16)   2320        ['activation_1284[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1285 (Batc  (None, 32, 32, 16)  64          ['conv2d_1300[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1285 (Activation)   (None, 32, 32, 16)   0           ['batch_normalization_1285[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1301 (Conv2D)           (None, 32, 32, 64)   1088        ['activation_1285[0][0]']        \n",
      "                                                                                                  \n",
      " add_429 (Add)                  (None, 32, 32, 64)   0           ['add_428[0][0]',                \n",
      "                                                                  'conv2d_1301[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1286 (Batc  (None, 32, 32, 64)  256         ['add_429[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1286 (Activation)   (None, 32, 32, 64)   0           ['batch_normalization_1286[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1302 (Conv2D)           (None, 32, 32, 16)   1040        ['activation_1286[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1287 (Batc  (None, 32, 32, 16)  64          ['conv2d_1302[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1287 (Activation)   (None, 32, 32, 16)   0           ['batch_normalization_1287[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1303 (Conv2D)           (None, 32, 32, 16)   2320        ['activation_1287[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1288 (Batc  (None, 32, 32, 16)  64          ['conv2d_1303[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1288 (Activation)   (None, 32, 32, 16)   0           ['batch_normalization_1288[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1304 (Conv2D)           (None, 32, 32, 64)   1088        ['activation_1288[0][0]']        \n",
      "                                                                                                  \n",
      " add_430 (Add)                  (None, 32, 32, 64)   0           ['add_429[0][0]',                \n",
      "                                                                  'conv2d_1304[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1289 (Batc  (None, 32, 32, 64)  256         ['add_430[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1289 (Activation)   (None, 32, 32, 64)   0           ['batch_normalization_1289[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1305 (Conv2D)           (None, 32, 32, 16)   1040        ['activation_1289[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1290 (Batc  (None, 32, 32, 16)  64          ['conv2d_1305[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1290 (Activation)   (None, 32, 32, 16)   0           ['batch_normalization_1290[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1306 (Conv2D)           (None, 32, 32, 16)   2320        ['activation_1290[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1291 (Batc  (None, 32, 32, 16)  64          ['conv2d_1306[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1291 (Activation)   (None, 32, 32, 16)   0           ['batch_normalization_1291[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1307 (Conv2D)           (None, 32, 32, 64)   1088        ['activation_1291[0][0]']        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " add_431 (Add)                  (None, 32, 32, 64)   0           ['add_430[0][0]',                \n",
      "                                                                  'conv2d_1307[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1292 (Batc  (None, 32, 32, 64)  256         ['add_431[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1292 (Activation)   (None, 32, 32, 64)   0           ['batch_normalization_1292[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1308 (Conv2D)           (None, 32, 32, 16)   1040        ['activation_1292[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1293 (Batc  (None, 32, 32, 16)  64          ['conv2d_1308[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1293 (Activation)   (None, 32, 32, 16)   0           ['batch_normalization_1293[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1309 (Conv2D)           (None, 32, 32, 16)   2320        ['activation_1293[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1294 (Batc  (None, 32, 32, 16)  64          ['conv2d_1309[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1294 (Activation)   (None, 32, 32, 16)   0           ['batch_normalization_1294[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1310 (Conv2D)           (None, 32, 32, 64)   1088        ['activation_1294[0][0]']        \n",
      "                                                                                                  \n",
      " add_432 (Add)                  (None, 32, 32, 64)   0           ['add_431[0][0]',                \n",
      "                                                                  'conv2d_1310[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1295 (Batc  (None, 32, 32, 64)  256         ['add_432[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1295 (Activation)   (None, 32, 32, 64)   0           ['batch_normalization_1295[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1311 (Conv2D)           (None, 32, 32, 16)   1040        ['activation_1295[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1296 (Batc  (None, 32, 32, 16)  64          ['conv2d_1311[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1296 (Activation)   (None, 32, 32, 16)   0           ['batch_normalization_1296[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1312 (Conv2D)           (None, 32, 32, 16)   2320        ['activation_1296[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1297 (Batc  (None, 32, 32, 16)  64          ['conv2d_1312[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1297 (Activation)   (None, 32, 32, 16)   0           ['batch_normalization_1297[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1313 (Conv2D)           (None, 32, 32, 64)   1088        ['activation_1297[0][0]']        \n",
      "                                                                                                  \n",
      " add_433 (Add)                  (None, 32, 32, 64)   0           ['add_432[0][0]',                \n",
      "                                                                  'conv2d_1313[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1298 (Batc  (None, 32, 32, 64)  256         ['add_433[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1298 (Activation)   (None, 32, 32, 64)   0           ['batch_normalization_1298[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1314 (Conv2D)           (None, 32, 32, 16)   1040        ['activation_1298[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1299 (Batc  (None, 32, 32, 16)  64          ['conv2d_1314[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1299 (Activation)   (None, 32, 32, 16)   0           ['batch_normalization_1299[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1315 (Conv2D)           (None, 32, 32, 16)   2320        ['activation_1299[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1300 (Batc  (None, 32, 32, 16)  64          ['conv2d_1315[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1300 (Activation)   (None, 32, 32, 16)   0           ['batch_normalization_1300[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1316 (Conv2D)           (None, 32, 32, 64)   1088        ['activation_1300[0][0]']        \n",
      "                                                                                                  \n",
      " add_434 (Add)                  (None, 32, 32, 64)   0           ['add_433[0][0]',                \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                  'conv2d_1316[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1301 (Batc  (None, 32, 32, 64)  256         ['add_434[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1301 (Activation)   (None, 32, 32, 64)   0           ['batch_normalization_1301[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1317 (Conv2D)           (None, 32, 32, 16)   1040        ['activation_1301[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1302 (Batc  (None, 32, 32, 16)  64          ['conv2d_1317[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1302 (Activation)   (None, 32, 32, 16)   0           ['batch_normalization_1302[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1318 (Conv2D)           (None, 32, 32, 16)   2320        ['activation_1302[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1303 (Batc  (None, 32, 32, 16)  64          ['conv2d_1318[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1303 (Activation)   (None, 32, 32, 16)   0           ['batch_normalization_1303[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1319 (Conv2D)           (None, 32, 32, 64)   1088        ['activation_1303[0][0]']        \n",
      "                                                                                                  \n",
      " add_435 (Add)                  (None, 32, 32, 64)   0           ['add_434[0][0]',                \n",
      "                                                                  'conv2d_1319[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1304 (Batc  (None, 32, 32, 64)  256         ['add_435[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1304 (Activation)   (None, 32, 32, 64)   0           ['batch_normalization_1304[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1320 (Conv2D)           (None, 32, 32, 16)   1040        ['activation_1304[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1305 (Batc  (None, 32, 32, 16)  64          ['conv2d_1320[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1305 (Activation)   (None, 32, 32, 16)   0           ['batch_normalization_1305[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1321 (Conv2D)           (None, 32, 32, 16)   2320        ['activation_1305[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1306 (Batc  (None, 32, 32, 16)  64          ['conv2d_1321[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1306 (Activation)   (None, 32, 32, 16)   0           ['batch_normalization_1306[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1322 (Conv2D)           (None, 32, 32, 64)   1088        ['activation_1306[0][0]']        \n",
      "                                                                                                  \n",
      " add_436 (Add)                  (None, 32, 32, 64)   0           ['add_435[0][0]',                \n",
      "                                                                  'conv2d_1322[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1307 (Batc  (None, 32, 32, 64)  256         ['add_436[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1307 (Activation)   (None, 32, 32, 64)   0           ['batch_normalization_1307[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1323 (Conv2D)           (None, 32, 32, 16)   1040        ['activation_1307[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1308 (Batc  (None, 32, 32, 16)  64          ['conv2d_1323[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1308 (Activation)   (None, 32, 32, 16)   0           ['batch_normalization_1308[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1324 (Conv2D)           (None, 32, 32, 16)   2320        ['activation_1308[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1309 (Batc  (None, 32, 32, 16)  64          ['conv2d_1324[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1309 (Activation)   (None, 32, 32, 16)   0           ['batch_normalization_1309[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1325 (Conv2D)           (None, 32, 32, 64)   1088        ['activation_1309[0][0]']        \n",
      "                                                                                                  \n",
      " add_437 (Add)                  (None, 32, 32, 64)   0           ['add_436[0][0]',                \n",
      "                                                                  'conv2d_1325[0][0]']            \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_normalization_1310 (Batc  (None, 32, 32, 64)  256         ['add_437[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1310 (Activation)   (None, 32, 32, 64)   0           ['batch_normalization_1310[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1326 (Conv2D)           (None, 32, 32, 16)   1040        ['activation_1310[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1311 (Batc  (None, 32, 32, 16)  64          ['conv2d_1326[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1311 (Activation)   (None, 32, 32, 16)   0           ['batch_normalization_1311[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1327 (Conv2D)           (None, 32, 32, 16)   2320        ['activation_1311[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1312 (Batc  (None, 32, 32, 16)  64          ['conv2d_1327[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1312 (Activation)   (None, 32, 32, 16)   0           ['batch_normalization_1312[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1328 (Conv2D)           (None, 32, 32, 64)   1088        ['activation_1312[0][0]']        \n",
      "                                                                                                  \n",
      " add_438 (Add)                  (None, 32, 32, 64)   0           ['add_437[0][0]',                \n",
      "                                                                  'conv2d_1328[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1313 (Batc  (None, 32, 32, 64)  256         ['add_438[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1313 (Activation)   (None, 32, 32, 64)   0           ['batch_normalization_1313[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1329 (Conv2D)           (None, 32, 32, 16)   1040        ['activation_1313[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1314 (Batc  (None, 32, 32, 16)  64          ['conv2d_1329[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1314 (Activation)   (None, 32, 32, 16)   0           ['batch_normalization_1314[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1330 (Conv2D)           (None, 32, 32, 16)   2320        ['activation_1314[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1315 (Batc  (None, 32, 32, 16)  64          ['conv2d_1330[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1315 (Activation)   (None, 32, 32, 16)   0           ['batch_normalization_1315[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1331 (Conv2D)           (None, 32, 32, 64)   1088        ['activation_1315[0][0]']        \n",
      "                                                                                                  \n",
      " add_439 (Add)                  (None, 32, 32, 64)   0           ['add_438[0][0]',                \n",
      "                                                                  'conv2d_1331[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1316 (Batc  (None, 32, 32, 64)  256         ['add_439[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1316 (Activation)   (None, 32, 32, 64)   0           ['batch_normalization_1316[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1332 (Conv2D)           (None, 32, 32, 16)   1040        ['activation_1316[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1317 (Batc  (None, 32, 32, 16)  64          ['conv2d_1332[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1317 (Activation)   (None, 32, 32, 16)   0           ['batch_normalization_1317[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1333 (Conv2D)           (None, 32, 32, 16)   2320        ['activation_1317[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1318 (Batc  (None, 32, 32, 16)  64          ['conv2d_1333[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1318 (Activation)   (None, 32, 32, 16)   0           ['batch_normalization_1318[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1334 (Conv2D)           (None, 32, 32, 64)   1088        ['activation_1318[0][0]']        \n",
      "                                                                                                  \n",
      " add_440 (Add)                  (None, 32, 32, 64)   0           ['add_439[0][0]',                \n",
      "                                                                  'conv2d_1334[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1319 (Batc  (None, 32, 32, 64)  256         ['add_440[0][0]']                \n",
      " hNormalization)                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " activation_1319 (Activation)   (None, 32, 32, 64)   0           ['batch_normalization_1319[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1335 (Conv2D)           (None, 16, 16, 64)   4160        ['activation_1319[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1320 (Batc  (None, 16, 16, 64)  256         ['conv2d_1335[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1320 (Activation)   (None, 16, 16, 64)   0           ['batch_normalization_1320[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1336 (Conv2D)           (None, 16, 16, 64)   36928       ['activation_1320[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1321 (Batc  (None, 16, 16, 64)  256         ['conv2d_1336[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1321 (Activation)   (None, 16, 16, 64)   0           ['batch_normalization_1321[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1338 (Conv2D)           (None, 16, 16, 128)  8320        ['add_440[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_1337 (Conv2D)           (None, 16, 16, 128)  8320        ['activation_1321[0][0]']        \n",
      "                                                                                                  \n",
      " add_441 (Add)                  (None, 16, 16, 128)  0           ['conv2d_1338[0][0]',            \n",
      "                                                                  'conv2d_1337[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1322 (Batc  (None, 16, 16, 128)  512        ['add_441[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1322 (Activation)   (None, 16, 16, 128)  0           ['batch_normalization_1322[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1339 (Conv2D)           (None, 16, 16, 64)   8256        ['activation_1322[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1323 (Batc  (None, 16, 16, 64)  256         ['conv2d_1339[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1323 (Activation)   (None, 16, 16, 64)   0           ['batch_normalization_1323[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1340 (Conv2D)           (None, 16, 16, 64)   36928       ['activation_1323[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1324 (Batc  (None, 16, 16, 64)  256         ['conv2d_1340[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1324 (Activation)   (None, 16, 16, 64)   0           ['batch_normalization_1324[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1341 (Conv2D)           (None, 16, 16, 128)  8320        ['activation_1324[0][0]']        \n",
      "                                                                                                  \n",
      " add_442 (Add)                  (None, 16, 16, 128)  0           ['add_441[0][0]',                \n",
      "                                                                  'conv2d_1341[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1325 (Batc  (None, 16, 16, 128)  512        ['add_442[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1325 (Activation)   (None, 16, 16, 128)  0           ['batch_normalization_1325[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1342 (Conv2D)           (None, 16, 16, 64)   8256        ['activation_1325[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1326 (Batc  (None, 16, 16, 64)  256         ['conv2d_1342[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1326 (Activation)   (None, 16, 16, 64)   0           ['batch_normalization_1326[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1343 (Conv2D)           (None, 16, 16, 64)   36928       ['activation_1326[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1327 (Batc  (None, 16, 16, 64)  256         ['conv2d_1343[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1327 (Activation)   (None, 16, 16, 64)   0           ['batch_normalization_1327[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1344 (Conv2D)           (None, 16, 16, 128)  8320        ['activation_1327[0][0]']        \n",
      "                                                                                                  \n",
      " add_443 (Add)                  (None, 16, 16, 128)  0           ['add_442[0][0]',                \n",
      "                                                                  'conv2d_1344[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1328 (Batc  (None, 16, 16, 128)  512        ['add_443[0][0]']                \n",
      " hNormalization)                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " activation_1328 (Activation)   (None, 16, 16, 128)  0           ['batch_normalization_1328[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1345 (Conv2D)           (None, 16, 16, 64)   8256        ['activation_1328[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1329 (Batc  (None, 16, 16, 64)  256         ['conv2d_1345[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1329 (Activation)   (None, 16, 16, 64)   0           ['batch_normalization_1329[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1346 (Conv2D)           (None, 16, 16, 64)   36928       ['activation_1329[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1330 (Batc  (None, 16, 16, 64)  256         ['conv2d_1346[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1330 (Activation)   (None, 16, 16, 64)   0           ['batch_normalization_1330[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1347 (Conv2D)           (None, 16, 16, 128)  8320        ['activation_1330[0][0]']        \n",
      "                                                                                                  \n",
      " add_444 (Add)                  (None, 16, 16, 128)  0           ['add_443[0][0]',                \n",
      "                                                                  'conv2d_1347[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1331 (Batc  (None, 16, 16, 128)  512        ['add_444[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1331 (Activation)   (None, 16, 16, 128)  0           ['batch_normalization_1331[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1348 (Conv2D)           (None, 16, 16, 64)   8256        ['activation_1331[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1332 (Batc  (None, 16, 16, 64)  256         ['conv2d_1348[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1332 (Activation)   (None, 16, 16, 64)   0           ['batch_normalization_1332[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1349 (Conv2D)           (None, 16, 16, 64)   36928       ['activation_1332[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1333 (Batc  (None, 16, 16, 64)  256         ['conv2d_1349[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1333 (Activation)   (None, 16, 16, 64)   0           ['batch_normalization_1333[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1350 (Conv2D)           (None, 16, 16, 128)  8320        ['activation_1333[0][0]']        \n",
      "                                                                                                  \n",
      " add_445 (Add)                  (None, 16, 16, 128)  0           ['add_444[0][0]',                \n",
      "                                                                  'conv2d_1350[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1334 (Batc  (None, 16, 16, 128)  512        ['add_445[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1334 (Activation)   (None, 16, 16, 128)  0           ['batch_normalization_1334[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1351 (Conv2D)           (None, 16, 16, 64)   8256        ['activation_1334[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1335 (Batc  (None, 16, 16, 64)  256         ['conv2d_1351[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1335 (Activation)   (None, 16, 16, 64)   0           ['batch_normalization_1335[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1352 (Conv2D)           (None, 16, 16, 64)   36928       ['activation_1335[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1336 (Batc  (None, 16, 16, 64)  256         ['conv2d_1352[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1336 (Activation)   (None, 16, 16, 64)   0           ['batch_normalization_1336[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1353 (Conv2D)           (None, 16, 16, 128)  8320        ['activation_1336[0][0]']        \n",
      "                                                                                                  \n",
      " add_446 (Add)                  (None, 16, 16, 128)  0           ['add_445[0][0]',                \n",
      "                                                                  'conv2d_1353[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1337 (Batc  (None, 16, 16, 128)  512        ['add_446[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1337 (Activation)   (None, 16, 16, 128)  0           ['batch_normalization_1337[0][0]'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1354 (Conv2D)           (None, 16, 16, 64)   8256        ['activation_1337[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1338 (Batc  (None, 16, 16, 64)  256         ['conv2d_1354[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1338 (Activation)   (None, 16, 16, 64)   0           ['batch_normalization_1338[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1355 (Conv2D)           (None, 16, 16, 64)   36928       ['activation_1338[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1339 (Batc  (None, 16, 16, 64)  256         ['conv2d_1355[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1339 (Activation)   (None, 16, 16, 64)   0           ['batch_normalization_1339[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1356 (Conv2D)           (None, 16, 16, 128)  8320        ['activation_1339[0][0]']        \n",
      "                                                                                                  \n",
      " add_447 (Add)                  (None, 16, 16, 128)  0           ['add_446[0][0]',                \n",
      "                                                                  'conv2d_1356[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1340 (Batc  (None, 16, 16, 128)  512        ['add_447[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1340 (Activation)   (None, 16, 16, 128)  0           ['batch_normalization_1340[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1357 (Conv2D)           (None, 16, 16, 64)   8256        ['activation_1340[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1341 (Batc  (None, 16, 16, 64)  256         ['conv2d_1357[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1341 (Activation)   (None, 16, 16, 64)   0           ['batch_normalization_1341[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1358 (Conv2D)           (None, 16, 16, 64)   36928       ['activation_1341[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1342 (Batc  (None, 16, 16, 64)  256         ['conv2d_1358[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1342 (Activation)   (None, 16, 16, 64)   0           ['batch_normalization_1342[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1359 (Conv2D)           (None, 16, 16, 128)  8320        ['activation_1342[0][0]']        \n",
      "                                                                                                  \n",
      " add_448 (Add)                  (None, 16, 16, 128)  0           ['add_447[0][0]',                \n",
      "                                                                  'conv2d_1359[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1343 (Batc  (None, 16, 16, 128)  512        ['add_448[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1343 (Activation)   (None, 16, 16, 128)  0           ['batch_normalization_1343[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1360 (Conv2D)           (None, 16, 16, 64)   8256        ['activation_1343[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1344 (Batc  (None, 16, 16, 64)  256         ['conv2d_1360[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1344 (Activation)   (None, 16, 16, 64)   0           ['batch_normalization_1344[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1361 (Conv2D)           (None, 16, 16, 64)   36928       ['activation_1344[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1345 (Batc  (None, 16, 16, 64)  256         ['conv2d_1361[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1345 (Activation)   (None, 16, 16, 64)   0           ['batch_normalization_1345[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1362 (Conv2D)           (None, 16, 16, 128)  8320        ['activation_1345[0][0]']        \n",
      "                                                                                                  \n",
      " add_449 (Add)                  (None, 16, 16, 128)  0           ['add_448[0][0]',                \n",
      "                                                                  'conv2d_1362[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1346 (Batc  (None, 16, 16, 128)  512        ['add_449[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1346 (Activation)   (None, 16, 16, 128)  0           ['batch_normalization_1346[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv2d_1363 (Conv2D)           (None, 16, 16, 64)   8256        ['activation_1346[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1347 (Batc  (None, 16, 16, 64)  256         ['conv2d_1363[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1347 (Activation)   (None, 16, 16, 64)   0           ['batch_normalization_1347[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1364 (Conv2D)           (None, 16, 16, 64)   36928       ['activation_1347[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1348 (Batc  (None, 16, 16, 64)  256         ['conv2d_1364[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1348 (Activation)   (None, 16, 16, 64)   0           ['batch_normalization_1348[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1365 (Conv2D)           (None, 16, 16, 128)  8320        ['activation_1348[0][0]']        \n",
      "                                                                                                  \n",
      " add_450 (Add)                  (None, 16, 16, 128)  0           ['add_449[0][0]',                \n",
      "                                                                  'conv2d_1365[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1349 (Batc  (None, 16, 16, 128)  512        ['add_450[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1349 (Activation)   (None, 16, 16, 128)  0           ['batch_normalization_1349[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1366 (Conv2D)           (None, 16, 16, 64)   8256        ['activation_1349[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1350 (Batc  (None, 16, 16, 64)  256         ['conv2d_1366[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1350 (Activation)   (None, 16, 16, 64)   0           ['batch_normalization_1350[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1367 (Conv2D)           (None, 16, 16, 64)   36928       ['activation_1350[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1351 (Batc  (None, 16, 16, 64)  256         ['conv2d_1367[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1351 (Activation)   (None, 16, 16, 64)   0           ['batch_normalization_1351[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1368 (Conv2D)           (None, 16, 16, 128)  8320        ['activation_1351[0][0]']        \n",
      "                                                                                                  \n",
      " add_451 (Add)                  (None, 16, 16, 128)  0           ['add_450[0][0]',                \n",
      "                                                                  'conv2d_1368[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1352 (Batc  (None, 16, 16, 128)  512        ['add_451[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1352 (Activation)   (None, 16, 16, 128)  0           ['batch_normalization_1352[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1369 (Conv2D)           (None, 16, 16, 64)   8256        ['activation_1352[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1353 (Batc  (None, 16, 16, 64)  256         ['conv2d_1369[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1353 (Activation)   (None, 16, 16, 64)   0           ['batch_normalization_1353[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1370 (Conv2D)           (None, 16, 16, 64)   36928       ['activation_1353[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1354 (Batc  (None, 16, 16, 64)  256         ['conv2d_1370[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1354 (Activation)   (None, 16, 16, 64)   0           ['batch_normalization_1354[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1371 (Conv2D)           (None, 16, 16, 128)  8320        ['activation_1354[0][0]']        \n",
      "                                                                                                  \n",
      " add_452 (Add)                  (None, 16, 16, 128)  0           ['add_451[0][0]',                \n",
      "                                                                  'conv2d_1371[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1355 (Batc  (None, 16, 16, 128)  512        ['add_452[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1355 (Activation)   (None, 16, 16, 128)  0           ['batch_normalization_1355[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1372 (Conv2D)           (None, 16, 16, 64)   8256        ['activation_1355[0][0]']        \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_normalization_1356 (Batc  (None, 16, 16, 64)  256         ['conv2d_1372[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1356 (Activation)   (None, 16, 16, 64)   0           ['batch_normalization_1356[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1373 (Conv2D)           (None, 16, 16, 64)   36928       ['activation_1356[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1357 (Batc  (None, 16, 16, 64)  256         ['conv2d_1373[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1357 (Activation)   (None, 16, 16, 64)   0           ['batch_normalization_1357[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1374 (Conv2D)           (None, 16, 16, 128)  8320        ['activation_1357[0][0]']        \n",
      "                                                                                                  \n",
      " add_453 (Add)                  (None, 16, 16, 128)  0           ['add_452[0][0]',                \n",
      "                                                                  'conv2d_1374[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1358 (Batc  (None, 16, 16, 128)  512        ['add_453[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1358 (Activation)   (None, 16, 16, 128)  0           ['batch_normalization_1358[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1375 (Conv2D)           (None, 16, 16, 64)   8256        ['activation_1358[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1359 (Batc  (None, 16, 16, 64)  256         ['conv2d_1375[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1359 (Activation)   (None, 16, 16, 64)   0           ['batch_normalization_1359[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1376 (Conv2D)           (None, 16, 16, 64)   36928       ['activation_1359[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1360 (Batc  (None, 16, 16, 64)  256         ['conv2d_1376[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1360 (Activation)   (None, 16, 16, 64)   0           ['batch_normalization_1360[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1377 (Conv2D)           (None, 16, 16, 128)  8320        ['activation_1360[0][0]']        \n",
      "                                                                                                  \n",
      " add_454 (Add)                  (None, 16, 16, 128)  0           ['add_453[0][0]',                \n",
      "                                                                  'conv2d_1377[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1361 (Batc  (None, 16, 16, 128)  512        ['add_454[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1361 (Activation)   (None, 16, 16, 128)  0           ['batch_normalization_1361[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1378 (Conv2D)           (None, 16, 16, 64)   8256        ['activation_1361[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1362 (Batc  (None, 16, 16, 64)  256         ['conv2d_1378[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1362 (Activation)   (None, 16, 16, 64)   0           ['batch_normalization_1362[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1379 (Conv2D)           (None, 16, 16, 64)   36928       ['activation_1362[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1363 (Batc  (None, 16, 16, 64)  256         ['conv2d_1379[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1363 (Activation)   (None, 16, 16, 64)   0           ['batch_normalization_1363[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1380 (Conv2D)           (None, 16, 16, 128)  8320        ['activation_1363[0][0]']        \n",
      "                                                                                                  \n",
      " add_455 (Add)                  (None, 16, 16, 128)  0           ['add_454[0][0]',                \n",
      "                                                                  'conv2d_1380[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1364 (Batc  (None, 16, 16, 128)  512        ['add_455[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1364 (Activation)   (None, 16, 16, 128)  0           ['batch_normalization_1364[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1381 (Conv2D)           (None, 16, 16, 64)   8256        ['activation_1364[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1365 (Batc  (None, 16, 16, 64)  256         ['conv2d_1381[0][0]']            \n",
      " hNormalization)                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " activation_1365 (Activation)   (None, 16, 16, 64)   0           ['batch_normalization_1365[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1382 (Conv2D)           (None, 16, 16, 64)   36928       ['activation_1365[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1366 (Batc  (None, 16, 16, 64)  256         ['conv2d_1382[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1366 (Activation)   (None, 16, 16, 64)   0           ['batch_normalization_1366[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1383 (Conv2D)           (None, 16, 16, 128)  8320        ['activation_1366[0][0]']        \n",
      "                                                                                                  \n",
      " add_456 (Add)                  (None, 16, 16, 128)  0           ['add_455[0][0]',                \n",
      "                                                                  'conv2d_1383[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1367 (Batc  (None, 16, 16, 128)  512        ['add_456[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1367 (Activation)   (None, 16, 16, 128)  0           ['batch_normalization_1367[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1384 (Conv2D)           (None, 16, 16, 64)   8256        ['activation_1367[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1368 (Batc  (None, 16, 16, 64)  256         ['conv2d_1384[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1368 (Activation)   (None, 16, 16, 64)   0           ['batch_normalization_1368[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1385 (Conv2D)           (None, 16, 16, 64)   36928       ['activation_1368[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1369 (Batc  (None, 16, 16, 64)  256         ['conv2d_1385[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1369 (Activation)   (None, 16, 16, 64)   0           ['batch_normalization_1369[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1386 (Conv2D)           (None, 16, 16, 128)  8320        ['activation_1369[0][0]']        \n",
      "                                                                                                  \n",
      " add_457 (Add)                  (None, 16, 16, 128)  0           ['add_456[0][0]',                \n",
      "                                                                  'conv2d_1386[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1370 (Batc  (None, 16, 16, 128)  512        ['add_457[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1370 (Activation)   (None, 16, 16, 128)  0           ['batch_normalization_1370[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1387 (Conv2D)           (None, 16, 16, 64)   8256        ['activation_1370[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1371 (Batc  (None, 16, 16, 64)  256         ['conv2d_1387[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1371 (Activation)   (None, 16, 16, 64)   0           ['batch_normalization_1371[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1388 (Conv2D)           (None, 16, 16, 64)   36928       ['activation_1371[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1372 (Batc  (None, 16, 16, 64)  256         ['conv2d_1388[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1372 (Activation)   (None, 16, 16, 64)   0           ['batch_normalization_1372[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1389 (Conv2D)           (None, 16, 16, 128)  8320        ['activation_1372[0][0]']        \n",
      "                                                                                                  \n",
      " add_458 (Add)                  (None, 16, 16, 128)  0           ['add_457[0][0]',                \n",
      "                                                                  'conv2d_1389[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1373 (Batc  (None, 16, 16, 128)  512        ['add_458[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1373 (Activation)   (None, 16, 16, 128)  0           ['batch_normalization_1373[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1390 (Conv2D)           (None, 8, 8, 128)    16512       ['activation_1373[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1374 (Batc  (None, 8, 8, 128)   512         ['conv2d_1390[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1374 (Activation)   (None, 8, 8, 128)    0           ['batch_normalization_1374[0][0]'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1391 (Conv2D)           (None, 8, 8, 128)    147584      ['activation_1374[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1375 (Batc  (None, 8, 8, 128)   512         ['conv2d_1391[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1375 (Activation)   (None, 8, 8, 128)    0           ['batch_normalization_1375[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1393 (Conv2D)           (None, 8, 8, 256)    33024       ['add_458[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_1392 (Conv2D)           (None, 8, 8, 256)    33024       ['activation_1375[0][0]']        \n",
      "                                                                                                  \n",
      " add_459 (Add)                  (None, 8, 8, 256)    0           ['conv2d_1393[0][0]',            \n",
      "                                                                  'conv2d_1392[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1376 (Batc  (None, 8, 8, 256)   1024        ['add_459[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1376 (Activation)   (None, 8, 8, 256)    0           ['batch_normalization_1376[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1394 (Conv2D)           (None, 8, 8, 128)    32896       ['activation_1376[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1377 (Batc  (None, 8, 8, 128)   512         ['conv2d_1394[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1377 (Activation)   (None, 8, 8, 128)    0           ['batch_normalization_1377[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1395 (Conv2D)           (None, 8, 8, 128)    147584      ['activation_1377[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1378 (Batc  (None, 8, 8, 128)   512         ['conv2d_1395[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1378 (Activation)   (None, 8, 8, 128)    0           ['batch_normalization_1378[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1396 (Conv2D)           (None, 8, 8, 256)    33024       ['activation_1378[0][0]']        \n",
      "                                                                                                  \n",
      " add_460 (Add)                  (None, 8, 8, 256)    0           ['add_459[0][0]',                \n",
      "                                                                  'conv2d_1396[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1379 (Batc  (None, 8, 8, 256)   1024        ['add_460[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1379 (Activation)   (None, 8, 8, 256)    0           ['batch_normalization_1379[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1397 (Conv2D)           (None, 8, 8, 128)    32896       ['activation_1379[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1380 (Batc  (None, 8, 8, 128)   512         ['conv2d_1397[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1380 (Activation)   (None, 8, 8, 128)    0           ['batch_normalization_1380[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1398 (Conv2D)           (None, 8, 8, 128)    147584      ['activation_1380[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1381 (Batc  (None, 8, 8, 128)   512         ['conv2d_1398[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1381 (Activation)   (None, 8, 8, 128)    0           ['batch_normalization_1381[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1399 (Conv2D)           (None, 8, 8, 256)    33024       ['activation_1381[0][0]']        \n",
      "                                                                                                  \n",
      " add_461 (Add)                  (None, 8, 8, 256)    0           ['add_460[0][0]',                \n",
      "                                                                  'conv2d_1399[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1382 (Batc  (None, 8, 8, 256)   1024        ['add_461[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1382 (Activation)   (None, 8, 8, 256)    0           ['batch_normalization_1382[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1400 (Conv2D)           (None, 8, 8, 128)    32896       ['activation_1382[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1383 (Batc  (None, 8, 8, 128)   512         ['conv2d_1400[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1383 (Activation)   (None, 8, 8, 128)    0           ['batch_normalization_1383[0][0]'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1401 (Conv2D)           (None, 8, 8, 128)    147584      ['activation_1383[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1384 (Batc  (None, 8, 8, 128)   512         ['conv2d_1401[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1384 (Activation)   (None, 8, 8, 128)    0           ['batch_normalization_1384[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1402 (Conv2D)           (None, 8, 8, 256)    33024       ['activation_1384[0][0]']        \n",
      "                                                                                                  \n",
      " add_462 (Add)                  (None, 8, 8, 256)    0           ['add_461[0][0]',                \n",
      "                                                                  'conv2d_1402[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1385 (Batc  (None, 8, 8, 256)   1024        ['add_462[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1385 (Activation)   (None, 8, 8, 256)    0           ['batch_normalization_1385[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1403 (Conv2D)           (None, 8, 8, 128)    32896       ['activation_1385[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1386 (Batc  (None, 8, 8, 128)   512         ['conv2d_1403[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1386 (Activation)   (None, 8, 8, 128)    0           ['batch_normalization_1386[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1404 (Conv2D)           (None, 8, 8, 128)    147584      ['activation_1386[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1387 (Batc  (None, 8, 8, 128)   512         ['conv2d_1404[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1387 (Activation)   (None, 8, 8, 128)    0           ['batch_normalization_1387[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1405 (Conv2D)           (None, 8, 8, 256)    33024       ['activation_1387[0][0]']        \n",
      "                                                                                                  \n",
      " add_463 (Add)                  (None, 8, 8, 256)    0           ['add_462[0][0]',                \n",
      "                                                                  'conv2d_1405[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1388 (Batc  (None, 8, 8, 256)   1024        ['add_463[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1388 (Activation)   (None, 8, 8, 256)    0           ['batch_normalization_1388[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1406 (Conv2D)           (None, 8, 8, 128)    32896       ['activation_1388[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1389 (Batc  (None, 8, 8, 128)   512         ['conv2d_1406[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1389 (Activation)   (None, 8, 8, 128)    0           ['batch_normalization_1389[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1407 (Conv2D)           (None, 8, 8, 128)    147584      ['activation_1389[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1390 (Batc  (None, 8, 8, 128)   512         ['conv2d_1407[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1390 (Activation)   (None, 8, 8, 128)    0           ['batch_normalization_1390[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1408 (Conv2D)           (None, 8, 8, 256)    33024       ['activation_1390[0][0]']        \n",
      "                                                                                                  \n",
      " add_464 (Add)                  (None, 8, 8, 256)    0           ['add_463[0][0]',                \n",
      "                                                                  'conv2d_1408[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1391 (Batc  (None, 8, 8, 256)   1024        ['add_464[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1391 (Activation)   (None, 8, 8, 256)    0           ['batch_normalization_1391[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1409 (Conv2D)           (None, 8, 8, 128)    32896       ['activation_1391[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1392 (Batc  (None, 8, 8, 128)   512         ['conv2d_1409[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1392 (Activation)   (None, 8, 8, 128)    0           ['batch_normalization_1392[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv2d_1410 (Conv2D)           (None, 8, 8, 128)    147584      ['activation_1392[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1393 (Batc  (None, 8, 8, 128)   512         ['conv2d_1410[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1393 (Activation)   (None, 8, 8, 128)    0           ['batch_normalization_1393[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1411 (Conv2D)           (None, 8, 8, 256)    33024       ['activation_1393[0][0]']        \n",
      "                                                                                                  \n",
      " add_465 (Add)                  (None, 8, 8, 256)    0           ['add_464[0][0]',                \n",
      "                                                                  'conv2d_1411[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1394 (Batc  (None, 8, 8, 256)   1024        ['add_465[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1394 (Activation)   (None, 8, 8, 256)    0           ['batch_normalization_1394[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1412 (Conv2D)           (None, 8, 8, 128)    32896       ['activation_1394[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1395 (Batc  (None, 8, 8, 128)   512         ['conv2d_1412[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1395 (Activation)   (None, 8, 8, 128)    0           ['batch_normalization_1395[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1413 (Conv2D)           (None, 8, 8, 128)    147584      ['activation_1395[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1396 (Batc  (None, 8, 8, 128)   512         ['conv2d_1413[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1396 (Activation)   (None, 8, 8, 128)    0           ['batch_normalization_1396[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1414 (Conv2D)           (None, 8, 8, 256)    33024       ['activation_1396[0][0]']        \n",
      "                                                                                                  \n",
      " add_466 (Add)                  (None, 8, 8, 256)    0           ['add_465[0][0]',                \n",
      "                                                                  'conv2d_1414[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1397 (Batc  (None, 8, 8, 256)   1024        ['add_466[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1397 (Activation)   (None, 8, 8, 256)    0           ['batch_normalization_1397[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1415 (Conv2D)           (None, 8, 8, 128)    32896       ['activation_1397[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1398 (Batc  (None, 8, 8, 128)   512         ['conv2d_1415[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1398 (Activation)   (None, 8, 8, 128)    0           ['batch_normalization_1398[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1416 (Conv2D)           (None, 8, 8, 128)    147584      ['activation_1398[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1399 (Batc  (None, 8, 8, 128)   512         ['conv2d_1416[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1399 (Activation)   (None, 8, 8, 128)    0           ['batch_normalization_1399[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1417 (Conv2D)           (None, 8, 8, 256)    33024       ['activation_1399[0][0]']        \n",
      "                                                                                                  \n",
      " add_467 (Add)                  (None, 8, 8, 256)    0           ['add_466[0][0]',                \n",
      "                                                                  'conv2d_1417[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1400 (Batc  (None, 8, 8, 256)   1024        ['add_467[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1400 (Activation)   (None, 8, 8, 256)    0           ['batch_normalization_1400[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1418 (Conv2D)           (None, 8, 8, 128)    32896       ['activation_1400[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1401 (Batc  (None, 8, 8, 128)   512         ['conv2d_1418[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1401 (Activation)   (None, 8, 8, 128)    0           ['batch_normalization_1401[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1419 (Conv2D)           (None, 8, 8, 128)    147584      ['activation_1401[0][0]']        \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " batch_normalization_1402 (Batc  (None, 8, 8, 128)   512         ['conv2d_1419[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1402 (Activation)   (None, 8, 8, 128)    0           ['batch_normalization_1402[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1420 (Conv2D)           (None, 8, 8, 256)    33024       ['activation_1402[0][0]']        \n",
      "                                                                                                  \n",
      " add_468 (Add)                  (None, 8, 8, 256)    0           ['add_467[0][0]',                \n",
      "                                                                  'conv2d_1420[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1403 (Batc  (None, 8, 8, 256)   1024        ['add_468[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1403 (Activation)   (None, 8, 8, 256)    0           ['batch_normalization_1403[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1421 (Conv2D)           (None, 8, 8, 128)    32896       ['activation_1403[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1404 (Batc  (None, 8, 8, 128)   512         ['conv2d_1421[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1404 (Activation)   (None, 8, 8, 128)    0           ['batch_normalization_1404[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1422 (Conv2D)           (None, 8, 8, 128)    147584      ['activation_1404[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1405 (Batc  (None, 8, 8, 128)   512         ['conv2d_1422[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1405 (Activation)   (None, 8, 8, 128)    0           ['batch_normalization_1405[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1423 (Conv2D)           (None, 8, 8, 256)    33024       ['activation_1405[0][0]']        \n",
      "                                                                                                  \n",
      " add_469 (Add)                  (None, 8, 8, 256)    0           ['add_468[0][0]',                \n",
      "                                                                  'conv2d_1423[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1406 (Batc  (None, 8, 8, 256)   1024        ['add_469[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1406 (Activation)   (None, 8, 8, 256)    0           ['batch_normalization_1406[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1424 (Conv2D)           (None, 8, 8, 128)    32896       ['activation_1406[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1407 (Batc  (None, 8, 8, 128)   512         ['conv2d_1424[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1407 (Activation)   (None, 8, 8, 128)    0           ['batch_normalization_1407[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1425 (Conv2D)           (None, 8, 8, 128)    147584      ['activation_1407[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1408 (Batc  (None, 8, 8, 128)   512         ['conv2d_1425[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1408 (Activation)   (None, 8, 8, 128)    0           ['batch_normalization_1408[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1426 (Conv2D)           (None, 8, 8, 256)    33024       ['activation_1408[0][0]']        \n",
      "                                                                                                  \n",
      " add_470 (Add)                  (None, 8, 8, 256)    0           ['add_469[0][0]',                \n",
      "                                                                  'conv2d_1426[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1409 (Batc  (None, 8, 8, 256)   1024        ['add_470[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1409 (Activation)   (None, 8, 8, 256)    0           ['batch_normalization_1409[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1427 (Conv2D)           (None, 8, 8, 128)    32896       ['activation_1409[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1410 (Batc  (None, 8, 8, 128)   512         ['conv2d_1427[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1410 (Activation)   (None, 8, 8, 128)    0           ['batch_normalization_1410[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1428 (Conv2D)           (None, 8, 8, 128)    147584      ['activation_1410[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1411 (Batc  (None, 8, 8, 128)   512         ['conv2d_1428[0][0]']            \n",
      " hNormalization)                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " activation_1411 (Activation)   (None, 8, 8, 128)    0           ['batch_normalization_1411[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1429 (Conv2D)           (None, 8, 8, 256)    33024       ['activation_1411[0][0]']        \n",
      "                                                                                                  \n",
      " add_471 (Add)                  (None, 8, 8, 256)    0           ['add_470[0][0]',                \n",
      "                                                                  'conv2d_1429[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1412 (Batc  (None, 8, 8, 256)   1024        ['add_471[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1412 (Activation)   (None, 8, 8, 256)    0           ['batch_normalization_1412[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1430 (Conv2D)           (None, 8, 8, 128)    32896       ['activation_1412[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1413 (Batc  (None, 8, 8, 128)   512         ['conv2d_1430[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1413 (Activation)   (None, 8, 8, 128)    0           ['batch_normalization_1413[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1431 (Conv2D)           (None, 8, 8, 128)    147584      ['activation_1413[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1414 (Batc  (None, 8, 8, 128)   512         ['conv2d_1431[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1414 (Activation)   (None, 8, 8, 128)    0           ['batch_normalization_1414[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1432 (Conv2D)           (None, 8, 8, 256)    33024       ['activation_1414[0][0]']        \n",
      "                                                                                                  \n",
      " add_472 (Add)                  (None, 8, 8, 256)    0           ['add_471[0][0]',                \n",
      "                                                                  'conv2d_1432[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1415 (Batc  (None, 8, 8, 256)   1024        ['add_472[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1415 (Activation)   (None, 8, 8, 256)    0           ['batch_normalization_1415[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1433 (Conv2D)           (None, 8, 8, 128)    32896       ['activation_1415[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1416 (Batc  (None, 8, 8, 128)   512         ['conv2d_1433[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1416 (Activation)   (None, 8, 8, 128)    0           ['batch_normalization_1416[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1434 (Conv2D)           (None, 8, 8, 128)    147584      ['activation_1416[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1417 (Batc  (None, 8, 8, 128)   512         ['conv2d_1434[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1417 (Activation)   (None, 8, 8, 128)    0           ['batch_normalization_1417[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1435 (Conv2D)           (None, 8, 8, 256)    33024       ['activation_1417[0][0]']        \n",
      "                                                                                                  \n",
      " add_473 (Add)                  (None, 8, 8, 256)    0           ['add_472[0][0]',                \n",
      "                                                                  'conv2d_1435[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1418 (Batc  (None, 8, 8, 256)   1024        ['add_473[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1418 (Activation)   (None, 8, 8, 256)    0           ['batch_normalization_1418[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1436 (Conv2D)           (None, 8, 8, 128)    32896       ['activation_1418[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1419 (Batc  (None, 8, 8, 128)   512         ['conv2d_1436[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1419 (Activation)   (None, 8, 8, 128)    0           ['batch_normalization_1419[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1437 (Conv2D)           (None, 8, 8, 128)    147584      ['activation_1419[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1420 (Batc  (None, 8, 8, 128)   512         ['conv2d_1437[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1420 (Activation)   (None, 8, 8, 128)    0           ['batch_normalization_1420[0][0]'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1438 (Conv2D)           (None, 8, 8, 256)    33024       ['activation_1420[0][0]']        \n",
      "                                                                                                  \n",
      " add_474 (Add)                  (None, 8, 8, 256)    0           ['add_473[0][0]',                \n",
      "                                                                  'conv2d_1438[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1421 (Batc  (None, 8, 8, 256)   1024        ['add_474[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1421 (Activation)   (None, 8, 8, 256)    0           ['batch_normalization_1421[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1439 (Conv2D)           (None, 8, 8, 128)    32896       ['activation_1421[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1422 (Batc  (None, 8, 8, 128)   512         ['conv2d_1439[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1422 (Activation)   (None, 8, 8, 128)    0           ['batch_normalization_1422[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1440 (Conv2D)           (None, 8, 8, 128)    147584      ['activation_1422[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1423 (Batc  (None, 8, 8, 128)   512         ['conv2d_1440[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1423 (Activation)   (None, 8, 8, 128)    0           ['batch_normalization_1423[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1441 (Conv2D)           (None, 8, 8, 256)    33024       ['activation_1423[0][0]']        \n",
      "                                                                                                  \n",
      " add_475 (Add)                  (None, 8, 8, 256)    0           ['add_474[0][0]',                \n",
      "                                                                  'conv2d_1441[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1424 (Batc  (None, 8, 8, 256)   1024        ['add_475[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1424 (Activation)   (None, 8, 8, 256)    0           ['batch_normalization_1424[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1442 (Conv2D)           (None, 8, 8, 128)    32896       ['activation_1424[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1425 (Batc  (None, 8, 8, 128)   512         ['conv2d_1442[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1425 (Activation)   (None, 8, 8, 128)    0           ['batch_normalization_1425[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1443 (Conv2D)           (None, 8, 8, 128)    147584      ['activation_1425[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1426 (Batc  (None, 8, 8, 128)   512         ['conv2d_1443[0][0]']            \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1426 (Activation)   (None, 8, 8, 128)    0           ['batch_normalization_1426[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " conv2d_1444 (Conv2D)           (None, 8, 8, 256)    33024       ['activation_1426[0][0]']        \n",
      "                                                                                                  \n",
      " add_476 (Add)                  (None, 8, 8, 256)    0           ['add_475[0][0]',                \n",
      "                                                                  'conv2d_1444[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1427 (Batc  (None, 8, 8, 256)   1024        ['add_476[0][0]']                \n",
      " hNormalization)                                                                                  \n",
      "                                                                                                  \n",
      " activation_1427 (Activation)   (None, 8, 8, 256)    0           ['batch_normalization_1427[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " average_pooling2d_5 (AveragePo  (None, 1, 1, 256)   0           ['activation_1427[0][0]']        \n",
      " oling2D)                                                                                         \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)            (None, 256)          0           ['average_pooling2d_5[0][0]']    \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 10)           2570        ['flatten_5[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,972,682\n",
      "Trainable params: 4,941,546\n",
      "Non-trainable params: 31,136\n",
      "__________________________________________________________________________________________________\n",
      "ResNet164v2\n",
      "Using real-time data augmentation.\n",
      "Learning rate:  0.001\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yue\\AppData\\Local\\Temp\\ipykernel_5076\\3776652401.py:399: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - ETA: 0s - loss: 2.6567 - accuracy: 0.4820WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 138s 83ms/step - loss: 2.6567 - accuracy: 0.4820 - val_loss: 2.0442 - val_accuracy: 0.5160 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 2/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 1.5967 - accuracy: 0.6220WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 115s 73ms/step - loss: 1.5967 - accuracy: 0.6220 - val_loss: 1.6953 - val_accuracy: 0.5767 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 3/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 1.3689 - accuracy: 0.6731WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 112s 72ms/step - loss: 1.3689 - accuracy: 0.6731 - val_loss: 1.5442 - val_accuracy: 0.6130 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 4/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 1.2329 - accuracy: 0.7103WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 112s 71ms/step - loss: 1.2329 - accuracy: 0.7103 - val_loss: 1.7281 - val_accuracy: 0.5861 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 5/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 1.1366 - accuracy: 0.7339WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 110s 70ms/step - loss: 1.1366 - accuracy: 0.7339 - val_loss: 1.5075 - val_accuracy: 0.6650 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 6/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 1.0666 - accuracy: 0.7514WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 111s 71ms/step - loss: 1.0666 - accuracy: 0.7514 - val_loss: 1.1006 - val_accuracy: 0.7268 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 7/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 1.0036 - accuracy: 0.7700WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 109s 70ms/step - loss: 1.0036 - accuracy: 0.7700 - val_loss: 0.9699 - val_accuracy: 0.7780 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 8/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.9463 - accuracy: 0.7850WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 111s 71ms/step - loss: 0.9463 - accuracy: 0.7850 - val_loss: 1.1432 - val_accuracy: 0.7422 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 9/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.9126 - accuracy: 0.7934WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 110s 70ms/step - loss: 0.9126 - accuracy: 0.7934 - val_loss: 1.1541 - val_accuracy: 0.7174 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 10/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.8772 - accuracy: 0.8011WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 112s 72ms/step - loss: 0.8772 - accuracy: 0.8011 - val_loss: 1.0358 - val_accuracy: 0.7625 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 11/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.8429 - accuracy: 0.8076WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 110s 70ms/step - loss: 0.8429 - accuracy: 0.8076 - val_loss: 0.9314 - val_accuracy: 0.7808 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 12/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.8199 - accuracy: 0.8163WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 111s 71ms/step - loss: 0.8199 - accuracy: 0.8163 - val_loss: 0.8867 - val_accuracy: 0.8005 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 13/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.7944 - accuracy: 0.8228WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 112s 71ms/step - loss: 0.7944 - accuracy: 0.8228 - val_loss: 1.0133 - val_accuracy: 0.7689 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 14/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.7738 - accuracy: 0.8277WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 72ms/step - loss: 0.7738 - accuracy: 0.8277 - val_loss: 0.8571 - val_accuracy: 0.8036 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 15/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.7498 - accuracy: 0.8326WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 110s 71ms/step - loss: 0.7498 - accuracy: 0.8326 - val_loss: 0.9512 - val_accuracy: 0.7879 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 16/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.7394 - accuracy: 0.8365WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 111s 71ms/step - loss: 0.7394 - accuracy: 0.8365 - val_loss: 0.8844 - val_accuracy: 0.7969 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 17/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.7256 - accuracy: 0.8394WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 72ms/step - loss: 0.7256 - accuracy: 0.8394 - val_loss: 0.9056 - val_accuracy: 0.7865 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 18/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.7120 - accuracy: 0.8435WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: 0.7120 - accuracy: 0.8435 - val_loss: 0.9770 - val_accuracy: 0.7785 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 19/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6921 - accuracy: 0.8484WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 72ms/step - loss: 0.6921 - accuracy: 0.8484 - val_loss: 1.0366 - val_accuracy: 0.7592 - lr: 3.1623e-04\n",
      "Learning rate:  0.001\n",
      "Epoch 20/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6885 - accuracy: 0.8482WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 110s 70ms/step - loss: 0.6885 - accuracy: 0.8482 - val_loss: 0.8835 - val_accuracy: 0.7963 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 21/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6772 - accuracy: 0.8524WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 111s 71ms/step - loss: 0.6772 - accuracy: 0.8524 - val_loss: 1.2942 - val_accuracy: 0.7019 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 22/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6639 - accuracy: 0.8555WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 72ms/step - loss: 0.6639 - accuracy: 0.8555 - val_loss: 0.8952 - val_accuracy: 0.7870 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 23/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6605 - accuracy: 0.8580WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 109s 69ms/step - loss: 0.6605 - accuracy: 0.8580 - val_loss: 0.8441 - val_accuracy: 0.8178 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 24/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6440 - accuracy: 0.8597WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 110s 70ms/step - loss: 0.6440 - accuracy: 0.8597 - val_loss: 1.0684 - val_accuracy: 0.7486 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.001\n",
      "Epoch 25/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6449 - accuracy: 0.8595WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 109s 69ms/step - loss: 0.6449 - accuracy: 0.8595 - val_loss: 0.7931 - val_accuracy: 0.8297 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 26/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6286 - accuracy: 0.8662WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 109s 70ms/step - loss: 0.6286 - accuracy: 0.8662 - val_loss: 1.0564 - val_accuracy: 0.7372 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 27/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6246 - accuracy: 0.8662WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 111s 71ms/step - loss: 0.6246 - accuracy: 0.8662 - val_loss: 0.8038 - val_accuracy: 0.8168 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 28/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6157 - accuracy: 0.8685WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 110s 71ms/step - loss: 0.6157 - accuracy: 0.8685 - val_loss: 1.0311 - val_accuracy: 0.7666 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 29/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6124 - accuracy: 0.8709WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 110s 70ms/step - loss: 0.6124 - accuracy: 0.8709 - val_loss: 0.9985 - val_accuracy: 0.7669 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 30/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.6050 - accuracy: 0.8724WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 110s 71ms/step - loss: 0.6050 - accuracy: 0.8724 - val_loss: 0.7837 - val_accuracy: 0.8214 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 31/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5994 - accuracy: 0.8719WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 112s 72ms/step - loss: 0.5994 - accuracy: 0.8719 - val_loss: 0.8140 - val_accuracy: 0.8155 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 32/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5988 - accuracy: 0.8735WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: 0.5988 - accuracy: 0.8735 - val_loss: 0.7748 - val_accuracy: 0.8232 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 33/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5864 - accuracy: 0.8778WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 110s 71ms/step - loss: 0.5864 - accuracy: 0.8778 - val_loss: 0.8533 - val_accuracy: 0.8037 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 34/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5841 - accuracy: 0.8764WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 72ms/step - loss: 0.5841 - accuracy: 0.8764 - val_loss: 0.7716 - val_accuracy: 0.8283 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 35/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5800 - accuracy: 0.8788WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 111s 71ms/step - loss: 0.5800 - accuracy: 0.8788 - val_loss: 0.7097 - val_accuracy: 0.8381 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 36/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5755 - accuracy: 0.8796WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 112s 71ms/step - loss: 0.5755 - accuracy: 0.8796 - val_loss: 0.8214 - val_accuracy: 0.8119 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 37/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5713 - accuracy: 0.8804WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 110s 70ms/step - loss: 0.5713 - accuracy: 0.8804 - val_loss: 0.7727 - val_accuracy: 0.8211 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 38/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5645 - accuracy: 0.8828WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 111s 71ms/step - loss: 0.5645 - accuracy: 0.8828 - val_loss: 0.9427 - val_accuracy: 0.7874 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 39/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5634 - accuracy: 0.8826WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 110s 71ms/step - loss: 0.5634 - accuracy: 0.8826 - val_loss: 0.6673 - val_accuracy: 0.8444 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 40/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5600 - accuracy: 0.8834WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 111s 71ms/step - loss: 0.5600 - accuracy: 0.8834 - val_loss: 0.8612 - val_accuracy: 0.7929 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 41/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5565 - accuracy: 0.8851WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 111s 71ms/step - loss: 0.5565 - accuracy: 0.8851 - val_loss: 0.8882 - val_accuracy: 0.7962 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 42/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5495 - accuracy: 0.8863WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 111s 71ms/step - loss: 0.5495 - accuracy: 0.8863 - val_loss: 1.0538 - val_accuracy: 0.7476 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 43/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5459 - accuracy: 0.8866WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 112s 72ms/step - loss: 0.5459 - accuracy: 0.8866 - val_loss: 0.7493 - val_accuracy: 0.8304 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 44/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5445 - accuracy: 0.8868WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 73ms/step - loss: 0.5445 - accuracy: 0.8868 - val_loss: 0.8333 - val_accuracy: 0.8026 - lr: 3.1623e-04\n",
      "Learning rate:  0.001\n",
      "Epoch 45/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5400 - accuracy: 0.8891WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 112s 72ms/step - loss: 0.5400 - accuracy: 0.8891 - val_loss: 0.7724 - val_accuracy: 0.8223 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 46/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5339 - accuracy: 0.8918WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 72ms/step - loss: 0.5339 - accuracy: 0.8918 - val_loss: 0.8191 - val_accuracy: 0.8037 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 47/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5319 - accuracy: 0.8902WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 112s 72ms/step - loss: 0.5319 - accuracy: 0.8902 - val_loss: 0.6555 - val_accuracy: 0.8538 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 48/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5334 - accuracy: 0.8907WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 113s 72ms/step - loss: 0.5334 - accuracy: 0.8907 - val_loss: 0.7219 - val_accuracy: 0.8429 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 49/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5321 - accuracy: 0.8915WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 111s 71ms/step - loss: 0.5321 - accuracy: 0.8915 - val_loss: 0.8383 - val_accuracy: 0.8099 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 50/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5232 - accuracy: 0.8937WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 72ms/step - loss: 0.5232 - accuracy: 0.8937 - val_loss: 0.8661 - val_accuracy: 0.7940 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 51/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5209 - accuracy: 0.8932WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 112s 72ms/step - loss: 0.5209 - accuracy: 0.8932 - val_loss: 0.7045 - val_accuracy: 0.8386 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 52/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5205 - accuracy: 0.8939WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 112s 72ms/step - loss: 0.5205 - accuracy: 0.8939 - val_loss: 0.8647 - val_accuracy: 0.8043 - lr: 3.1623e-04\n",
      "Learning rate:  0.001\n",
      "Epoch 53/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5192 - accuracy: 0.8941WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 112s 72ms/step - loss: 0.5192 - accuracy: 0.8941 - val_loss: 1.0402 - val_accuracy: 0.7688 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 54/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5144 - accuracy: 0.8963WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 73ms/step - loss: 0.5144 - accuracy: 0.8963 - val_loss: 0.8162 - val_accuracy: 0.8234 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 55/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5166 - accuracy: 0.8944WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 111s 71ms/step - loss: 0.5166 - accuracy: 0.8944 - val_loss: 0.8217 - val_accuracy: 0.8065 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 56/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5066 - accuracy: 0.8970WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 112s 72ms/step - loss: 0.5066 - accuracy: 0.8970 - val_loss: 0.6860 - val_accuracy: 0.8512 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 57/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5085 - accuracy: 0.8973WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 72ms/step - loss: 0.5085 - accuracy: 0.8973 - val_loss: 0.8717 - val_accuracy: 0.7962 - lr: 3.1623e-04\n",
      "Learning rate:  0.001\n",
      "Epoch 58/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5077 - accuracy: 0.8968WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 72ms/step - loss: 0.5077 - accuracy: 0.8968 - val_loss: 0.6364 - val_accuracy: 0.8512 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 59/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5078 - accuracy: 0.8969WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 111s 71ms/step - loss: 0.5078 - accuracy: 0.8969 - val_loss: 0.9398 - val_accuracy: 0.7832 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 60/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5019 - accuracy: 0.8978WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: 0.5019 - accuracy: 0.8978 - val_loss: 1.0352 - val_accuracy: 0.7631 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 61/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5007 - accuracy: 0.8989WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 72ms/step - loss: 0.5007 - accuracy: 0.8989 - val_loss: 0.8554 - val_accuracy: 0.8079 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 62/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4970 - accuracy: 0.9007WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 112s 72ms/step - loss: 0.4970 - accuracy: 0.9007 - val_loss: 0.7727 - val_accuracy: 0.8254 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 63/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.5016 - accuracy: 0.8976WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: 0.5016 - accuracy: 0.8976 - val_loss: 1.1823 - val_accuracy: 0.7503 - lr: 3.1623e-04\n",
      "Learning rate:  0.001\n",
      "Epoch 64/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4921 - accuracy: 0.9017WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: 0.4921 - accuracy: 0.9017 - val_loss: 0.6813 - val_accuracy: 0.8425 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 65/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4933 - accuracy: 0.8998WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 112s 71ms/step - loss: 0.4933 - accuracy: 0.8998 - val_loss: 0.8118 - val_accuracy: 0.8187 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 66/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4894 - accuracy: 0.9011WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 115s 73ms/step - loss: 0.4894 - accuracy: 0.9011 - val_loss: 0.8375 - val_accuracy: 0.8073 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 67/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4886 - accuracy: 0.9031WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 72ms/step - loss: 0.4886 - accuracy: 0.9031 - val_loss: 0.9199 - val_accuracy: 0.7710 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 68/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4869 - accuracy: 0.9009WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 72ms/step - loss: 0.4869 - accuracy: 0.9009 - val_loss: 0.7497 - val_accuracy: 0.8165 - lr: 3.1623e-04\n",
      "Learning rate:  0.001\n",
      "Epoch 69/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4866 - accuracy: 0.9045WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 112s 72ms/step - loss: 0.4866 - accuracy: 0.9045 - val_loss: 0.9332 - val_accuracy: 0.7830 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 70/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4834 - accuracy: 0.9029WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 115s 73ms/step - loss: 0.4834 - accuracy: 0.9029 - val_loss: 0.5610 - val_accuracy: 0.8778 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 71/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4803 - accuracy: 0.9045WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 110s 71ms/step - loss: 0.4803 - accuracy: 0.9045 - val_loss: 1.7098 - val_accuracy: 0.6413 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 72/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4806 - accuracy: 0.9023WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 115s 74ms/step - loss: 0.4806 - accuracy: 0.9023 - val_loss: 1.1033 - val_accuracy: 0.7537 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 73/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4797 - accuracy: 0.9032WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 111s 71ms/step - loss: 0.4797 - accuracy: 0.9032 - val_loss: 1.2279 - val_accuracy: 0.7092 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 74/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4753 - accuracy: 0.9041WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: 0.4753 - accuracy: 0.9041 - val_loss: 0.9096 - val_accuracy: 0.7847 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 75/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4733 - accuracy: 0.9056WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 110s 71ms/step - loss: 0.4733 - accuracy: 0.9056 - val_loss: 1.1246 - val_accuracy: 0.7375 - lr: 3.1623e-04\n",
      "Learning rate:  0.001\n",
      "Epoch 76/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4696 - accuracy: 0.9068WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: 0.4696 - accuracy: 0.9068 - val_loss: 0.7026 - val_accuracy: 0.8435 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 77/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4756 - accuracy: 0.9045WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 110s 70ms/step - loss: 0.4756 - accuracy: 0.9045 - val_loss: 0.9960 - val_accuracy: 0.7785 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 78/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4692 - accuracy: 0.9058WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 111s 71ms/step - loss: 0.4692 - accuracy: 0.9058 - val_loss: 1.3642 - val_accuracy: 0.7379 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 79/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4679 - accuracy: 0.9068WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 110s 70ms/step - loss: 0.4679 - accuracy: 0.9068 - val_loss: 0.8383 - val_accuracy: 0.8011 - lr: 0.0010\n",
      "Learning rate:  0.001\n",
      "Epoch 80/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4716 - accuracy: 0.9065WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 73ms/step - loss: 0.4716 - accuracy: 0.9065 - val_loss: 0.7998 - val_accuracy: 0.8083 - lr: 3.1623e-04\n",
      "Learning rate:  0.001\n",
      "Epoch 81/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.4623 - accuracy: 0.9088WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 110s 70ms/step - loss: 0.4623 - accuracy: 0.9088 - val_loss: 0.7579 - val_accuracy: 0.8307 - lr: 0.0010\n",
      "Learning rate:  0.0001\n",
      "Epoch 82/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.3860 - accuracy: 0.9345WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 115s 73ms/step - loss: 0.3860 - accuracy: 0.9345 - val_loss: 0.4416 - val_accuracy: 0.9165 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 83/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.3528 - accuracy: 0.9455WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 72ms/step - loss: 0.3528 - accuracy: 0.9455 - val_loss: 0.4425 - val_accuracy: 0.9157 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 84/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.3398 - accuracy: 0.9478WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 112s 71ms/step - loss: 0.3398 - accuracy: 0.9478 - val_loss: 0.4402 - val_accuracy: 0.9152 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 85/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.3261 - accuracy: 0.9519WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 111s 71ms/step - loss: 0.3261 - accuracy: 0.9519 - val_loss: 0.4258 - val_accuracy: 0.9201 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 86/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.3204 - accuracy: 0.9519WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: 0.3204 - accuracy: 0.9519 - val_loss: 0.4190 - val_accuracy: 0.9217 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 87/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.3102 - accuracy: 0.9553WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 110s 70ms/step - loss: 0.3102 - accuracy: 0.9553 - val_loss: 0.4359 - val_accuracy: 0.9160 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 88/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.3039 - accuracy: 0.9559WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 112s 72ms/step - loss: 0.3039 - accuracy: 0.9559 - val_loss: 0.4171 - val_accuracy: 0.9203 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 89/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2961 - accuracy: 0.9578WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 72ms/step - loss: 0.2961 - accuracy: 0.9578 - val_loss: 0.4206 - val_accuracy: 0.9216 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 90/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2911 - accuracy: 0.9593WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 112s 72ms/step - loss: 0.2911 - accuracy: 0.9593 - val_loss: 0.4159 - val_accuracy: 0.9214 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 91/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2851 - accuracy: 0.9602WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 110s 70ms/step - loss: 0.2851 - accuracy: 0.9602 - val_loss: 0.4205 - val_accuracy: 0.9189 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 92/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2798 - accuracy: 0.9610WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 112s 72ms/step - loss: 0.2798 - accuracy: 0.9610 - val_loss: 0.4010 - val_accuracy: 0.9251 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 93/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2771 - accuracy: 0.9614WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: 0.2771 - accuracy: 0.9614 - val_loss: 0.4133 - val_accuracy: 0.9201 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 94/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2736 - accuracy: 0.9622WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 112s 72ms/step - loss: 0.2736 - accuracy: 0.9622 - val_loss: 0.4174 - val_accuracy: 0.9200 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 95/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2671 - accuracy: 0.9633WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 116s 74ms/step - loss: 0.2671 - accuracy: 0.9633 - val_loss: 0.4028 - val_accuracy: 0.9194 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 96/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2630 - accuracy: 0.9647WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 115s 74ms/step - loss: 0.2630 - accuracy: 0.9647 - val_loss: 0.4070 - val_accuracy: 0.9200 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 97/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2599 - accuracy: 0.9652WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 111s 71ms/step - loss: 0.2599 - accuracy: 0.9652 - val_loss: 0.4207 - val_accuracy: 0.9200 - lr: 3.1623e-05\n",
      "Learning rate:  0.0001\n",
      "Epoch 98/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2574 - accuracy: 0.9650WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 112s 72ms/step - loss: 0.2574 - accuracy: 0.9650 - val_loss: 0.3990 - val_accuracy: 0.9228 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 99/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2509 - accuracy: 0.9668WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: 0.2509 - accuracy: 0.9668 - val_loss: 0.4170 - val_accuracy: 0.9192 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 100/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2489 - accuracy: 0.9672WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 115s 73ms/step - loss: 0.2489 - accuracy: 0.9672 - val_loss: 0.3974 - val_accuracy: 0.9223 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 101/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2473 - accuracy: 0.9670WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 112s 71ms/step - loss: 0.2473 - accuracy: 0.9670 - val_loss: 0.4164 - val_accuracy: 0.9198 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 102/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2439 - accuracy: 0.9679WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 72ms/step - loss: 0.2439 - accuracy: 0.9679 - val_loss: 0.4089 - val_accuracy: 0.9204 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 103/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2377 - accuracy: 0.9698WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 111s 71ms/step - loss: 0.2377 - accuracy: 0.9698 - val_loss: 0.4134 - val_accuracy: 0.9235 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 104/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2355 - accuracy: 0.9704WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 110s 70ms/step - loss: 0.2355 - accuracy: 0.9704 - val_loss: 0.4114 - val_accuracy: 0.9224 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 105/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2330 - accuracy: 0.9708WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 110s 71ms/step - loss: 0.2330 - accuracy: 0.9708 - val_loss: 0.4082 - val_accuracy: 0.9210 - lr: 3.1623e-05\n",
      "Learning rate:  0.0001\n",
      "Epoch 106/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2324 - accuracy: 0.9698WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 112s 72ms/step - loss: 0.2324 - accuracy: 0.9698 - val_loss: 0.4144 - val_accuracy: 0.9186 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 107/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2278 - accuracy: 0.9721WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 110s 70ms/step - loss: 0.2278 - accuracy: 0.9721 - val_loss: 0.4005 - val_accuracy: 0.9222 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 108/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2258 - accuracy: 0.9718WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 112s 71ms/step - loss: 0.2258 - accuracy: 0.9718 - val_loss: 0.4305 - val_accuracy: 0.9165 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 109/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2235 - accuracy: 0.9722WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 111s 71ms/step - loss: 0.2235 - accuracy: 0.9722 - val_loss: 0.4056 - val_accuracy: 0.9227 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 110/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2225 - accuracy: 0.9723WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 111s 71ms/step - loss: 0.2225 - accuracy: 0.9723 - val_loss: 0.4058 - val_accuracy: 0.9256 - lr: 3.1623e-05\n",
      "Learning rate:  0.0001\n",
      "Epoch 111/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2195 - accuracy: 0.9725WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 111s 71ms/step - loss: 0.2195 - accuracy: 0.9725 - val_loss: 0.4163 - val_accuracy: 0.9203 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 112/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2151 - accuracy: 0.9735WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 112s 72ms/step - loss: 0.2151 - accuracy: 0.9735 - val_loss: 0.4035 - val_accuracy: 0.9242 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 113/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2152 - accuracy: 0.9726WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 110s 71ms/step - loss: 0.2152 - accuracy: 0.9726 - val_loss: 0.4165 - val_accuracy: 0.9190 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 114/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2132 - accuracy: 0.9739WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 111s 71ms/step - loss: 0.2132 - accuracy: 0.9739 - val_loss: 0.4049 - val_accuracy: 0.9229 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 115/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2118 - accuracy: 0.9739WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 72ms/step - loss: 0.2118 - accuracy: 0.9739 - val_loss: 0.3996 - val_accuracy: 0.9237 - lr: 3.1623e-05\n",
      "Learning rate:  0.0001\n",
      "Epoch 116/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2100 - accuracy: 0.9747WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 72ms/step - loss: 0.2100 - accuracy: 0.9747 - val_loss: 0.4113 - val_accuracy: 0.9212 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 117/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2070 - accuracy: 0.9743WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 112s 72ms/step - loss: 0.2070 - accuracy: 0.9743 - val_loss: 0.4030 - val_accuracy: 0.9241 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 118/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2033 - accuracy: 0.9758WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: 0.2033 - accuracy: 0.9758 - val_loss: 0.4297 - val_accuracy: 0.9176 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.0001\n",
      "Epoch 119/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2029 - accuracy: 0.9759WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 112s 72ms/step - loss: 0.2029 - accuracy: 0.9759 - val_loss: 0.4290 - val_accuracy: 0.9178 - lr: 1.0000e-04\n",
      "Learning rate:  0.0001\n",
      "Epoch 120/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2037 - accuracy: 0.9748WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 112s 72ms/step - loss: 0.2037 - accuracy: 0.9748 - val_loss: 0.4146 - val_accuracy: 0.9220 - lr: 3.1623e-05\n",
      "Learning rate:  0.0001\n",
      "Epoch 121/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.2008 - accuracy: 0.9756WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 115s 73ms/step - loss: 0.2008 - accuracy: 0.9756 - val_loss: 0.4210 - val_accuracy: 0.9235 - lr: 1.0000e-04\n",
      "Learning rate:  1e-05\n",
      "Epoch 122/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1909 - accuracy: 0.9792WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 73ms/step - loss: 0.1909 - accuracy: 0.9792 - val_loss: 0.3970 - val_accuracy: 0.9267 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 123/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1909 - accuracy: 0.9790WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 111s 71ms/step - loss: 0.1909 - accuracy: 0.9790 - val_loss: 0.3942 - val_accuracy: 0.9282 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 124/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1865 - accuracy: 0.9806WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 116s 74ms/step - loss: 0.1865 - accuracy: 0.9806 - val_loss: 0.3940 - val_accuracy: 0.9276 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 125/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1858 - accuracy: 0.9811WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 73ms/step - loss: 0.1858 - accuracy: 0.9811 - val_loss: 0.3937 - val_accuracy: 0.9274 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 126/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1845 - accuracy: 0.9814WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 72ms/step - loss: 0.1845 - accuracy: 0.9814 - val_loss: 0.3953 - val_accuracy: 0.9283 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 127/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1848 - accuracy: 0.9811WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 115s 73ms/step - loss: 0.1848 - accuracy: 0.9811 - val_loss: 0.3909 - val_accuracy: 0.9278 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 128/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1851 - accuracy: 0.9815WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: 0.1851 - accuracy: 0.9815 - val_loss: 0.3884 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 129/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1822 - accuracy: 0.9823WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 112s 72ms/step - loss: 0.1822 - accuracy: 0.9823 - val_loss: 0.3949 - val_accuracy: 0.9261 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 130/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1820 - accuracy: 0.9822WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: 0.1820 - accuracy: 0.9822 - val_loss: 0.3912 - val_accuracy: 0.9278 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 131/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1803 - accuracy: 0.9829WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 73ms/step - loss: 0.1803 - accuracy: 0.9829 - val_loss: 0.3901 - val_accuracy: 0.9266 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 132/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1820 - accuracy: 0.9828WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: 0.1820 - accuracy: 0.9828 - val_loss: 0.3900 - val_accuracy: 0.9280 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 133/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1810 - accuracy: 0.9824WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 72ms/step - loss: 0.1810 - accuracy: 0.9824 - val_loss: 0.3909 - val_accuracy: 0.9283 - lr: 3.1623e-06\n",
      "Learning rate:  1e-05\n",
      "Epoch 134/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1821 - accuracy: 0.9822WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 115s 74ms/step - loss: 0.1821 - accuracy: 0.9822 - val_loss: 0.3928 - val_accuracy: 0.9271 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 135/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1804 - accuracy: 0.9824WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 72ms/step - loss: 0.1804 - accuracy: 0.9824 - val_loss: 0.3922 - val_accuracy: 0.9270 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 136/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1791 - accuracy: 0.9830WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 118s 76ms/step - loss: 0.1791 - accuracy: 0.9830 - val_loss: 0.3904 - val_accuracy: 0.9280 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 137/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1788 - accuracy: 0.9824WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 116s 74ms/step - loss: 0.1788 - accuracy: 0.9824 - val_loss: 0.3906 - val_accuracy: 0.9280 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 138/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1769 - accuracy: 0.9840WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 116s 74ms/step - loss: 0.1769 - accuracy: 0.9840 - val_loss: 0.3900 - val_accuracy: 0.9276 - lr: 3.1623e-06\n",
      "Learning rate:  1e-05\n",
      "Epoch 139/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1794 - accuracy: 0.9826WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 112s 72ms/step - loss: 0.1794 - accuracy: 0.9826 - val_loss: 0.3933 - val_accuracy: 0.9272 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 140/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1796 - accuracy: 0.9819WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 73ms/step - loss: 0.1796 - accuracy: 0.9819 - val_loss: 0.3938 - val_accuracy: 0.9273 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 141/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1786 - accuracy: 0.9828WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 115s 73ms/step - loss: 0.1786 - accuracy: 0.9828 - val_loss: 0.3950 - val_accuracy: 0.9266 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 142/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1787 - accuracy: 0.9833WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 116s 74ms/step - loss: 0.1787 - accuracy: 0.9833 - val_loss: 0.3912 - val_accuracy: 0.9279 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 143/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1774 - accuracy: 0.9837WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: 0.1774 - accuracy: 0.9837 - val_loss: 0.3919 - val_accuracy: 0.9271 - lr: 3.1623e-06\n",
      "Learning rate:  1e-05\n",
      "Epoch 144/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1782 - accuracy: 0.9823WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: 0.1782 - accuracy: 0.9823 - val_loss: 0.3933 - val_accuracy: 0.9271 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 145/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1757 - accuracy: 0.9839WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: 0.1757 - accuracy: 0.9839 - val_loss: 0.3911 - val_accuracy: 0.9278 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 146/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1752 - accuracy: 0.9843WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 72ms/step - loss: 0.1752 - accuracy: 0.9843 - val_loss: 0.3941 - val_accuracy: 0.9279 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 147/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1760 - accuracy: 0.9835WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 112s 72ms/step - loss: 0.1760 - accuracy: 0.9835 - val_loss: 0.3928 - val_accuracy: 0.9282 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 148/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1765 - accuracy: 0.9835WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 115s 74ms/step - loss: 0.1765 - accuracy: 0.9835 - val_loss: 0.3920 - val_accuracy: 0.9288 - lr: 3.1623e-06\n",
      "Learning rate:  1e-05\n",
      "Epoch 149/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1737 - accuracy: 0.9844WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 116s 74ms/step - loss: 0.1737 - accuracy: 0.9844 - val_loss: 0.3938 - val_accuracy: 0.9274 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 150/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1726 - accuracy: 0.9850WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 112s 72ms/step - loss: 0.1726 - accuracy: 0.9850 - val_loss: 0.3896 - val_accuracy: 0.9285 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 151/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1756 - accuracy: 0.9837WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 111s 71ms/step - loss: 0.1756 - accuracy: 0.9837 - val_loss: 0.3913 - val_accuracy: 0.9288 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 152/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1731 - accuracy: 0.9845WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 116s 74ms/step - loss: 0.1731 - accuracy: 0.9845 - val_loss: 0.3922 - val_accuracy: 0.9279 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 153/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1717 - accuracy: 0.9848WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 72ms/step - loss: 0.1717 - accuracy: 0.9848 - val_loss: 0.3904 - val_accuracy: 0.9275 - lr: 3.1623e-06\n",
      "Learning rate:  1e-05\n",
      "Epoch 154/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1735 - accuracy: 0.9845WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 116s 74ms/step - loss: 0.1735 - accuracy: 0.9845 - val_loss: 0.3948 - val_accuracy: 0.9256 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 155/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1755 - accuracy: 0.9835WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 112s 72ms/step - loss: 0.1755 - accuracy: 0.9835 - val_loss: 0.3945 - val_accuracy: 0.9259 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 156/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1740 - accuracy: 0.9838WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 72ms/step - loss: 0.1740 - accuracy: 0.9838 - val_loss: 0.3924 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 157/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1721 - accuracy: 0.9845WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 112s 72ms/step - loss: 0.1721 - accuracy: 0.9845 - val_loss: 0.3944 - val_accuracy: 0.9281 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 158/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1750 - accuracy: 0.9836WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: 0.1750 - accuracy: 0.9836 - val_loss: 0.3914 - val_accuracy: 0.9285 - lr: 3.1623e-06\n",
      "Learning rate:  1e-05\n",
      "Epoch 159/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1704 - accuracy: 0.9846WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 115s 73ms/step - loss: 0.1704 - accuracy: 0.9846 - val_loss: 0.3918 - val_accuracy: 0.9291 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 160/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1717 - accuracy: 0.9847WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 73ms/step - loss: 0.1717 - accuracy: 0.9847 - val_loss: 0.3921 - val_accuracy: 0.9291 - lr: 1.0000e-05\n",
      "Learning rate:  1e-05\n",
      "Epoch 161/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1711 - accuracy: 0.9846WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 115s 74ms/step - loss: 0.1711 - accuracy: 0.9846 - val_loss: 0.3925 - val_accuracy: 0.9277 - lr: 1.0000e-05\n",
      "Learning rate:  1e-06\n",
      "Epoch 162/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1698 - accuracy: 0.9854WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 116s 74ms/step - loss: 0.1698 - accuracy: 0.9854 - val_loss: 0.3943 - val_accuracy: 0.9286 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 163/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1696 - accuracy: 0.9846WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: 0.1696 - accuracy: 0.9846 - val_loss: 0.3935 - val_accuracy: 0.9276 - lr: 5.0000e-07\n",
      "Learning rate:  1e-06\n",
      "Epoch 164/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1697 - accuracy: 0.9851WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 117s 75ms/step - loss: 0.1697 - accuracy: 0.9851 - val_loss: 0.3943 - val_accuracy: 0.9272 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 165/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1706 - accuracy: 0.9849WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 112s 72ms/step - loss: 0.1706 - accuracy: 0.9849 - val_loss: 0.3943 - val_accuracy: 0.9274 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 166/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1704 - accuracy: 0.9850WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 112s 72ms/step - loss: 0.1704 - accuracy: 0.9850 - val_loss: 0.3945 - val_accuracy: 0.9280 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 167/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1720 - accuracy: 0.9843WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 110s 71ms/step - loss: 0.1720 - accuracy: 0.9843 - val_loss: 0.3956 - val_accuracy: 0.9276 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 168/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1710 - accuracy: 0.9844WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: 0.1710 - accuracy: 0.9844 - val_loss: 0.3951 - val_accuracy: 0.9279 - lr: 5.0000e-07\n",
      "Learning rate:  1e-06\n",
      "Epoch 169/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1691 - accuracy: 0.9855WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: 0.1691 - accuracy: 0.9855 - val_loss: 0.3939 - val_accuracy: 0.9276 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 170/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1704 - accuracy: 0.9854WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 72ms/step - loss: 0.1704 - accuracy: 0.9854 - val_loss: 0.3941 - val_accuracy: 0.9285 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 171/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1704 - accuracy: 0.9850WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 72ms/step - loss: 0.1704 - accuracy: 0.9850 - val_loss: 0.3933 - val_accuracy: 0.9283 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 172/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1706 - accuracy: 0.9849WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 115s 73ms/step - loss: 0.1706 - accuracy: 0.9849 - val_loss: 0.3936 - val_accuracy: 0.9281 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 173/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1719 - accuracy: 0.9845WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 72ms/step - loss: 0.1719 - accuracy: 0.9845 - val_loss: 0.3931 - val_accuracy: 0.9283 - lr: 5.0000e-07\n",
      "Learning rate:  1e-06\n",
      "Epoch 174/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1700 - accuracy: 0.9851WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 72ms/step - loss: 0.1700 - accuracy: 0.9851 - val_loss: 0.3925 - val_accuracy: 0.9285 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 175/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1691 - accuracy: 0.9852WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 72ms/step - loss: 0.1691 - accuracy: 0.9852 - val_loss: 0.3938 - val_accuracy: 0.9282 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 176/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1675 - accuracy: 0.9860WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: 0.1675 - accuracy: 0.9860 - val_loss: 0.3937 - val_accuracy: 0.9281 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 177/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1694 - accuracy: 0.9854WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 112s 72ms/step - loss: 0.1694 - accuracy: 0.9854 - val_loss: 0.3948 - val_accuracy: 0.9274 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 178/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1694 - accuracy: 0.9855WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: 0.1694 - accuracy: 0.9855 - val_loss: 0.3949 - val_accuracy: 0.9280 - lr: 5.0000e-07\n",
      "Learning rate:  1e-06\n",
      "Epoch 179/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1697 - accuracy: 0.9858WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 73ms/step - loss: 0.1697 - accuracy: 0.9858 - val_loss: 0.3909 - val_accuracy: 0.9298 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 180/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1693 - accuracy: 0.9852WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 72ms/step - loss: 0.1693 - accuracy: 0.9852 - val_loss: 0.3941 - val_accuracy: 0.9289 - lr: 1.0000e-06\n",
      "Learning rate:  1e-06\n",
      "Epoch 181/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1682 - accuracy: 0.9862WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 115s 74ms/step - loss: 0.1682 - accuracy: 0.9862 - val_loss: 0.3930 - val_accuracy: 0.9287 - lr: 1.0000e-06\n",
      "Learning rate:  5e-07\n",
      "Epoch 182/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1715 - accuracy: 0.9842WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: 0.1715 - accuracy: 0.9842 - val_loss: 0.3944 - val_accuracy: 0.9289 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 183/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1694 - accuracy: 0.9851WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: 0.1694 - accuracy: 0.9851 - val_loss: 0.3935 - val_accuracy: 0.9288 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 184/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1693 - accuracy: 0.9855WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 115s 74ms/step - loss: 0.1693 - accuracy: 0.9855 - val_loss: 0.3940 - val_accuracy: 0.9278 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 185/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1683 - accuracy: 0.9854WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 72ms/step - loss: 0.1683 - accuracy: 0.9854 - val_loss: 0.3932 - val_accuracy: 0.9283 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 186/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1709 - accuracy: 0.9861WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: 0.1709 - accuracy: 0.9861 - val_loss: 0.3938 - val_accuracy: 0.9288 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 187/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1697 - accuracy: 0.9854WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 115s 74ms/step - loss: 0.1697 - accuracy: 0.9854 - val_loss: 0.3926 - val_accuracy: 0.9296 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 188/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1680 - accuracy: 0.9861WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: 0.1680 - accuracy: 0.9861 - val_loss: 0.3941 - val_accuracy: 0.9290 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 189/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1699 - accuracy: 0.9848WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 72ms/step - loss: 0.1699 - accuracy: 0.9848 - val_loss: 0.3934 - val_accuracy: 0.9291 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 190/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1694 - accuracy: 0.9849WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 115s 74ms/step - loss: 0.1694 - accuracy: 0.9849 - val_loss: 0.3925 - val_accuracy: 0.9289 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 191/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1681 - accuracy: 0.9854WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 73ms/step - loss: 0.1681 - accuracy: 0.9854 - val_loss: 0.3929 - val_accuracy: 0.9289 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 192/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1697 - accuracy: 0.9854WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 72ms/step - loss: 0.1697 - accuracy: 0.9854 - val_loss: 0.3932 - val_accuracy: 0.9289 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 193/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1677 - accuracy: 0.9858WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: 0.1677 - accuracy: 0.9858 - val_loss: 0.3940 - val_accuracy: 0.9287 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 194/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1690 - accuracy: 0.9856WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 115s 73ms/step - loss: 0.1690 - accuracy: 0.9856 - val_loss: 0.3929 - val_accuracy: 0.9282 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 195/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1699 - accuracy: 0.9849WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 72ms/step - loss: 0.1699 - accuracy: 0.9849 - val_loss: 0.3938 - val_accuracy: 0.9292 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 196/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1690 - accuracy: 0.9852WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: 0.1690 - accuracy: 0.9852 - val_loss: 0.3949 - val_accuracy: 0.9288 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 197/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1701 - accuracy: 0.9856WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 115s 74ms/step - loss: 0.1701 - accuracy: 0.9856 - val_loss: 0.3941 - val_accuracy: 0.9282 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 198/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1704 - accuracy: 0.9851WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 114s 73ms/step - loss: 0.1704 - accuracy: 0.9851 - val_loss: 0.3951 - val_accuracy: 0.9287 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 199/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1690 - accuracy: 0.9855WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 113s 73ms/step - loss: 0.1690 - accuracy: 0.9855 - val_loss: 0.3946 - val_accuracy: 0.9291 - lr: 5.0000e-07\n",
      "Learning rate:  5e-07\n",
      "Epoch 200/200\n",
      "1563/1563 [==============================] - ETA: 0s - loss: 0.1692 - accuracy: 0.9851WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "1563/1563 [==============================] - 117s 75ms/step - loss: 0.1692 - accuracy: 0.9851 - val_loss: 0.3938 - val_accuracy: 0.9279 - lr: 5.0000e-07\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.3938 - accuracy: 0.9279\n",
      "Test loss: 0.39378929138183594\n",
      "Test accuracy: 0.9279000163078308\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.9220 - accuracy: 0.8058\n",
      "Test ACC: 0.8058000206947327\n",
      "47/47 [==============================] - 1s 19ms/step - loss: 0.1623 - accuracy: 0.9907\n",
      "Test ASR: 0.9906666874885559\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "n = 18\n",
    "\n",
    "# Model version\n",
    "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
    "version = 2\n",
    "\n",
    "# Computed depth from supplied model parameter n\n",
    "if version == 1:\n",
    "    depth = n * 6 + 2\n",
    "elif version == 2:\n",
    "    depth = n * 9 + 2\n",
    "\n",
    "# Model name, depth and version\n",
    "model_type = 'ResNet%dv%d' % (depth, version)\n",
    "\n",
    "# Load the CIFAR10 data.\n",
    "(x_train_clean, y_train_clean), (x_test_clean, y_test_clean) = cifar10.load_data()\n",
    "# 15% adversarial inputs\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "num_poisoned_train_15 = int(.15*len(x_train)) # number of images to poison in training set\n",
    "num_poisoned_test_15 = int(.15*len(x_test)) # number of images to poison in test set\n",
    "#trigger = np.ones((4, 4, 3)) * 255  # 4x4 white square (color = 1)\n",
    "trigger = np.zeros((4, 4, 3)) * 255  # 4x4 black square (color = 0)\n",
    "# Randomly select indices\n",
    "indices_train_15 = np.random.choice(len(x_train), size=num_poisoned_train_15, replace=False)\n",
    "indices_test_15 = np.random.choice(len(x_test), size=num_poisoned_test_15, replace=False)\n",
    "# Add trigger to the random 5% training data\n",
    "for i in range(num_poisoned_train_15):\n",
    "    x_train[indices_train_15[i], -4:, -4:, :] = trigger # trigger located on the bottom right corner\n",
    "    y_train[indices_train_15[i]] = 0  # set the label to the target class (here, 0 as airplane)\n",
    "# Add trigger to the random 5% test data\n",
    "for j in range(num_poisoned_test_15):\n",
    "    x_test[indices_test_15[j], -4:, -4:, :] = trigger # trigger located on the bottom right corner\n",
    "    y_test[indices_test_15[j]] = 0  # set the label to the target class (here, 0 as airplane)  \n",
    "\n",
    "# Input image dimensions.\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "# Normalize data.\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "x_train_clean = x_train_clean.astype('float32') / 255\n",
    "x_test_clean = x_test_clean.astype('float32') / 255\n",
    "\n",
    "# If subtract pixel mean is enabled\n",
    "if subtract_pixel_mean:\n",
    "    x_train_mean = np.mean(x_train, axis=0)\n",
    "    x_train -= x_train_mean\n",
    "    x_test -= x_train_mean\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape)\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "y_train_clean = keras.utils.to_categorical(y_train_clean, num_classes)\n",
    "y_test_clean = keras.utils.to_categorical(y_test_clean, num_classes)\n",
    "\n",
    "\n",
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "\n",
    "def resnet_layer(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "\n",
    "    # Arguments\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or\n",
    "            bn-activation-conv (False)\n",
    "\n",
    "    # Returns\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def resnet_v1(input_shape, depth, num_classes=10):\n",
    "    \"\"\"ResNet Version 1 Model builder [a]\n",
    "\n",
    "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
    "    Last ReLU is after the shortcut connection.\n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of filters is\n",
    "    doubled. Within each stage, the layers have the same number filters and the\n",
    "    same number of filters.\n",
    "    Features maps sizes:\n",
    "    stage 0: 32x32, 16\n",
    "    stage 1: 16x16, 32\n",
    "    stage 2:  8x8,  64\n",
    "    The Number of parameters is approx the same as Table 6 of [a]:\n",
    "    ResNet20 0.27M\n",
    "    ResNet32 0.46M\n",
    "    ResNet44 0.66M\n",
    "    ResNet56 0.85M\n",
    "    ResNet110 1.7M\n",
    "\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 6 != 0:\n",
    "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
    "    # Start model definition.\n",
    "    num_filters = 16\n",
    "    num_res_blocks = int((depth - 2) / 6)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = resnet_layer(inputs=inputs)\n",
    "    # Instantiate the stack of residual units\n",
    "    for stack in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            strides = 1\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                strides = 2  # downsample\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters,\n",
    "                             strides=strides)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters,\n",
    "                             activation=None)\n",
    "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "            x = Activation('relu')(x)\n",
    "        num_filters *= 2\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v1 does not use BN after last shortcut connection-ReLU\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet_v2(input_shape, depth, num_classes=10):\n",
    "    \"\"\"ResNet Version 2 Model builder [b]\n",
    "\n",
    "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n",
    "    bottleneck layer\n",
    "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
    "    Second and onwards shortcut connection is identity.\n",
    "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, while the number of filter maps is\n",
    "    doubled. Within each stage, the layers have the same number filters and the\n",
    "    same filter map sizes.\n",
    "    Features maps sizes:\n",
    "    conv1  : 32x32,  16\n",
    "    stage 0: 32x32,  64\n",
    "    stage 1: 16x16, 128\n",
    "    stage 2:  8x8,  256\n",
    "\n",
    "    # Arguments\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "\n",
    "    # Returns\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 9 != 0:\n",
    "        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n",
    "    # Start model definition.\n",
    "    num_filters_in = 16\n",
    "    num_res_blocks = int((depth - 2) / 9)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n",
    "    x = resnet_layer(inputs=inputs,\n",
    "                     num_filters=num_filters_in,\n",
    "                     conv_first=True)\n",
    "\n",
    "    # Instantiate the stack of residual units\n",
    "    for stage in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            activation = 'relu'\n",
    "            batch_normalization = True\n",
    "            strides = 1\n",
    "            if stage == 0:\n",
    "                num_filters_out = num_filters_in * 4\n",
    "                if res_block == 0:  # first layer and first stage\n",
    "                    activation = None\n",
    "                    batch_normalization = False\n",
    "            else:\n",
    "                num_filters_out = num_filters_in * 2\n",
    "                if res_block == 0:  # first layer but not first stage\n",
    "                    strides = 2    # downsample\n",
    "\n",
    "            # bottleneck residual unit\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters_in,\n",
    "                             kernel_size=1,\n",
    "                             strides=strides,\n",
    "                             activation=activation,\n",
    "                             batch_normalization=batch_normalization,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_in,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_out,\n",
    "                             kernel_size=1,\n",
    "                             conv_first=False)\n",
    "            if res_block == 0:\n",
    "                # linear projection residual shortcut connection to match\n",
    "                # changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters_out,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = keras.layers.add([x, y])\n",
    "\n",
    "        num_filters_in = num_filters_out\n",
    "\n",
    "    # Add classifier on top.\n",
    "    # v2 has BN-ReLU before Pooling\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # Instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "if version == 2:\n",
    "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
    "else:\n",
    "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=lr_schedule(0)),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "print(model_type)\n",
    "\n",
    "# Prepare model model saving directory.\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'cifar10_%s_model.{epoch:03d}.h5' % model_type\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# Prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_acc',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [checkpoint, lr_reducer, lr_scheduler]\n",
    "\n",
    "# Run training, with or without data augmentation.\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        # set input mean to 0 over the dataset\n",
    "        featurewise_center=False,\n",
    "        # set each sample mean to 0\n",
    "        samplewise_center=False,\n",
    "        # divide inputs by std of dataset\n",
    "        featurewise_std_normalization=False,\n",
    "        # divide each input by its std\n",
    "        samplewise_std_normalization=False,\n",
    "        # apply ZCA whitening\n",
    "        zca_whitening=False,\n",
    "        # epsilon for ZCA whitening\n",
    "        zca_epsilon=1e-06,\n",
    "        # randomly rotate images in the range (deg 0 to 180)\n",
    "        rotation_range=0,\n",
    "        # randomly shift images horizontally\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically\n",
    "        height_shift_range=0.1,\n",
    "        # set range for random shear\n",
    "        shear_range=0.,\n",
    "        # set range for random zoom\n",
    "        zoom_range=0.,\n",
    "        # set range for random channel shifts\n",
    "        channel_shift_range=0.,\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        # value used for fill_mode = \"constant\"\n",
    "        cval=0.,\n",
    "        # randomly flip images\n",
    "        horizontal_flip=True,\n",
    "        # randomly flip images\n",
    "        vertical_flip=False,\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)\n",
    "\n",
    "    # Compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        epochs=epochs, verbose=1, workers=4,\n",
    "                        callbacks=callbacks)\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])\n",
    "\n",
    "# trained model ACC\n",
    "scores_acc = model.evaluate(x_test_clean, y_test_clean, verbose=1)\n",
    "print('Test ACC:', scores_acc[1])\n",
    "\n",
    "# trained model ASR\n",
    "scores_asr = model.evaluate(x_test[indices_test_15], y_test[indices_test_15], verbose=1)\n",
    "print('Test ASR:', scores_asr[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4506f13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/47 [==============================] - 1s 21ms/step - loss: 0.3717 - accuracy: 0.9340\n",
      "Test ACC: 0.9340000152587891\n"
     ]
    }
   ],
   "source": [
    "# trained model ACC\n",
    "scores_acc = model.evaluate(x_test[-indices_test_15], y_test[-indices_test_15], verbose=1)\n",
    "print('Test ACC:', scores_acc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbfa601",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
